{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "970d9aef",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71cace5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T02:57:37.844452Z",
     "start_time": "2022-11-14T02:57:32.940450Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e3db1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T03:47:12.458066Z",
     "start_time": "2022-10-27T03:47:12.452095Z"
    }
   },
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c7a26f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:04:46.752781Z",
     "start_time": "2022-11-14T03:03:16.762426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "There are 6 set of X\n",
      "X_*_nozero\n",
      "------------------------------------------------------------\n",
      "Normalized version\n",
      "X_*_norm\n",
      "------------------------------------------------------------\n",
      "There are 4 set of Y\n",
      "y_train_t1, y_train_t2, y_valid_t1, y_valid_t2\n",
      "when training, please use: 'y_train_t1_value,y_train_t2_value,y_valid_t1_value,y_valid_t2_value'\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "%run Data_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa393c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:06:01.527173Z",
     "start_time": "2022-11-14T03:06:01.518906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16760, 61)\n",
      "(2394, 61)\n",
      "(4790, 61)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_norm.shape)\n",
    "print(X_valid_norm.shape)\n",
    "print(X_test_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ffdcc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T06:27:37.687176Z",
     "start_time": "2022-11-12T06:27:37.683442Z"
    }
   },
   "source": [
    "# Imbalanced Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0e38388",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:06:04.316381Z",
     "start_time": "2022-11-14T03:06:04.293088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15535, 62) (1225, 62)\n"
     ]
    }
   ],
   "source": [
    "Full = pd.DataFrame(np.concatenate((X_train_norm,pd.DataFrame(y_train_t1.iloc[:,-1])),axis=1))\n",
    "Full\n",
    "\n",
    "label0 = Full[Full[61]==0]\n",
    "label1 = Full[Full[61]==1]\n",
    "print(label0.shape,label1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cac17082",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:06:06.154107Z",
     "start_time": "2022-11-14T03:06:05.903399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31070, 61)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "oversample = RandomOverSampler()\n",
    "x_over, y_over = oversample.fit_resample(X_train_norm, y_train_t1.iloc[:,-1])\n",
    "\n",
    "\n",
    "y_over = pd.DataFrame(y_over)\n",
    "y_over.shape\n",
    "x_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd3c662f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:06:08.132399Z",
     "start_time": "2022-11-14T03:06:08.095152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15535, 62) (15535, 62)\n"
     ]
    }
   ],
   "source": [
    "Full = pd.DataFrame(np.concatenate((x_over,y_over),axis=1))\n",
    "Full\n",
    "\n",
    "label0 = Full[Full[61]==0]\n",
    "label1 = Full[Full[61]==1]\n",
    "print(label0.shape,label1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55d6208d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:06:11.247652Z",
     "start_time": "2022-11-14T03:06:11.241208Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_norm=x_over\n",
    "\n",
    "y_train_t1 = y_over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560831ad",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fb9fe03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:06:15.430057Z",
     "start_time": "2022-11-14T03:06:15.421312Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = X_train_norm.shape[1] # 7488/24\n",
    "output_size = 2 # live or dead\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7e4676",
   "metadata": {},
   "source": [
    "# Create FullyNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c00d907c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:06:17.223389Z",
     "start_time": "2022-11-14T03:06:17.208920Z"
    }
   },
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 52)\n",
    "        self.fc2 = nn.Linear(52, 26)\n",
    "        self.fc3 = nn.Linear(26, 13)\n",
    "        self.fc4 = nn.Linear(13, 1)\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm1d(52)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(26)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "         x = F.leaky_relu(self.fc1(x))\n",
    "         x = self.batchnorm1(x)\n",
    "         x = F.leaky_relu(self.fc2(x))\n",
    "         x = self.batchnorm2(x)\n",
    "         x = F.leaky_relu(self.fc3(x))\n",
    "         x = self.dropout(x)\n",
    "         x = torch.sigmoid(self.fc4(x))\n",
    "         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076d6376",
   "metadata": {},
   "source": [
    "# Data transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7e4872c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:06:47.490552Z",
     "start_time": "2022-11-14T03:06:47.481504Z"
    }
   },
   "outputs": [],
   "source": [
    "class CusDatasetLoader(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.len = y.shape[0]\n",
    "        self.x_data = x\n",
    "        self.y_data = y\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #return self.dataframe.iloc[index]\n",
    "        return self.x_data[index], self.y_data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "456be776",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:06:49.651475Z",
     "start_time": "2022-11-14T03:06:49.641127Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_shape(X) : used for split the data into a right tensor size\n",
    "#input: X in shape of 16760 rows × 104 columns (df)\n",
    "#output: X in shape of torch.Size([16760, 104, 1]) (tensor)\n",
    "\n",
    "def X_tensor(X):\n",
    "    X_tensor = torch.from_numpy(np.array(X)).to(torch.float32)\n",
    "    #print(X_tensor.shape)\n",
    "    #X_tensor = torch.stack(X_tensor).permute()\n",
    "    print(\"X now in shape of\",X_tensor.shape)\n",
    "    return X_tensor\n",
    "\n",
    "# y_tensor(y) : used for split the data into a right tensor size\n",
    "#input: X in shape of 16760 rows × 7488 columns (df)\n",
    "#output: X in shape of torch.Size([16760, 312, 24]) (tensor)\n",
    "\n",
    "def y_tensor(y):\n",
    "    y= torch.from_numpy(np.array(y)).to(torch.float32).reshape(len(y),1)\n",
    "    print(\"y now in shape of\",y.shape)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "006849f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:06:51.768297Z",
     "start_time": "2022-11-14T03:06:51.715743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X now in shape of torch.Size([31070, 61])\n",
      "y now in shape of torch.Size([31070, 1])\n",
      "torch.Size([61])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# X should be in smaples, 1, squence, rows\n",
    "X1 = X_tensor(X_train_norm)\n",
    "y1 = y_tensor(y_train_t1.iloc[:,-1].astype(float))\n",
    "\n",
    "train_datasets = CusDatasetLoader(X1, y1)\n",
    "train_loader = DataLoader(dataset=train_datasets, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "x,y = train_datasets[0]\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e366eb01",
   "metadata": {},
   "source": [
    "# Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6443333a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:06:57.121899Z",
     "start_time": "2022-11-14T03:06:57.096657Z"
    }
   },
   "outputs": [],
   "source": [
    "model = NN(input_size).to(device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "521238bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-10T17:45:27.568519Z",
     "start_time": "2022-11-10T17:45:27.562929Z"
    }
   },
   "source": [
    "# Criterion and optimizer setting\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "#optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "#optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e73149f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:06:59.836071Z",
     "start_time": "2022-11-14T03:06:59.829298Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adadelta(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680547a7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-11-14T03:07:04.906Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: | Loss: 2.67201 | Acc: 0.582\n",
      "Epoch 001: | Loss: 2.41841 | Acc: 0.642\n",
      "Epoch 002: | Loss: 2.18822 | Acc: 0.676\n",
      "Epoch 003: | Loss: 2.01252 | Acc: 0.698\n",
      "Epoch 004: | Loss: 1.76016 | Acc: 0.713\n",
      "Epoch 005: | Loss: 1.55199 | Acc: 0.725\n",
      "Epoch 006: | Loss: 1.33506 | Acc: 0.734\n",
      "Epoch 007: | Loss: 1.32244 | Acc: 0.742\n",
      "Epoch 008: | Loss: 1.15546 | Acc: 0.748\n",
      "Epoch 009: | Loss: 1.31664 | Acc: 0.754\n",
      "Epoch 010: | Loss: 1.03218 | Acc: 0.758\n",
      "Epoch 011: | Loss: 1.13198 | Acc: 0.763\n",
      "Epoch 012: | Loss: 0.84321 | Acc: 0.766\n",
      "Epoch 013: | Loss: 0.80803 | Acc: 0.770\n",
      "Epoch 014: | Loss: 0.87325 | Acc: 0.773\n",
      "Epoch 015: | Loss: 0.93985 | Acc: 0.776\n",
      "Epoch 016: | Loss: 0.79397 | Acc: 0.779\n",
      "Epoch 017: | Loss: 0.88705 | Acc: 0.781\n",
      "Epoch 018: | Loss: 0.66645 | Acc: 0.784\n",
      "Epoch 019: | Loss: 0.90683 | Acc: 0.786\n",
      "Epoch 020: | Loss: 0.85435 | Acc: 0.789\n",
      "Epoch 021: | Loss: 0.70470 | Acc: 0.791\n",
      "Epoch 022: | Loss: 0.60547 | Acc: 0.793\n",
      "Epoch 023: | Loss: 0.66008 | Acc: 0.795\n",
      "Epoch 024: | Loss: 0.65927 | Acc: 0.797\n",
      "Epoch 025: | Loss: 0.75910 | Acc: 0.799\n",
      "Epoch 026: | Loss: 0.69386 | Acc: 0.801\n",
      "Epoch 027: | Loss: 0.57330 | Acc: 0.802\n",
      "Epoch 028: | Loss: 0.61382 | Acc: 0.804\n",
      "Epoch 029: | Loss: 0.52692 | Acc: 0.806\n",
      "Epoch 030: | Loss: 0.55182 | Acc: 0.808\n",
      "Epoch 031: | Loss: 0.51108 | Acc: 0.809\n",
      "Epoch 032: | Loss: 0.72770 | Acc: 0.811\n",
      "Epoch 033: | Loss: 0.51894 | Acc: 0.813\n",
      "Epoch 034: | Loss: 0.67376 | Acc: 0.814\n",
      "Epoch 035: | Loss: 0.54473 | Acc: 0.816\n",
      "Epoch 036: | Loss: 0.48988 | Acc: 0.817\n",
      "Epoch 037: | Loss: 0.65708 | Acc: 0.819\n",
      "Epoch 038: | Loss: 0.71385 | Acc: 0.820\n",
      "Epoch 039: | Loss: 0.54252 | Acc: 0.822\n",
      "Epoch 040: | Loss: 0.58134 | Acc: 0.823\n",
      "Epoch 041: | Loss: 0.47294 | Acc: 0.825\n",
      "Epoch 042: | Loss: 0.59782 | Acc: 0.826\n",
      "Epoch 043: | Loss: 0.53900 | Acc: 0.828\n",
      "Epoch 044: | Loss: 0.68143 | Acc: 0.829\n",
      "Epoch 045: | Loss: 0.66834 | Acc: 0.830\n",
      "Epoch 046: | Loss: 0.64271 | Acc: 0.832\n",
      "Epoch 047: | Loss: 0.50372 | Acc: 0.833\n",
      "Epoch 048: | Loss: 0.53533 | Acc: 0.834\n",
      "Epoch 049: | Loss: 0.49192 | Acc: 0.836\n",
      "Epoch 050: | Loss: 0.59071 | Acc: 0.837\n",
      "Epoch 051: | Loss: 0.67497 | Acc: 0.838\n",
      "Epoch 052: | Loss: 0.83095 | Acc: 0.839\n",
      "Epoch 053: | Loss: 0.63026 | Acc: 0.841\n",
      "Epoch 054: | Loss: 0.56251 | Acc: 0.842\n",
      "Epoch 055: | Loss: 0.46234 | Acc: 0.843\n",
      "Epoch 056: | Loss: 0.60813 | Acc: 0.844\n",
      "Epoch 057: | Loss: 0.58672 | Acc: 0.845\n",
      "Epoch 058: | Loss: 0.38236 | Acc: 0.846\n",
      "Epoch 059: | Loss: 0.49436 | Acc: 0.847\n"
     ]
    }
   ],
   "source": [
    "losses=[]\n",
    "acc_list=[]\n",
    "num_correct = 0\n",
    "num_samples = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        \n",
    "        # l2 regularization\n",
    "        l2_lambda = 0.02\n",
    "        l2_norm = sum(p.pow(2.0).sum()\n",
    "                  for p in model.parameters())\n",
    "        loss = loss + l2_lambda * l2_norm\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "        \n",
    "        #accuracy\n",
    "        scores = model(data)\n",
    "        predictions = scores\n",
    "        predictions = predictions.detach().apply_( lambda x: 1 if x >= 0.5 else 0 )\n",
    "        num_correct += int((predictions == targets).sum())\n",
    "        num_samples += predictions.size(0)\n",
    "        acc = num_correct / num_samples\n",
    "        \n",
    "    if epoch%5 == 0:\n",
    "        losses.append(loss.detach().numpy() )\n",
    "        acc_list.append(acc)\n",
    "    print(f'Epoch {epoch:03}: | Loss: {loss:.5f} | Acc: {acc:.3f}')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fcb9b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T09:13:56.281942Z",
     "start_time": "2022-11-12T09:13:56.178537Z"
    }
   },
   "outputs": [],
   "source": [
    "#plotting the loss\n",
    "x_range = list(range(5,5*len(losses)+5,5))\n",
    "plt.plot(x_range,losses)\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bcbff7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-28T17:23:14.669685Z",
     "start_time": "2022-10-28T17:23:14.663564Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7057e4ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T09:13:53.231997Z",
     "start_time": "2022-11-12T09:13:53.177988Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_correct = 0\n",
    "num_samples = 0\n",
    "\n",
    "# Set model to eval\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device=device)\n",
    "        y.to(device=device)\n",
    "        #y = torch.squeeze(y.to(device=device), 1)\n",
    "        #print(y.shape)\n",
    "\n",
    "        scores = model(x)\n",
    "        predictions = scores\n",
    "        predictions = predictions.apply_( lambda x: 1 if x >= 0.5 else 0 )\n",
    "        num_correct += int((predictions == y).sum())\n",
    "        num_samples += predictions.size(0)\n",
    "\n",
    "# Toggle model back to train\n",
    "model.train()\n",
    "#print(num_correct , num_samples)\n",
    "num_correct / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a94a4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T09:13:53.243529Z",
     "start_time": "2022-11-12T09:13:53.236579Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check accuracy on training & test to see how good our model\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    # Set model to eval\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(device=device)\n",
    "            y.to(device=device)\n",
    "            #y = torch.squeeze(y.to(device=device), 1)\n",
    "            #print(y.shape)\n",
    "\n",
    "            scores = model(x)\n",
    "            predictions = scores\n",
    "            predictions = predictions.apply_( lambda x: 1 if x >= 0.5 else 0 )\n",
    "            num_correct += int((predictions == y).sum())\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    # Toggle model back to train\n",
    "    model.train()\n",
    "    return num_correct / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f370065c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T09:13:53.297241Z",
     "start_time": "2022-11-12T09:13:53.246459Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:2f} %\")\n",
    "#print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122b08ba",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Model Performance on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7194f3f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T09:13:53.341969Z",
     "start_time": "2022-11-12T09:13:53.299911Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X2 = X_tensor(X_valid_norm)\n",
    "y2 = y_tensor(y_valid_t1.iloc[:,-1])\n",
    "\n",
    "Valid_datasets = CusDatasetLoader(X2, y2)\n",
    "Valid_loader = DataLoader(dataset=Valid_datasets, batch_size=batch_size, shuffle=True)\n",
    "print(f\"Accuracy on valid set: {check_accuracy(Valid_loader, model)*100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d120b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T09:13:53.483511Z",
     "start_time": "2022-11-12T09:13:53.344586Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_true = np.array(y_valid_t1.iloc[:,[-1]])\n",
    "all_y_pred = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x, y in Valid_loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            #y = torch.squeeze(y.to(device=device), 1)\n",
    "            \n",
    "            pred_y1 = torch.sigmoid(model(x))\n",
    "            y_pred = pred_y1.squeeze(-1).detach().numpy()\n",
    "            all_y_pred = np.append(all_y_pred, y_pred)\n",
    "\n",
    "print(y_true.shape)\n",
    "print(all_y_pred.reshape(-1,1).shape)\n",
    "fpr, tpr, _ = metrics.roc_curve(y_true, all_y_pred)\n",
    "roc_auc = metrics.roc_auc_score(y_true, all_y_pred)\n",
    "\n",
    "model.train()\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k-')\n",
    "plt.plot(fpr, tpr, label='FN(area = {:.3f})'.format(roc_auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title(\"ROC curve\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16acbcd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc30b2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T09:13:53.489456Z",
     "start_time": "2022-11-12T09:13:53.486041Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test(loader, model):\n",
    "    # Set model to eval\n",
    "    model.eval()\n",
    "    res = torch.tensor([], dtype=torch.int64)\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            predictions = scores\n",
    "            res =  torch.cat((predictions, res), 0)  \n",
    "    model.train()\n",
    "   \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767ccbaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T09:13:53.518258Z",
     "start_time": "2022-11-12T09:13:53.490696Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test_mean\n",
    "x_valid_mean=X_test_mean.values\n",
    "x_valid_mean_scaled = scaler.fit_transform(x_valid_mean)\n",
    "X_test_norm=pd.DataFrame(x_valid_mean_scaled)\n",
    "X_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e51253",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T09:13:53.591262Z",
     "start_time": "2022-11-12T09:13:53.519776Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test_final = X_tensor(X_test_norm)\n",
    "y_final = torch.zeros([4790,1])\n",
    "\n",
    "test_datasets = CusDatasetLoader(X_test_final, y_final)\n",
    "test_loader = DataLoader(dataset=test_datasets, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "result = test(test_loader, model)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8747d5c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-12T09:13:53.615499Z",
     "start_time": "2022-11-12T09:13:53.593321Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#df.index = ['Row_1', 'Row_2', 'Row_3', 'Row_4']\n",
    "res1 = pd.DataFrame(result.tolist(), columns=[\"Predicted\"])\n",
    "res1.index = X_test.index\n",
    "res1.index.name = 'Id'\n",
    "pd.DataFrame(res1).to_csv('out.csv')\n",
    "#print(torch.count_nonzero(torch.from_numpy(np.array(res1)).to(torch.float32)))\n",
    "res1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp3340",
   "language": "python",
   "name": "comp3340"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
