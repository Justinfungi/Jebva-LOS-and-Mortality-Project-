{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training the model\n",
    "X_train_realmean = pd.read_csv(\"../X/Xtrainmean.csv\")\n",
    "\n",
    "# For cross validation\n",
    "X_valid_realmean = pd.read_csv(\"../X/Xvalidmean.csv\")\n",
    "\n",
    "# For prediction\n",
    "X_test_realmean = pd.read_csv(\"../X/Xtestmean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_t1 = pd.read_csv(\"../Task1/Y_train.csv\")\n",
    "y_valid_t1 = pd.read_csv(\"../Task1/Y_valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_t2_value=y_train_t1[\"mort_icu\"]\n",
    "y_valid_t2_value=y_valid_t1[\"mort_icu\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminate feature containing 70% 0 value\n",
    "import copy\n",
    "X_train_nozero=copy.deepcopy(X_train_realmean)\n",
    "X_valid_nozero=copy.deepcopy(X_valid_realmean)\n",
    "X_test_nozero=copy.deepcopy(X_test_realmean)\n",
    "for i in X_train_realmean.columns:\n",
    "    if (X_train_nozero[i] == 0).sum()> 12000:\n",
    "        X_train_nozero.drop(i, axis=1, inplace=True)\n",
    "\n",
    "headnozero=list(X_train_nozero.columns.values)\n",
    "X_valid_nozero = X_valid_nozero[X_train_nozero.columns]\n",
    "X_test_nozero = X_test_nozero[X_train_nozero.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute the 0 with mean\n",
    "imp = SimpleImputer(missing_values=0, strategy='mean')\n",
    "X_train_nozero = pd.DataFrame(imp.fit_transform(X_train_nozero))\n",
    "X_train_nozero.columns=headnozero\n",
    "X_valid_nozero = pd.DataFrame(imp.fit_transform(X_valid_nozero))\n",
    "X_valid_nozero.columns=headnozero\n",
    "X_test_nozero = pd.DataFrame(imp.fit_transform(X_test_nozero))\n",
    "X_test_nozero.columns=headnozero\n",
    "X_train_nozero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_realmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(X_train_realmean,y_train_t2,on = 'Unnamed: 0',how='inner')\n",
    "valid = pd.merge(X_valid_realmean,y_valid_t2,on = 'Unnamed: 0',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##查看相关性\n",
    "train.corr().iloc[:,-1].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.corr().iloc[:,-1].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##查看方差\n",
    "train.var().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.corr().iloc[:,-1].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##对训练和验证集删除ID字段\n",
    "train.drop(['Unnamed: 0'],axis = 1,inplace=True)\n",
    "valid.drop(['Unnamed: 0'],axis = 1,inplace=True)\n",
    "test.drop(['Unnamed: 0'],axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.var().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_low_var = train.var()[train.var()<0.08].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_realmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_realmean.drop(train_low_var,axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(train_low_var,axis = 1,inplace=True)\n",
    "valid.drop(train_low_var,axis = 1,inplace=True)\n",
    "#X_test_realmean.drop(train_low_var,axis = 1,inplace=True)\n",
    "low_corr = train.corr().iloc[:,-1][abs(train.corr().iloc[:,-1])<0.005].index\n",
    "\n",
    "train_1 = train.copy()\n",
    "valid_1 = valid.copy()\n",
    "test_1=test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bycorrelation=train_1.iloc[:,:-1].to_csv('cor_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpd.to_csv('validnewpd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validbycorrelation=valid_1.iloc[:,:-1].to_csv('cor_valid.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbycorrelation=test_1.to_csv('cor_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbycorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##模型的建立\n",
    "##先使用lightgbm\n",
    "train_feature = train_1.loc[:,train_1.columns!='los_icu']\n",
    "train_label = train_1.loc[:,train_1.columns=='los_icu']\n",
    "\n",
    "valid_feature = valid_1.loc[:,valid_1.columns!='los_icu']\n",
    "valid_label = valid_1.loc[:,valid_1.columns=='los_icu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature=train_feature.append(valid_feature)\n",
    "train_feature=train_feature.append(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label=np.append(train_label,valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = cat.CatBoostRegressor(n_estimators=2000,verbose=0)\n",
    "\n",
    "cat_model.fit(train_feature.values,train_label)\n",
    "\n",
    "\n",
    "##预测\n",
    "pred = cat_model.predict(valid_feature.values)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(valid_label,pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cat_model.predict(test_1)\n",
    "pd.DataFrame(pred).to_csv('trainvalid.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = cat.CatBoostRegressor(n_estimators=2000,verbose=0)\n",
    "\n",
    "lgb_model.fit(X_train_selected_t2_norm,y_train_t2_value)\n",
    "\n",
    "\n",
    "##预测\n",
    "pred = lgb_model.predict(X_valid_selected_t2_norm)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_valid_t2_value,pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##测试数据\n",
    "\n",
    "\n",
    "##预测\n",
    "pred = lgb_model.predict(X_test_realmean.iloc[:,1:])\n",
    "pd.DataFrame(pred).to_csv('sample_submission_catboost.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##dnn\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "from keras import layers,models\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D,Flatten,MaxPooling1D,Dense,Dropout,Input,Reshape,Activation\n",
    "from keras.models import Sequential\n",
    "from keras.models import Sequential,Model\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def design_model():\n",
    "    # design network\n",
    "    inp=Input(shape=(61,))\n",
    "    reshape=Reshape((61,1))(inp)\n",
    "    conv1=Conv1D(32,3,padding='same')(reshape)\n",
    "    print(conv1)\n",
    "    l1=Activation('relu')(conv1)\n",
    "    print(l1)\n",
    "    l2 = Dropout(0.2)(l1)\n",
    "    m2=MaxPooling1D(pool_size=2,padding='valid')(l2)\n",
    "    print(m2)\n",
    "    m3 = Flatten()(m2)\n",
    "    print(m3)\n",
    "    m4 = Dense(8,activation='relu')(m3)\n",
    "    m5 = Dense(1,activation='linear')(m4)\n",
    "    model=Model(inputs = inp,outputs = m5)\n",
    "    model.summary() #打印出模型概况\n",
    "    model.compile(loss=[\"mse\"], optimizer='adam',metrics=['mse'])\n",
    "    \n",
    "    return model\n",
    "cnn_model = design_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = cnn_model.fit(train_feature, train_label, epochs=300, batch_size=1200,  validation_data=[valid_feature, valid_label],verbose=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = cnn_model.fit(X_train_selected_t2_norm,y_train_t2_value, epochs=300, batch_size=1200,  validation_data=[X_valid_selected_t2_norm, y_valid_t2_value],verbose=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##预测\n",
    "pred = cnn_model.predict(X_valid_selected_t2_norm)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_valid_t2_value,pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##模型融合\n",
    "##单独模型建模的函数\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor,AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "def get_models():\n",
    "    \"\"\"Generate a library of base learners.\"\"\"\n",
    "    \n",
    "    knn = KNeighborsRegressor()\n",
    "    gb = GradientBoostingRegressor(n_estimators = 100,random_state=922)\n",
    "    rf = RandomForestRegressor(n_estimators = 20,random_state=922)\n",
    "    adat = AdaBoostRegressor(n_estimators = 100,random_state=922)\n",
    "    lgb_model = lgb.LGBMRegressor(n_estimators=2000)\n",
    "    cat_model = cat.CatBoostRegressor(verbose=0,n_estimators=2000)\n",
    "    models = {\n",
    "              'knn': knn,\n",
    "              'rf': rf,\n",
    "              'gb': gb,\n",
    "              'adat':adat,\n",
    "              'lgb':lgb_model,\n",
    "              'cat':cat_model\n",
    "              }\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(model_list,xtrain,xtest,ytrain,ytest):\n",
    "    \"\"\"Fit models in list on training set and return preds\"\"\"\n",
    "    ##七个模型对于测试集的预测结果\n",
    "    P1 = np.zeros((ytest.shape[0], len(model_list)))\n",
    "    P1 = pd.DataFrame(P1)\n",
    "\n",
    "    print(\"Fitting models.\")\n",
    "    cols = list()\n",
    "    for i, (name, m) in enumerate(model_list.items()):\n",
    "        print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        m.fit(xtrain, ytrain)\n",
    "        P1.iloc[:, i] = m.predict(xtest)\n",
    "        cols.append(name)\n",
    "        print(\"done\")\n",
    "\n",
    "    P1.columns = cols\n",
    "    print(\"Done.\\n\")\n",
    "    return P1\n",
    "\n",
    "\n",
    "def score_models(y,P1):\n",
    "    \"\"\"Score model in prediction DF\"\"\"\n",
    "    print(\"Scoring models.\")\n",
    "    zb = pd.DataFrame()\n",
    "    for m in P1.columns:\n",
    "        rmse = np.sqrt(mean_squared_error(y,P1.loc[:,m]))\n",
    "        zb = pd.concat([zb,pd.DataFrame(np.array([rmse]).reshape(-1,1),columns = [m],\\\n",
    "                             index = ['rmse'])],axis = 1)\n",
    "\n",
    "        # print(\"%-26s: %.3f\" % (m, roc_score))\n",
    "    print(\"Done.\\n\")\n",
    "    return zb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "models = get_models()\n",
    "P1 = train_predict(models,train_feature.values,valid_feature.values,train_label.values,valid_label.values)\n",
    "zb = score_models(valid_label.values,P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_label.values.ravel()\n",
    "valid_label = valid_label.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##训练第一层分类器\n",
    "##Stacking建模------------不调参\n",
    "from sklearn.model_selection import KFold\n",
    "base_learners = get_models()\n",
    "kf = KFold(n_splits=5,shuffle=False)\n",
    "def get_oof(model,x_train,y_train,x_test):\n",
    "    oof_train=np.zeros((x_train.shape[0],))     \n",
    "    oof_test=np.zeros((x_test.shape[0],))       \n",
    "    oof_test_skf=np.zeros((5,x_test.shape[0]))  \n",
    "    for i,(train_index,test_index) in enumerate(kf.split(x_train)): \n",
    "        kf_x_train=x_train[train_index] \n",
    "        kf_y_train=y_train[train_index]              \n",
    "        kf_x_test=x_train[test_index]                \n",
    "        model=model.fit(kf_x_train,kf_y_train)\n",
    "        oof_train[test_index]=model.predict(kf_x_test)       \n",
    "        oof_test_skf[i,:]=model.predict(x_test)             \n",
    "    oof_test[:]=oof_test_skf.mean(axis=0)      \n",
    "    return oof_train,oof_test\n",
    "\n",
    "number_models=len(base_learners)\n",
    "xtrain_new=np.zeros((train_feature.shape[0],number_models))\n",
    "xtest_new=np.zeros((valid_feature.shape[0],number_models))\n",
    "for i, (name, m) in enumerate(base_learners.items()):\n",
    "    xtrain_new[:,i],xtest_new[:,i]=get_oof(m,train_feature.values,train_label,valid_feature.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cat\n",
    "meta_learner_no_params = cat.CatBoostRegressor(iterations = 2000)\n",
    "meta_learner_no_params.fit(xtrain_new, train_label)\n",
    "\n",
    "##预测\n",
    "pred = meta_learner_no_params.predict(valid_feature.values)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(valid_label,pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##模型调参\n",
    "from hyperopt import hp, tpe, fmin,STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "\n",
    "##定义第二层的要优化的参数函数\n",
    "def hyperopt_objective(params):\n",
    "    model=cat.CatBoostRegressor(iterations=int(params['iterations'])\n",
    "              ,max_depth=int(params['max_depth'])\n",
    "              ,l2_leaf_reg=params['l2_leaf_reg']\n",
    "              ,learning_rate=params['learning_rate']\n",
    "              )\n",
    "    \n",
    "    cv=KFold(n_splits=5,shuffle=True,random_state=3612)\n",
    "    validate_loss=abs(cross_val_score(model,train_feature,train_label\n",
    "                                   ,cv=cv\n",
    "                                   ,scoring='neg_root_mean_squared_error'\n",
    "                                   ,n_jobs=-1\n",
    "                                   ,error_score='raise')).mean()\n",
    "    \n",
    "    return validate_loss\n",
    "\n",
    " ##生成参数范围\n",
    "iterations_range = range(1500,2500,50)\n",
    "depth_range = range(1,10,1)\n",
    "l2_leaf_reg_range = range(2,8,1)\n",
    "\n",
    "param_grid_simple={'iterations':hp.choice('iterations',iterations_range)\n",
    "                   ,'max_depth':hp.choice('max_depth',depth_range)\n",
    "                   ,'l2_leaf_reg':hp.choice('l2_leaf_reg',l2_leaf_reg_range)\n",
    "                   ,'learning_rate':hp.quniform('learning_rate',0.001,0.5,0.001)\n",
    "                  }\n",
    "\n",
    "def param_hyperopt(max_evals=100):\n",
    "    # 记录迭代过程\n",
    "    trials=Trials()\n",
    "    \n",
    "    # 提前停止\n",
    "    early_stop_fn=no_progress_loss(50) \n",
    "\n",
    "    params_best=fmin(hyperopt_objective # 设定目标函数\n",
    "                     ,space=param_grid_simple \n",
    "                     ,algo=tpe.suggest \n",
    "                     ,max_evals=max_evals # 设定迭代次数\n",
    "                     ,trials=trials \n",
    "                     ,early_stop_fn=early_stop_fn # 控制提前停止\n",
    "                    )\n",
    "    \n",
    "    print('best parmas:',params_best)\n",
    "    return params_best,trials\n",
    "print('Stacking贝叶斯优化开始------------')\n",
    "params_best,trials = param_hyperopt(max_evals=50)\n",
    "print('Stacking贝叶斯优化结束------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner = cat.CatBoostRegressor(max_depth = depth_range[params_best['max_depth']],\n",
    "                                      iterations = iterations_range[params_best['iterations']],\n",
    "                                      l2_leaf_reg = l2_leaf_reg_range[params_best['l2_leaf_reg']])\n",
    "meta_learner.fit(train_feature, train_label)\n",
    "\n",
    "\n",
    "\n",
    "##预测\n",
    "pred_param = meta_learner.predict(valid_feature.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_catboost(model):\n",
    "    result=pd.DataFrame(model.get_feature_importance(),index=model.feature_names_,columns=['FeatureImportance'])\n",
    "    return result.sort_values('FeatureImportance',ascending=False)\n",
    "df=feature_importance_catboost(meta_learner)\n",
    "newco=df.drop(df.index[55:]).index\n",
    "df.drop(df.index[55:])\n",
    "#newco=df.drop(df.index[51:]).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##模型调参\n",
    "from hyperopt import hp, tpe, fmin,STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "\n",
    "##定义第二层的要优化的参数函数\n",
    "def hyperopt_objective(params):\n",
    "    model=cat.CatBoostRegressor(iterations=int(params['iterations'])\n",
    "              ,max_depth=int(params['max_depth'])\n",
    "              ,l2_leaf_reg=params['l2_leaf_reg']\n",
    "              ,learning_rate=params['learning_rate']\n",
    "              )\n",
    "    \n",
    "    cv=KFold(n_splits=5,shuffle=True,random_state=7)\n",
    "    validate_loss=abs(cross_val_score(model,trainnewpd,train_label\n",
    "                                   ,cv=cv\n",
    "                                   ,scoring='neg_root_mean_squared_error'\n",
    "                                   ,n_jobs=-1\n",
    "                                   ,error_score='raise')).mean()\n",
    "    \n",
    "    return validate_loss\n",
    "\n",
    " ##生成参数范围\n",
    "iterations_range = range(1500,2500,50)\n",
    "depth_range = range(1,10,1)\n",
    "l2_leaf_reg_range = range(2,8,1)\n",
    "\n",
    "param_grid_simple={'iterations':hp.choice('iterations',iterations_range)\n",
    "                   ,'max_depth':hp.choice('max_depth',depth_range)\n",
    "                   ,'l2_leaf_reg':hp.choice('l2_leaf_reg',l2_leaf_reg_range)\n",
    "                   ,'learning_rate':hp.quniform('learning_rate',0.001,0.5,0.001)\n",
    "                  }\n",
    "\n",
    "def param_hyperopt(max_evals=100):\n",
    "    # 记录迭代过程\n",
    "    trials=Trials()\n",
    "    \n",
    "    # 提前停止\n",
    "    early_stop_fn=no_progress_loss(50) \n",
    "\n",
    "    params_best=fmin(hyperopt_objective\n",
    "                     ,space=param_grid_simple \n",
    "                     ,algo=tpe.suggest \n",
    "                     ,max_evals=max_evals \n",
    "                     ,trials=trials \n",
    "                     ,early_stop_fn=early_stop_fn\n",
    "                    )\n",
    "    \n",
    "    print('best parmas:',params_best)\n",
    "    return params_best,trials\n",
    "print('Stacking贝叶斯优化开始------------')\n",
    "params_best,trials = param_hyperopt(max_evals=50)\n",
    "print('Stacking贝叶斯优化结束------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainnew=[]\n",
    "validnew=[]\n",
    "testnew=[]\n",
    "for i in newco:\n",
    "    trainnew.append(train_feature[i])\n",
    "    validnew.append(valid_feature[i])\n",
    "    testnew.append(test_1[i])\n",
    "trainnewpd=pd.DataFrame(trainnew).T\n",
    "validnewpd=pd.DataFrame(validnew).T\n",
    "testnewpd=pd.DataFrame(testnew).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner.fit(trainnewpd, train_label)\n",
    "\n",
    "pred_param = meta_learner.predict(validnewpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(mean_squared_error(valid_label.tolist(),pred_param)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = meta_learner.predict(test_1)\n",
    "pd.DataFrame(pred).to_csv('night.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "8ba9518ca4d3a1cfdfdedb62c6a9445a18bf006711f276b156ac15948056c126"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
