{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training the model\n",
    "X_train_realmean = pd.read_csv(\"../X/Xtrainmean.csv\")\n",
    "\n",
    "# For cross validation\n",
    "X_valid_realmean = pd.read_csv(\"../X/Xvalidmean.csv\")\n",
    "\n",
    "# For prediction\n",
    "X_test_realmean = pd.read_csv(\"../X/Xtestmean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_t1 = pd.read_csv(\"../Task1/Y_train.csv\")\n",
    "y_valid_t1 = pd.read_csv(\"../Task1/Y_valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_t2_value=y_train_t1[\"mort_icu\"]\n",
    "y_valid_t2_value=y_valid_t1[\"mort_icu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=X_test_realmean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminate feature containing 70% 0 value\n",
    "import copy\n",
    "X_train_nozero=copy.deepcopy(X_train_realmean)\n",
    "X_valid_nozero=copy.deepcopy(X_valid_realmean)\n",
    "X_test_nozero=copy.deepcopy(X_test_realmean)\n",
    "for i in X_train_realmean.columns:\n",
    "    if (X_train_nozero[i] == 0).sum()> 12000:\n",
    "        X_train_nozero.drop(i, axis=1, inplace=True)\n",
    "\n",
    "headnozero=list(X_train_nozero.columns.values)\n",
    "X_valid_nozero = X_valid_nozero[X_train_nozero.columns]\n",
    "X_test_nozero = X_test_nozero[X_train_nozero.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute the 0 with mean\n",
    "imp = SimpleImputer(missing_values=0, strategy='mean')\n",
    "X_train_nozero = pd.DataFrame(imp.fit_transform(X_train_nozero))\n",
    "X_train_nozero.columns=headnozero\n",
    "X_valid_nozero = pd.DataFrame(imp.fit_transform(X_valid_nozero))\n",
    "X_valid_nozero.columns=headnozero\n",
    "X_test_nozero = pd.DataFrame(imp.fit_transform(X_test_nozero))\n",
    "X_test_nozero.columns=headnozero\n",
    "X_train_nozero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(X_train_realmean,y_train_t1,on = 'Unnamed: 0',how='inner')\n",
    "valid = pd.merge(X_valid_realmean,y_valid_t1,on = 'Unnamed: 0',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>alanine aminotransferase</th>\n",
       "      <th>albumin</th>\n",
       "      <th>albumin ascites</th>\n",
       "      <th>albumin pleural</th>\n",
       "      <th>albumin urine</th>\n",
       "      <th>alkaline phosphate</th>\n",
       "      <th>anion gap</th>\n",
       "      <th>asparate aminotransferase</th>\n",
       "      <th>basophils</th>\n",
       "      <th>...</th>\n",
       "      <th>tidal volume spontaneous</th>\n",
       "      <th>total protein</th>\n",
       "      <th>total protein urine</th>\n",
       "      <th>troponin-i</th>\n",
       "      <th>troponin-t</th>\n",
       "      <th>venous pvo2</th>\n",
       "      <th>weight</th>\n",
       "      <th>white blood cell count</th>\n",
       "      <th>white blood cell count urine</th>\n",
       "      <th>mort_icu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3_145834_211552</td>\n",
       "      <td>-0.254460</td>\n",
       "      <td>-1.979855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.318615</td>\n",
       "      <td>0.931458</td>\n",
       "      <td>-0.226618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.026004</td>\n",
       "      <td>0.634186</td>\n",
       "      <td>0.160067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6_107064_228232</td>\n",
       "      <td>-0.256599</td>\n",
       "      <td>-0.251806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.422405</td>\n",
       "      <td>1.723627</td>\n",
       "      <td>-0.254291</td>\n",
       "      <td>-0.742403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.181589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9_150750_220597</td>\n",
       "      <td>-0.269432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.367050</td>\n",
       "      <td>-0.330641</td>\n",
       "      <td>-0.271686</td>\n",
       "      <td>2.097036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.181589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11_194540_229441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.088963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.139623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12_112213_232669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.240269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.333059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.317391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.414731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16755</th>\n",
       "      <td>99966_167228_252173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.044231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.572320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.361918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.584864</td>\n",
       "      <td>-0.156720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756</th>\n",
       "      <td>99973_150202_275083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.290362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.677870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.364145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.973702</td>\n",
       "      <td>0.429243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16757</th>\n",
       "      <td>99982_151454_221194</td>\n",
       "      <td>-0.260876</td>\n",
       "      <td>1.044231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.297857</td>\n",
       "      <td>-0.330641</td>\n",
       "      <td>-0.261407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.443803</td>\n",
       "      <td>-0.682067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16758</th>\n",
       "      <td>99991_151118_226241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.753579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.782719</td>\n",
       "      <td>-0.633884</td>\n",
       "      <td>-0.303768</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16759</th>\n",
       "      <td>99995_137810_229633</td>\n",
       "      <td>-0.243765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.207906</td>\n",
       "      <td>-1.418195</td>\n",
       "      <td>-0.221874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.411152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.366371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.607453</td>\n",
       "      <td>-0.447371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16760 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Unnamed: 0  alanine aminotransferase   albumin  \\\n",
       "0          3_145834_211552                 -0.254460 -1.979855   \n",
       "1          6_107064_228232                 -0.256599 -0.251806   \n",
       "2          9_150750_220597                 -0.269432  0.000000   \n",
       "3         11_194540_229441                  0.000000  0.000000   \n",
       "4         12_112213_232669                  0.000000  0.000000   \n",
       "...                    ...                       ...       ...   \n",
       "16755  99966_167228_252173                  0.000000  1.044231   \n",
       "16756  99973_150202_275083                  0.000000  0.000000   \n",
       "16757  99982_151454_221194                 -0.260876  1.044231   \n",
       "16758  99991_151118_226241                  0.000000  0.000000   \n",
       "16759  99995_137810_229633                 -0.243765  0.000000   \n",
       "\n",
       "       albumin ascites  albumin pleural  albumin urine  alkaline phosphate  \\\n",
       "0                  0.0              0.0            0.0           -0.318615   \n",
       "1                  0.0              0.0            0.0           -0.422405   \n",
       "2                  0.0              0.0            0.0           -0.367050   \n",
       "3                  0.0              0.0            0.0            0.000000   \n",
       "4                  0.0              0.0            0.0            0.000000   \n",
       "...                ...              ...            ...                 ...   \n",
       "16755              0.0              0.0            0.0            0.000000   \n",
       "16756              0.0              0.0            0.0            0.000000   \n",
       "16757              0.0              0.0            0.0           -0.297857   \n",
       "16758              0.0              0.0            0.0            0.000000   \n",
       "16759              0.0              0.0            0.0           -0.207906   \n",
       "\n",
       "       anion gap  asparate aminotransferase  basophils  ...  \\\n",
       "0       0.931458                  -0.226618   0.000000  ...   \n",
       "1       1.723627                  -0.254291  -0.742403  ...   \n",
       "2      -0.330641                  -0.271686   2.097036  ...   \n",
       "3      -0.088963                   0.000000   0.000000  ...   \n",
       "4       1.240269                   0.000000   0.000000  ...   \n",
       "...          ...                        ...        ...  ...   \n",
       "16755  -0.572320                   0.000000   0.290121  ...   \n",
       "16756  -0.290362                   0.000000  -0.677870  ...   \n",
       "16757  -0.330641                  -0.261407   0.000000  ...   \n",
       "16758  -0.753579                   0.000000   0.000000  ...   \n",
       "16759  -1.418195                  -0.221874   0.000000  ...   \n",
       "\n",
       "       tidal volume spontaneous  total protein  total protein urine  \\\n",
       "0                      0.000000            0.0                  0.0   \n",
       "1                      0.000000            0.0                  0.0   \n",
       "2                      0.000000            0.0                  0.0   \n",
       "3                      0.000000            0.0                  0.0   \n",
       "4                     -1.333059            0.0                  0.0   \n",
       "...                         ...            ...                  ...   \n",
       "16755                  0.000000            0.0                  0.0   \n",
       "16756                  0.000000            0.0                  0.0   \n",
       "16757                  0.000000            0.0                  0.0   \n",
       "16758                  0.000000            0.0                  0.0   \n",
       "16759                 -0.411152            0.0                  0.0   \n",
       "\n",
       "       troponin-i  troponin-t  venous pvo2    weight  white blood cell count  \\\n",
       "0             0.0    0.000000          0.0  1.026004                0.634186   \n",
       "1             0.0    0.000000          0.0  0.000000               -0.181589   \n",
       "2             0.0    0.000000          0.0  0.000000               -0.181589   \n",
       "3             0.0    0.000000          0.0  0.000000               -0.139623   \n",
       "4             0.0   -0.317391          0.0  0.000000               -0.414731   \n",
       "...           ...         ...          ...       ...                     ...   \n",
       "16755         0.0   -0.361918          0.0  0.584864               -0.156720   \n",
       "16756         0.0   -0.364145          0.0  0.973702                0.429243   \n",
       "16757         0.0    0.000000          0.0 -0.443803               -0.682067   \n",
       "16758         0.0    0.000000          0.0  0.782719               -0.633884   \n",
       "16759         0.0   -0.366371          0.0 -0.607453               -0.447371   \n",
       "\n",
       "       white blood cell count urine  mort_icu  \n",
       "0                          0.160067         0  \n",
       "1                          0.000000         0  \n",
       "2                          0.000000         1  \n",
       "3                          0.000000         0  \n",
       "4                          0.000000         0  \n",
       "...                             ...       ...  \n",
       "16755                      0.000000         0  \n",
       "16756                      0.000000         0  \n",
       "16757                      0.000000         0  \n",
       "16758                     -0.303768         0  \n",
       "16759                      0.000000         0  \n",
       "\n",
       "[16760 rows x 106 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mort_icu                                     1.000000\n",
       "anion gap                                    0.210730\n",
       "lactate                                      0.193637\n",
       "lactic acid                                  0.183405\n",
       "blood urea nitrogen                          0.143719\n",
       "                                               ...   \n",
       "co2                                         -0.092061\n",
       "mean corpuscular hemoglobin concentration   -0.102825\n",
       "albumin                                     -0.112213\n",
       "bicarbonate                                 -0.112932\n",
       "glascow coma scale total                    -0.221923\n",
       "Name: mort_icu, Length: 105, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##查看相关性\n",
    "train.corr().iloc[:,-1].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mort_icu                    1.000000\n",
       "lactate                     0.194417\n",
       "lactic acid                 0.186412\n",
       "anion gap                   0.174031\n",
       "blood urea nitrogen         0.132405\n",
       "                              ...   \n",
       "co2                        -0.092509\n",
       "bicarbonate                -0.112102\n",
       "glascow coma scale total   -0.212527\n",
       "creatinine body fluid            NaN\n",
       "lymphocytes atypical csl         NaN\n",
       "Name: mort_icu, Length: 105, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.corr().iloc[:,-1].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean corpuscular hemoglobin                  0.974906\n",
       "mean corpuscular volume                      0.958519\n",
       "platelets                                    0.925568\n",
       "red blood cell count                         0.892813\n",
       "mean corpuscular hemoglobin concentration    0.861872\n",
       "                                               ...   \n",
       "albumin pleural                              0.002685\n",
       "creatinine ascites                           0.001253\n",
       "lymphocytes atypical csl                     0.000716\n",
       "creatinine pleural                           0.000716\n",
       "creatinine body fluid                        0.000708\n",
       "Length: 105, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##查看方差\n",
    "train.var().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mort_icu                                     1.000000\n",
       "anion gap                                    0.210730\n",
       "lactate                                      0.193637\n",
       "lactic acid                                  0.183405\n",
       "blood urea nitrogen                          0.143719\n",
       "                                               ...   \n",
       "co2                                         -0.092061\n",
       "mean corpuscular hemoglobin concentration   -0.102825\n",
       "albumin                                     -0.112213\n",
       "bicarbonate                                 -0.112932\n",
       "glascow coma scale total                    -0.221923\n",
       "Name: mort_icu, Length: 105, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr().iloc[:,-1].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16760, 106)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##对训练和验证集删除ID字段\n",
    "train.drop(['Unnamed: 0'],axis = 1,inplace=True)\n",
    "valid.drop(['Unnamed: 0'],axis = 1,inplace=True)\n",
    "test.drop(['Unnamed: 0'],axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "platelets                                    0.943340\n",
       "mean corpuscular hemoglobin                  0.923437\n",
       "blood urea nitrogen                          0.905915\n",
       "mean corpuscular hemoglobin concentration    0.868764\n",
       "mean corpuscular volume                      0.867709\n",
       "                                               ...   \n",
       "calcium urine                                0.000781\n",
       "red blood cell count ascites                 0.000398\n",
       "creatinine ascites                           0.000058\n",
       "creatinine body fluid                        0.000000\n",
       "lymphocytes atypical csl                     0.000000\n",
       "Length: 105, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.var().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_low_var = train.var()[train.var()<0.08].index[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4790, 104)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(train_low_var,axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(train_low_var,axis = 1,inplace=True)\n",
    "valid.drop(train_low_var,axis = 1,inplace=True)\n",
    "low_corr = train.corr().iloc[:,-1][abs(train.corr().iloc[:,-1])<0.005].index\n",
    "\n",
    "train_1 = train.copy()\n",
    "valid_1 = valid.copy()\n",
    "test_1=test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bycorrelation=train_1.iloc[:,:-1].to_csv('cor_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpd.to_csv('validnewpd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validbycorrelation=valid_1.iloc[:,:-1].to_csv('cor_valid.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbycorrelation=test_1.to_csv('cor_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbycorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "##模型的建立\n",
    "##先使用lightgbm\n",
    "train_feature = train_1.loc[:,train_1.columns!='mort_icu']\n",
    "train_label = train_1.loc[:,train_1.columns=='mort_icu']\n",
    "\n",
    "valid_feature = valid_1.loc[:,valid_1.columns!='mort_icu']\n",
    "valid_label = valid_1.loc[:,valid_1.columns=='mort_icu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CatBoostClassifier' object has no attribute 'decision_function'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21292/689189106.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m##预测\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0my_valid_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcat_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_feature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m# compute ROC curve and AUC for each learning rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_valid_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CatBoostClassifier' object has no attribute 'decision_function'"
     ]
    }
   ],
   "source": [
    "cat_model = cat.CatBoostClassifier(n_estimators=2000,verbose=0)\n",
    "\n",
    "cat_model.fit(train_feature.values,train_label)\n",
    "\n",
    "\n",
    "##预测\n",
    "\n",
    "y_valid_score = cat_model.decision_function(valid_feature.values)\n",
    "# compute ROC curve and AUC for each learning rate\n",
    "fpr, tpr, thresholds = roc_curve(valid_feature,y_valid_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cat_model.predict_proba(test_1)\n",
    "pd.DataFrame(pred).to_csv('cat.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = cat.CatBoostRegressor(n_estimators=2000,verbose=0)\n",
    "\n",
    "lgb_model.fit(X_train_selected_t2_norm,y_train_t2_value)\n",
    "\n",
    "\n",
    "##预测\n",
    "pred = lgb_model.predict(X_valid_selected_t2_norm)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_valid_t2_value,pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "##dnn\n",
    "from tensorflow import keras\n",
    "from keras import optimizers\n",
    "from keras import layers,models\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D,Flatten,MaxPooling1D,Dense,Dropout,Input,Reshape,Activation\n",
    "from keras.models import Sequential\n",
    "from keras.models import Sequential,Model\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 61, 32), dtype=tf.float32, name=None), name='conv1d/BiasAdd:0', description=\"created by layer 'conv1d'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 61, 32), dtype=tf.float32, name=None), name='activation/Relu:0', description=\"created by layer 'activation'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 30, 32), dtype=tf.float32, name=None), name='max_pooling1d/Squeeze:0', description=\"created by layer 'max_pooling1d'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 960), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 61)]              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 61, 1)             0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 61, 32)            128       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 61, 32)            0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 61, 32)            0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 30, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 960)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 7688      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,825\n",
      "Trainable params: 7,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def design_model():\n",
    "    # design network\n",
    "    inp=Input(shape=(61,))\n",
    "    reshape=Reshape((61,1))(inp)\n",
    "    conv1=Conv1D(32,3,padding='same')(reshape)\n",
    "    print(conv1)\n",
    "    l1=Activation('relu')(conv1)\n",
    "    print(l1)\n",
    "    l2 = Dropout(0.2)(l1)\n",
    "    m2=MaxPooling1D(pool_size=2,padding='valid')(l2)\n",
    "    print(m2)\n",
    "    m3 = Flatten()(m2)\n",
    "    print(m3)\n",
    "    m4 = Dense(8,activation='relu')(m3)\n",
    "    m5 = Dense(1,activation='linear')(m4)\n",
    "    model=Model(inputs = inp,outputs = m5)\n",
    "    model.summary() #打印出模型概况\n",
    "    model.compile(loss=[\"mse\"], optimizer='adam',metrics=['mse'])\n",
    "    \n",
    "    return model\n",
    "cnn_model = design_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"D:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"D:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"D:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"D:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"D:\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 61), found shape=(None, 74)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21292/1881913042.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1200\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalid_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"D:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"D:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"D:\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"D:\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"D:\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 61), found shape=(None, 74)\n"
     ]
    }
   ],
   "source": [
    "history1 = cnn_model.fit(train_feature, train_label, epochs=300, batch_size=1200,  validation_data=[valid_feature, valid_label],verbose=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##预测\n",
    "pred = cnn_model.predict(X_valid_selected_t2_norm)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_valid_t2_value,pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "##模型融合\n",
    "##单独模型建模的函数\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor,AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "def get_models():\n",
    "    \"\"\"Generate a library of base learners.\"\"\"\n",
    "    \n",
    "    knn = KNeighborsRegressor()\n",
    "    gb = GradientBoostingRegressor(n_estimators = 100,random_state=922)\n",
    "    rf = RandomForestRegressor(n_estimators = 20,random_state=922)\n",
    "    adat = AdaBoostRegressor(n_estimators = 100,random_state=922)\n",
    "    lgb_model = lgb.LGBMRegressor(n_estimators=2000)\n",
    "    cat_model = cat.CatBoostRegressor(verbose=0,n_estimators=2000)\n",
    "    models = {\n",
    "              'knn': knn,\n",
    "              'rf': rf,\n",
    "              'gb': gb,\n",
    "              'adat':adat,\n",
    "              'lgb':lgb_model,\n",
    "              'cat':cat_model\n",
    "              }\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(model_list,xtrain,xtest,ytrain,ytest):\n",
    "    \"\"\"Fit models in list on training set and return preds\"\"\"\n",
    "    ##七个模型对于测试集的预测结果\n",
    "    P1 = np.zeros((ytest.shape[0], len(model_list)))\n",
    "    P1 = pd.DataFrame(P1)\n",
    "\n",
    "    print(\"Fitting models.\")\n",
    "    cols = list()\n",
    "    for i, (name, m) in enumerate(model_list.items()):\n",
    "        print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        m.fit(xtrain, ytrain)\n",
    "        P1.iloc[:, i] = m.predict(xtest)\n",
    "        cols.append(name)\n",
    "        print(\"done\")\n",
    "\n",
    "    P1.columns = cols\n",
    "    print(\"Done.\\n\")\n",
    "    return P1\n",
    "\n",
    "\n",
    "def score_models(y,P1):\n",
    "    \"\"\"Score model in prediction DF\"\"\"\n",
    "    print(\"Scoring models.\")\n",
    "    zb = pd.DataFrame()\n",
    "    for m in P1.columns:\n",
    "        rmse = np.sqrt(mean_squared_error(y,P1.loc[:,m]))\n",
    "        zb = pd.concat([zb,pd.DataFrame(np.array([rmse]).reshape(-1,1),columns = [m],\\\n",
    "                             index = ['rmse'])],axis = 1)\n",
    "\n",
    "        # print(\"%-26s: %.3f\" % (m, roc_score))\n",
    "    print(\"Done.\\n\")\n",
    "    return zb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting models.\n",
      "knn... done\n",
      "rf... done\n",
      "gb... done\n",
      "adat... done\n",
      "lgb... done\n",
      "cat... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n",
      "Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "models = get_models()\n",
    "P1 = train_predict(models,train_feature.values,valid_feature.values,train_label.values,valid_label.values)\n",
    "zb = score_models(valid_label.values,P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knn</th>\n",
       "      <th>rf</th>\n",
       "      <th>gb</th>\n",
       "      <th>adat</th>\n",
       "      <th>lgb</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.108487</td>\n",
       "      <td>0.041768</td>\n",
       "      <td>0.115392</td>\n",
       "      <td>0.111629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.093330</td>\n",
       "      <td>0.041768</td>\n",
       "      <td>0.347747</td>\n",
       "      <td>0.149019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.006062</td>\n",
       "      <td>0.041768</td>\n",
       "      <td>-0.045078</td>\n",
       "      <td>-0.022567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.028470</td>\n",
       "      <td>0.041768</td>\n",
       "      <td>0.124130</td>\n",
       "      <td>0.047172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.016206</td>\n",
       "      <td>0.041768</td>\n",
       "      <td>-0.039644</td>\n",
       "      <td>-0.018420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.014229</td>\n",
       "      <td>0.041768</td>\n",
       "      <td>0.011707</td>\n",
       "      <td>-0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>0.041768</td>\n",
       "      <td>-0.021299</td>\n",
       "      <td>-0.018572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.226737</td>\n",
       "      <td>0.142925</td>\n",
       "      <td>0.282306</td>\n",
       "      <td>0.346407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.063671</td>\n",
       "      <td>0.041768</td>\n",
       "      <td>0.029758</td>\n",
       "      <td>0.073779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.006814</td>\n",
       "      <td>0.041768</td>\n",
       "      <td>-0.025299</td>\n",
       "      <td>0.008798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2394 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      knn    rf        gb      adat       lgb       cat\n",
       "0     0.0  0.10  0.108487  0.041768  0.115392  0.111629\n",
       "1     0.0  0.15  0.093330  0.041768  0.347747  0.149019\n",
       "2     0.0  0.05  0.006062  0.041768 -0.045078 -0.022567\n",
       "3     0.0  0.05  0.028470  0.041768  0.124130  0.047172\n",
       "4     0.0  0.05 -0.016206  0.041768 -0.039644 -0.018420\n",
       "...   ...   ...       ...       ...       ...       ...\n",
       "2389  0.0  0.00  0.014229  0.041768  0.011707 -0.000133\n",
       "2390  0.0  0.05  0.004939  0.041768 -0.021299 -0.018572\n",
       "2391  0.0  0.55  0.226737  0.142925  0.282306  0.346407\n",
       "2392  0.2  0.10  0.063671  0.041768  0.029758  0.073779\n",
       "2393  0.0  0.00 -0.006814  0.041768 -0.025299  0.008798\n",
       "\n",
       "[2394 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knn</th>\n",
       "      <th>rf</th>\n",
       "      <th>gb</th>\n",
       "      <th>adat</th>\n",
       "      <th>lgb</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>0.236622</td>\n",
       "      <td>0.228028</td>\n",
       "      <td>0.2189</td>\n",
       "      <td>0.235682</td>\n",
       "      <td>0.221743</td>\n",
       "      <td>0.216937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           knn        rf      gb      adat       lgb       cat\n",
       "rmse  0.236622  0.228028  0.2189  0.235682  0.221743  0.216937"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alanine aminotransferase</th>\n",
       "      <th>albumin</th>\n",
       "      <th>alkaline phosphate</th>\n",
       "      <th>anion gap</th>\n",
       "      <th>asparate aminotransferase</th>\n",
       "      <th>basophils</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>bilirubin</th>\n",
       "      <th>blood urea nitrogen</th>\n",
       "      <th>calcium</th>\n",
       "      <th>...</th>\n",
       "      <th>systemic vascular resistance</th>\n",
       "      <th>systolic blood pressure</th>\n",
       "      <th>temperature</th>\n",
       "      <th>tidal volume observed</th>\n",
       "      <th>tidal volume set</th>\n",
       "      <th>tidal volume spontaneous</th>\n",
       "      <th>troponin-t</th>\n",
       "      <th>weight</th>\n",
       "      <th>white blood cell count</th>\n",
       "      <th>white blood cell count urine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.088963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.019964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.717612</td>\n",
       "      <td>-0.187666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.396711</td>\n",
       "      <td>0.702213</td>\n",
       "      <td>1.214153</td>\n",
       "      <td>2.536928</td>\n",
       "      <td>-0.353795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.387277</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.261946</td>\n",
       "      <td>1.044231</td>\n",
       "      <td>-0.138712</td>\n",
       "      <td>-0.733439</td>\n",
       "      <td>-0.259826</td>\n",
       "      <td>-0.226141</td>\n",
       "      <td>0.877078</td>\n",
       "      <td>-0.322540</td>\n",
       "      <td>-0.339235</td>\n",
       "      <td>-0.119024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.281789</td>\n",
       "      <td>0.056583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.105634</td>\n",
       "      <td>1.437970</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.251251</td>\n",
       "      <td>0.612219</td>\n",
       "      <td>0.117304</td>\n",
       "      <td>-0.330641</td>\n",
       "      <td>-0.265360</td>\n",
       "      <td>-0.484272</td>\n",
       "      <td>0.591306</td>\n",
       "      <td>-0.420192</td>\n",
       "      <td>-0.509118</td>\n",
       "      <td>0.395792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140199</td>\n",
       "      <td>-0.974249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.517139</td>\n",
       "      <td>-0.410068</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.813998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.158846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.138463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.403265</td>\n",
       "      <td>-0.018154</td>\n",
       "      <td>1.058462</td>\n",
       "      <td>0.883270</td>\n",
       "      <td>0.859888</td>\n",
       "      <td>-0.094990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220140</td>\n",
       "      <td>-0.452033</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.271571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.173309</td>\n",
       "      <td>-0.813998</td>\n",
       "      <td>-0.267732</td>\n",
       "      <td>1.580775</td>\n",
       "      <td>-0.051682</td>\n",
       "      <td>-0.420192</td>\n",
       "      <td>-0.416455</td>\n",
       "      <td>-0.736803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.269928</td>\n",
       "      <td>1.361948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.020899</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.572320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.662951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.045800</td>\n",
       "      <td>0.601718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.312894</td>\n",
       "      <td>-0.819947</td>\n",
       "      <td>-0.599413</td>\n",
       "      <td>-2.494192</td>\n",
       "      <td>-0.101985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.884455</td>\n",
       "      <td>-0.340125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4786</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.216102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.587504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.057667</td>\n",
       "      <td>0.533076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.527590</td>\n",
       "      <td>-0.115897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.339655</td>\n",
       "      <td>-0.370414</td>\n",
       "      <td>-0.041704</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4787</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.693159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.587504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.717612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.142656</td>\n",
       "      <td>0.342592</td>\n",
       "      <td>-0.059030</td>\n",
       "      <td>0.021368</td>\n",
       "      <td>-0.076804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109258</td>\n",
       "      <td>-0.338260</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.636073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.742403</td>\n",
       "      <td>-0.158846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.278523</td>\n",
       "      <td>0.258507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555985</td>\n",
       "      <td>-1.013160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.308485</td>\n",
       "      <td>-0.511336</td>\n",
       "      <td>0.318889</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4789</th>\n",
       "      <td>-0.246974</td>\n",
       "      <td>-1.691847</td>\n",
       "      <td>-0.443163</td>\n",
       "      <td>0.072156</td>\n",
       "      <td>-0.265360</td>\n",
       "      <td>-0.226141</td>\n",
       "      <td>-0.266011</td>\n",
       "      <td>-0.460881</td>\n",
       "      <td>1.390488</td>\n",
       "      <td>-0.713922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213222</td>\n",
       "      <td>-0.650296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.717063</td>\n",
       "      <td>0.558248</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4790 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alanine aminotransferase   albumin  alkaline phosphate  anion gap  \\\n",
       "0                     0.000000  0.000000            0.000000  -0.088963   \n",
       "1                    -0.261946  1.044231           -0.138712  -0.733439   \n",
       "2                    -0.251251  0.612219            0.117304  -0.330641   \n",
       "3                     0.000000  0.000000            0.000000  -0.813998   \n",
       "4                    -0.271571  0.000000           -0.173309  -0.813998   \n",
       "...                        ...       ...                 ...        ...   \n",
       "4785                  0.000000  0.000000            0.000000  -0.572320   \n",
       "4786                  0.000000  0.000000            0.000000   1.216102   \n",
       "4787                  0.000000  0.000000            0.000000  -0.693159   \n",
       "4788                  0.000000  0.000000            0.000000   0.636073   \n",
       "4789                 -0.246974 -1.691847           -0.443163   0.072156   \n",
       "\n",
       "      asparate aminotransferase  basophils  bicarbonate  bilirubin  \\\n",
       "0                      0.000000   0.000000     1.019964   0.000000   \n",
       "1                     -0.259826  -0.226141     0.877078  -0.322540   \n",
       "2                     -0.265360  -0.484272     0.591306  -0.420192   \n",
       "3                      0.000000   0.000000    -0.158846   0.000000   \n",
       "4                     -0.267732   1.580775    -0.051682  -0.420192   \n",
       "...                         ...        ...          ...        ...   \n",
       "4785                   0.000000   0.000000     1.662951   0.000000   \n",
       "4786                   0.000000   0.000000    -0.587504   0.000000   \n",
       "4787                   0.000000   0.000000    -0.587504   0.000000   \n",
       "4788                   0.000000  -0.742403    -0.158846   0.000000   \n",
       "4789                  -0.265360  -0.226141    -0.266011  -0.460881   \n",
       "\n",
       "      blood urea nitrogen   calcium  ...  systemic vascular resistance  \\\n",
       "0               -0.717612 -0.187666  ...                      0.000000   \n",
       "1               -0.339235 -0.119024  ...                      0.000000   \n",
       "2               -0.509118  0.395792  ...                      0.000000   \n",
       "3               -0.138463  0.000000  ...                     -0.403265   \n",
       "4               -0.416455 -0.736803  ...                      0.000000   \n",
       "...                   ...       ...  ...                           ...   \n",
       "4785            -0.045800  0.601718  ...                      0.000000   \n",
       "4786             2.057667  0.533076  ...                      0.000000   \n",
       "4787            -0.717612  0.000000  ...                      0.000000   \n",
       "4788             0.278523  0.258507  ...                      0.000000   \n",
       "4789             1.390488 -0.713922  ...                      0.000000   \n",
       "\n",
       "      systolic blood pressure  temperature  tidal volume observed  \\\n",
       "0                   -0.396711     0.702213               1.214153   \n",
       "1                   -0.281789     0.056583               0.000000   \n",
       "2                    0.140199    -0.974249               0.000000   \n",
       "3                   -0.018154     1.058462               0.883270   \n",
       "4                   -1.269928     1.361948               0.000000   \n",
       "...                       ...          ...                    ...   \n",
       "4785                -0.312894    -0.819947              -0.599413   \n",
       "4786                 1.527590    -0.115897               0.000000   \n",
       "4787                -0.142656     0.342592              -0.059030   \n",
       "4788                 0.555985    -1.013160               0.000000   \n",
       "4789                 0.213222    -0.650296               0.000000   \n",
       "\n",
       "      tidal volume set  tidal volume spontaneous  troponin-t    weight  \\\n",
       "0             2.536928                 -0.353795    0.000000  0.000000   \n",
       "1             0.000000                  0.000000    0.000000 -0.105634   \n",
       "2             0.000000                  0.000000    0.000000 -0.517139   \n",
       "3             0.859888                 -0.094990    0.000000  0.220140   \n",
       "4             0.000000                  0.000000    0.000000  0.000000   \n",
       "...                ...                       ...         ...       ...   \n",
       "4785         -2.494192                 -0.101985    0.000000 -0.884455   \n",
       "4786          0.000000                  0.000000   -0.339655 -0.370414   \n",
       "4787          0.021368                 -0.076804    0.000000  0.109258   \n",
       "4788          0.000000                  0.000000   -0.308485 -0.511336   \n",
       "4789          0.000000                  0.000000    0.000000 -0.717063   \n",
       "\n",
       "      white blood cell count  white blood cell count urine  \n",
       "0                   0.387277                           0.0  \n",
       "1                   1.437970                           0.0  \n",
       "2                  -0.410068                           0.0  \n",
       "3                  -0.452033                           0.0  \n",
       "4                  -1.020899                           0.0  \n",
       "...                      ...                           ...  \n",
       "4785               -0.340125                           0.0  \n",
       "4786               -0.041704                           0.0  \n",
       "4787               -0.338260                           0.0  \n",
       "4788                0.318889                           0.0  \n",
       "4789                0.558248                           0.0  \n",
       "\n",
       "[4790 rows x 74 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alanine aminotransferase</th>\n",
       "      <th>albumin</th>\n",
       "      <th>alkaline phosphate</th>\n",
       "      <th>anion gap</th>\n",
       "      <th>asparate aminotransferase</th>\n",
       "      <th>basophils</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>bilirubin</th>\n",
       "      <th>blood urea nitrogen</th>\n",
       "      <th>calcium</th>\n",
       "      <th>...</th>\n",
       "      <th>systemic vascular resistance</th>\n",
       "      <th>systolic blood pressure</th>\n",
       "      <th>temperature</th>\n",
       "      <th>tidal volume observed</th>\n",
       "      <th>tidal volume set</th>\n",
       "      <th>tidal volume spontaneous</th>\n",
       "      <th>troponin-t</th>\n",
       "      <th>weight</th>\n",
       "      <th>white blood cell count</th>\n",
       "      <th>white blood cell count urine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.254460</td>\n",
       "      <td>-1.979855</td>\n",
       "      <td>-0.318615</td>\n",
       "      <td>0.931458</td>\n",
       "      <td>-0.226618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.694872</td>\n",
       "      <td>-0.298127</td>\n",
       "      <td>0.792807</td>\n",
       "      <td>-1.004507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615623</td>\n",
       "      <td>-0.638602</td>\n",
       "      <td>-0.002273</td>\n",
       "      <td>0.800876</td>\n",
       "      <td>0.440628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.026004</td>\n",
       "      <td>0.634186</td>\n",
       "      <td>0.160067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.256599</td>\n",
       "      <td>-0.251806</td>\n",
       "      <td>-0.422405</td>\n",
       "      <td>1.723627</td>\n",
       "      <td>-0.254291</td>\n",
       "      <td>-0.742403</td>\n",
       "      <td>-1.444821</td>\n",
       "      <td>-0.444605</td>\n",
       "      <td>1.737977</td>\n",
       "      <td>-0.016061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.537514</td>\n",
       "      <td>-0.518339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.181589</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.269432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.367050</td>\n",
       "      <td>-0.330641</td>\n",
       "      <td>-0.271686</td>\n",
       "      <td>2.097036</td>\n",
       "      <td>1.019964</td>\n",
       "      <td>-0.395779</td>\n",
       "      <td>-0.439621</td>\n",
       "      <td>0.636039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.723172</td>\n",
       "      <td>0.101098</td>\n",
       "      <td>0.801063</td>\n",
       "      <td>1.039571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.181589</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.088963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.484141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.439621</td>\n",
       "      <td>0.910607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.661305</td>\n",
       "      <td>-0.188482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.139623</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.240269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.694872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348021</td>\n",
       "      <td>0.224186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.603034</td>\n",
       "      <td>-0.157922</td>\n",
       "      <td>0.476344</td>\n",
       "      <td>0.680205</td>\n",
       "      <td>-1.333059</td>\n",
       "      <td>-0.317391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.414731</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16755</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.044231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.572320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290121</td>\n",
       "      <td>0.091204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.200239</td>\n",
       "      <td>0.407232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667703</td>\n",
       "      <td>-1.013160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.361918</td>\n",
       "      <td>0.584864</td>\n",
       "      <td>-0.156720</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16756</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.290362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.677870</td>\n",
       "      <td>-2.230694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.331513</td>\n",
       "      <td>-0.599519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.389591</td>\n",
       "      <td>-0.067515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.364145</td>\n",
       "      <td>0.973702</td>\n",
       "      <td>0.429243</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16757</th>\n",
       "      <td>-0.260876</td>\n",
       "      <td>1.044231</td>\n",
       "      <td>-0.297857</td>\n",
       "      <td>-0.330641</td>\n",
       "      <td>-0.261407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.448622</td>\n",
       "      <td>-0.151648</td>\n",
       "      <td>0.116362</td>\n",
       "      <td>0.361470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.128922</td>\n",
       "      <td>-0.353408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.443803</td>\n",
       "      <td>-0.682067</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16758</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.753579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.051682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.219544</td>\n",
       "      <td>-0.788284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.021813</td>\n",
       "      <td>0.149653</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.782719</td>\n",
       "      <td>-0.633884</td>\n",
       "      <td>-0.303768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16759</th>\n",
       "      <td>-0.243765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.207906</td>\n",
       "      <td>-1.418195</td>\n",
       "      <td>-0.221874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.220207</td>\n",
       "      <td>0.361027</td>\n",
       "      <td>-0.671280</td>\n",
       "      <td>0.052581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.724944</td>\n",
       "      <td>0.064435</td>\n",
       "      <td>-1.081352</td>\n",
       "      <td>-0.817152</td>\n",
       "      <td>-0.411152</td>\n",
       "      <td>-0.366371</td>\n",
       "      <td>-0.607453</td>\n",
       "      <td>-0.447371</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16760 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alanine aminotransferase   albumin  alkaline phosphate  anion gap  \\\n",
       "0                     -0.254460 -1.979855           -0.318615   0.931458   \n",
       "1                     -0.256599 -0.251806           -0.422405   1.723627   \n",
       "2                     -0.269432  0.000000           -0.367050  -0.330641   \n",
       "3                      0.000000  0.000000            0.000000  -0.088963   \n",
       "4                      0.000000  0.000000            0.000000   1.240269   \n",
       "...                         ...       ...                 ...        ...   \n",
       "16755                  0.000000  1.044231            0.000000  -0.572320   \n",
       "16756                  0.000000  0.000000            0.000000  -0.290362   \n",
       "16757                 -0.260876  1.044231           -0.297857  -0.330641   \n",
       "16758                  0.000000  0.000000            0.000000  -0.753579   \n",
       "16759                 -0.243765  0.000000           -0.207906  -1.418195   \n",
       "\n",
       "       asparate aminotransferase  basophils  bicarbonate  bilirubin  \\\n",
       "0                      -0.226618   0.000000    -1.694872  -0.298127   \n",
       "1                      -0.254291  -0.742403    -1.444821  -0.444605   \n",
       "2                      -0.271686   2.097036     1.019964  -0.395779   \n",
       "3                       0.000000   0.000000     0.484141   0.000000   \n",
       "4                       0.000000   0.000000    -1.694872   0.000000   \n",
       "...                          ...        ...          ...        ...   \n",
       "16755                   0.000000   0.290121     0.091204   0.000000   \n",
       "16756                   0.000000  -0.677870    -2.230694   0.000000   \n",
       "16757                  -0.261407   0.000000     1.448622  -0.151648   \n",
       "16758                   0.000000   0.000000    -0.051682   0.000000   \n",
       "16759                  -0.221874   0.000000     2.220207   0.361027   \n",
       "\n",
       "       blood urea nitrogen   calcium  ...  systemic vascular resistance  \\\n",
       "0                 0.792807 -1.004507  ...                      0.615623   \n",
       "1                 1.737977 -0.016061  ...                      0.000000   \n",
       "2                -0.439621  0.636039  ...                      0.000000   \n",
       "3                -0.439621  0.910607  ...                      0.000000   \n",
       "4                 0.348021  0.224186  ...                      0.000000   \n",
       "...                    ...       ...  ...                           ...   \n",
       "16755            -0.200239  0.407232  ...                      0.000000   \n",
       "16756            -0.331513 -0.599519  ...                      0.000000   \n",
       "16757             0.116362  0.361470  ...                      0.000000   \n",
       "16758            -0.219544 -0.788284  ...                      0.000000   \n",
       "16759            -0.671280  0.052581  ...                      0.000000   \n",
       "\n",
       "       systolic blood pressure  temperature  tidal volume observed  \\\n",
       "0                    -0.638602    -0.002273               0.800876   \n",
       "1                     1.537514    -0.518339               0.000000   \n",
       "2                     1.723172     0.101098               0.801063   \n",
       "3                    -0.661305    -0.188482               0.000000   \n",
       "4                     0.603034    -0.157922               0.476344   \n",
       "...                        ...          ...                    ...   \n",
       "16755                 0.667703    -1.013160               0.000000   \n",
       "16756                -0.389591    -0.067515               0.000000   \n",
       "16757                -1.128922    -0.353408               0.000000   \n",
       "16758                 2.021813     0.149653               0.000000   \n",
       "16759                 0.724944     0.064435              -1.081352   \n",
       "\n",
       "       tidal volume set  tidal volume spontaneous  troponin-t    weight  \\\n",
       "0              0.440628                  0.000000    0.000000  1.026004   \n",
       "1              0.000000                  0.000000    0.000000  0.000000   \n",
       "2              1.039571                  0.000000    0.000000  0.000000   \n",
       "3              0.000000                  0.000000    0.000000  0.000000   \n",
       "4              0.680205                 -1.333059   -0.317391  0.000000   \n",
       "...                 ...                       ...         ...       ...   \n",
       "16755          0.000000                  0.000000   -0.361918  0.584864   \n",
       "16756          0.000000                  0.000000   -0.364145  0.973702   \n",
       "16757          0.000000                  0.000000    0.000000 -0.443803   \n",
       "16758          0.000000                  0.000000    0.000000  0.782719   \n",
       "16759         -0.817152                 -0.411152   -0.366371 -0.607453   \n",
       "\n",
       "       white blood cell count  white blood cell count urine  \n",
       "0                    0.634186                      0.160067  \n",
       "1                   -0.181589                      0.000000  \n",
       "2                   -0.181589                      0.000000  \n",
       "3                   -0.139623                      0.000000  \n",
       "4                   -0.414731                      0.000000  \n",
       "...                       ...                           ...  \n",
       "16755               -0.156720                      0.000000  \n",
       "16756                0.429243                      0.000000  \n",
       "16757               -0.682067                      0.000000  \n",
       "16758               -0.633884                     -0.303768  \n",
       "16759               -0.447371                      0.000000  \n",
       "\n",
       "[16760 rows x 74 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_label.values.ravel()\n",
    "valid_label = valid_label.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "##训练第一层分类器\n",
    "##Stacking建模------------不调参\n",
    "from sklearn.model_selection import KFold\n",
    "base_learners = get_models()\n",
    "kf = KFold(n_splits=5,shuffle=False)\n",
    "def get_oof(model,x_train,y_train,x_test):\n",
    "    oof_train=np.zeros((x_train.shape[0],))     \n",
    "    oof_test=np.zeros((x_test.shape[0],))       \n",
    "    oof_test_skf=np.zeros((5,x_test.shape[0]))  \n",
    "    for i,(train_index,test_index) in enumerate(kf.split(x_train)): \n",
    "        kf_x_train=x_train[train_index] \n",
    "        kf_y_train=y_train[train_index]              \n",
    "        kf_x_test=x_train[test_index]                \n",
    "        model=model.fit(kf_x_train,kf_y_train)\n",
    "        oof_train[test_index]=model.predict(kf_x_test)       \n",
    "        oof_test_skf[i,:]=model.predict(x_test)             \n",
    "    oof_test[:]=oof_test_skf.mean(axis=0)      \n",
    "    return oof_train,oof_test\n",
    "\n",
    "number_models=len(base_learners)\n",
    "xtrain_new=np.zeros((train_feature.shape[0],number_models))\n",
    "xtest_new=np.zeros((valid_feature.shape[0],number_models))\n",
    "for i, (name, m) in enumerate(base_learners.items()):\n",
    "    xtrain_new[:,i],xtest_new[:,i]=get_oof(m,train_feature.values,train_label,valid_feature.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.036381\n",
      "0:\tlearn: 0.2580043\ttotal: 3.28ms\tremaining: 6.56s\n",
      "1:\tlearn: 0.2558430\ttotal: 5.3ms\tremaining: 5.29s\n",
      "2:\tlearn: 0.2538703\ttotal: 7.26ms\tremaining: 4.83s\n",
      "3:\tlearn: 0.2519768\ttotal: 9.18ms\tremaining: 4.58s\n",
      "4:\tlearn: 0.2501705\ttotal: 11.1ms\tremaining: 4.42s\n",
      "5:\tlearn: 0.2484364\ttotal: 13ms\tremaining: 4.33s\n",
      "6:\tlearn: 0.2468678\ttotal: 15.1ms\tremaining: 4.3s\n",
      "7:\tlearn: 0.2453851\ttotal: 17ms\tremaining: 4.24s\n",
      "8:\tlearn: 0.2439408\ttotal: 18.9ms\tremaining: 4.18s\n",
      "9:\tlearn: 0.2426330\ttotal: 20.9ms\tremaining: 4.16s\n",
      "10:\tlearn: 0.2413672\ttotal: 22.9ms\tremaining: 4.14s\n",
      "11:\tlearn: 0.2401600\ttotal: 25.1ms\tremaining: 4.16s\n",
      "12:\tlearn: 0.2390220\ttotal: 27.1ms\tremaining: 4.13s\n",
      "13:\tlearn: 0.2379978\ttotal: 29ms\tremaining: 4.12s\n",
      "14:\tlearn: 0.2370593\ttotal: 30.9ms\tremaining: 4.08s\n",
      "15:\tlearn: 0.2361138\ttotal: 32.8ms\tremaining: 4.07s\n",
      "16:\tlearn: 0.2352518\ttotal: 34.7ms\tremaining: 4.05s\n",
      "17:\tlearn: 0.2344328\ttotal: 36.6ms\tremaining: 4.04s\n",
      "18:\tlearn: 0.2336759\ttotal: 38.6ms\tremaining: 4.03s\n",
      "19:\tlearn: 0.2329703\ttotal: 40.6ms\tremaining: 4.02s\n",
      "20:\tlearn: 0.2323373\ttotal: 42.5ms\tremaining: 4.01s\n",
      "21:\tlearn: 0.2316889\ttotal: 44.5ms\tremaining: 4s\n",
      "22:\tlearn: 0.2311250\ttotal: 46.4ms\tremaining: 3.99s\n",
      "23:\tlearn: 0.2305625\ttotal: 48.5ms\tremaining: 3.99s\n",
      "24:\tlearn: 0.2300254\ttotal: 50.4ms\tremaining: 3.98s\n",
      "25:\tlearn: 0.2295260\ttotal: 52.4ms\tremaining: 3.98s\n",
      "26:\tlearn: 0.2290512\ttotal: 54.3ms\tremaining: 3.97s\n",
      "27:\tlearn: 0.2286238\ttotal: 56.3ms\tremaining: 3.96s\n",
      "28:\tlearn: 0.2282057\ttotal: 58.2ms\tremaining: 3.96s\n",
      "29:\tlearn: 0.2277978\ttotal: 60.3ms\tremaining: 3.96s\n",
      "30:\tlearn: 0.2274234\ttotal: 62.4ms\tremaining: 3.96s\n",
      "31:\tlearn: 0.2271094\ttotal: 64.4ms\tremaining: 3.96s\n",
      "32:\tlearn: 0.2267672\ttotal: 66.4ms\tremaining: 3.96s\n",
      "33:\tlearn: 0.2264556\ttotal: 68.3ms\tremaining: 3.95s\n",
      "34:\tlearn: 0.2261562\ttotal: 70.3ms\tremaining: 3.95s\n",
      "35:\tlearn: 0.2259017\ttotal: 72.3ms\tremaining: 3.94s\n",
      "36:\tlearn: 0.2256346\ttotal: 74.3ms\tremaining: 3.94s\n",
      "37:\tlearn: 0.2254009\ttotal: 76.2ms\tremaining: 3.94s\n",
      "38:\tlearn: 0.2251632\ttotal: 78.2ms\tremaining: 3.93s\n",
      "39:\tlearn: 0.2249406\ttotal: 80.2ms\tremaining: 3.93s\n",
      "40:\tlearn: 0.2247173\ttotal: 82.1ms\tremaining: 3.92s\n",
      "41:\tlearn: 0.2244993\ttotal: 84.1ms\tremaining: 3.92s\n",
      "42:\tlearn: 0.2242713\ttotal: 86.1ms\tremaining: 3.92s\n",
      "43:\tlearn: 0.2240676\ttotal: 88ms\tremaining: 3.91s\n",
      "44:\tlearn: 0.2238833\ttotal: 90.1ms\tremaining: 3.91s\n",
      "45:\tlearn: 0.2237451\ttotal: 92.1ms\tremaining: 3.91s\n",
      "46:\tlearn: 0.2235949\ttotal: 94ms\tremaining: 3.91s\n",
      "47:\tlearn: 0.2234411\ttotal: 96ms\tremaining: 3.9s\n",
      "48:\tlearn: 0.2233138\ttotal: 98.1ms\tremaining: 3.9s\n",
      "49:\tlearn: 0.2231833\ttotal: 100ms\tremaining: 3.9s\n",
      "50:\tlearn: 0.2230648\ttotal: 102ms\tremaining: 3.9s\n",
      "51:\tlearn: 0.2229556\ttotal: 104ms\tremaining: 3.9s\n",
      "52:\tlearn: 0.2228474\ttotal: 106ms\tremaining: 3.9s\n",
      "53:\tlearn: 0.2227376\ttotal: 108ms\tremaining: 3.89s\n",
      "54:\tlearn: 0.2225960\ttotal: 110ms\tremaining: 3.89s\n",
      "55:\tlearn: 0.2224940\ttotal: 112ms\tremaining: 3.88s\n",
      "56:\tlearn: 0.2224144\ttotal: 114ms\tremaining: 3.88s\n",
      "57:\tlearn: 0.2223137\ttotal: 116ms\tremaining: 3.88s\n",
      "58:\tlearn: 0.2221999\ttotal: 118ms\tremaining: 3.88s\n",
      "59:\tlearn: 0.2220775\ttotal: 120ms\tremaining: 3.87s\n",
      "60:\tlearn: 0.2219877\ttotal: 122ms\tremaining: 3.87s\n",
      "61:\tlearn: 0.2218959\ttotal: 124ms\tremaining: 3.87s\n",
      "62:\tlearn: 0.2218312\ttotal: 126ms\tremaining: 3.87s\n",
      "63:\tlearn: 0.2217564\ttotal: 128ms\tremaining: 3.86s\n",
      "64:\tlearn: 0.2216649\ttotal: 130ms\tremaining: 3.86s\n",
      "65:\tlearn: 0.2215588\ttotal: 132ms\tremaining: 3.86s\n",
      "66:\tlearn: 0.2214730\ttotal: 134ms\tremaining: 3.85s\n",
      "67:\tlearn: 0.2213821\ttotal: 136ms\tremaining: 3.85s\n",
      "68:\tlearn: 0.2213050\ttotal: 138ms\tremaining: 3.85s\n",
      "69:\tlearn: 0.2212619\ttotal: 140ms\tremaining: 3.85s\n",
      "70:\tlearn: 0.2212233\ttotal: 142ms\tremaining: 3.85s\n",
      "71:\tlearn: 0.2211582\ttotal: 144ms\tremaining: 3.84s\n",
      "72:\tlearn: 0.2210669\ttotal: 145ms\tremaining: 3.84s\n",
      "73:\tlearn: 0.2209855\ttotal: 147ms\tremaining: 3.83s\n",
      "74:\tlearn: 0.2209367\ttotal: 149ms\tremaining: 3.83s\n",
      "75:\tlearn: 0.2208749\ttotal: 151ms\tremaining: 3.83s\n",
      "76:\tlearn: 0.2208426\ttotal: 153ms\tremaining: 3.83s\n",
      "77:\tlearn: 0.2207940\ttotal: 155ms\tremaining: 3.83s\n",
      "78:\tlearn: 0.2207456\ttotal: 157ms\tremaining: 3.83s\n",
      "79:\tlearn: 0.2207013\ttotal: 159ms\tremaining: 3.82s\n",
      "80:\tlearn: 0.2206547\ttotal: 161ms\tremaining: 3.82s\n",
      "81:\tlearn: 0.2206198\ttotal: 163ms\tremaining: 3.81s\n",
      "82:\tlearn: 0.2205795\ttotal: 165ms\tremaining: 3.81s\n",
      "83:\tlearn: 0.2205410\ttotal: 167ms\tremaining: 3.81s\n",
      "84:\tlearn: 0.2204928\ttotal: 169ms\tremaining: 3.82s\n",
      "85:\tlearn: 0.2204574\ttotal: 171ms\tremaining: 3.82s\n",
      "86:\tlearn: 0.2203931\ttotal: 174ms\tremaining: 3.82s\n",
      "87:\tlearn: 0.2203512\ttotal: 176ms\tremaining: 3.82s\n",
      "88:\tlearn: 0.2203314\ttotal: 178ms\tremaining: 3.82s\n",
      "89:\tlearn: 0.2202829\ttotal: 180ms\tremaining: 3.82s\n",
      "90:\tlearn: 0.2202288\ttotal: 182ms\tremaining: 3.82s\n",
      "91:\tlearn: 0.2201786\ttotal: 184ms\tremaining: 3.81s\n",
      "92:\tlearn: 0.2200935\ttotal: 186ms\tremaining: 3.81s\n",
      "93:\tlearn: 0.2200504\ttotal: 188ms\tremaining: 3.81s\n",
      "94:\tlearn: 0.2200009\ttotal: 190ms\tremaining: 3.81s\n",
      "95:\tlearn: 0.2199844\ttotal: 192ms\tremaining: 3.8s\n",
      "96:\tlearn: 0.2199396\ttotal: 194ms\tremaining: 3.8s\n",
      "97:\tlearn: 0.2199166\ttotal: 196ms\tremaining: 3.8s\n",
      "98:\tlearn: 0.2198808\ttotal: 198ms\tremaining: 3.8s\n",
      "99:\tlearn: 0.2198698\ttotal: 200ms\tremaining: 3.8s\n",
      "100:\tlearn: 0.2198674\ttotal: 201ms\tremaining: 3.78s\n",
      "101:\tlearn: 0.2197889\ttotal: 203ms\tremaining: 3.78s\n",
      "102:\tlearn: 0.2197383\ttotal: 205ms\tremaining: 3.77s\n",
      "103:\tlearn: 0.2196877\ttotal: 207ms\tremaining: 3.77s\n",
      "104:\tlearn: 0.2196553\ttotal: 209ms\tremaining: 3.77s\n",
      "105:\tlearn: 0.2196184\ttotal: 211ms\tremaining: 3.77s\n",
      "106:\tlearn: 0.2195848\ttotal: 213ms\tremaining: 3.76s\n",
      "107:\tlearn: 0.2195674\ttotal: 215ms\tremaining: 3.76s\n",
      "108:\tlearn: 0.2195161\ttotal: 217ms\tremaining: 3.76s\n",
      "109:\tlearn: 0.2195082\ttotal: 218ms\tremaining: 3.75s\n",
      "110:\tlearn: 0.2194525\ttotal: 220ms\tremaining: 3.74s\n",
      "111:\tlearn: 0.2193946\ttotal: 222ms\tremaining: 3.74s\n",
      "112:\tlearn: 0.2193459\ttotal: 224ms\tremaining: 3.74s\n",
      "113:\tlearn: 0.2193117\ttotal: 226ms\tremaining: 3.74s\n",
      "114:\tlearn: 0.2192759\ttotal: 228ms\tremaining: 3.73s\n",
      "115:\tlearn: 0.2192054\ttotal: 230ms\tremaining: 3.73s\n",
      "116:\tlearn: 0.2191751\ttotal: 232ms\tremaining: 3.73s\n",
      "117:\tlearn: 0.2191469\ttotal: 234ms\tremaining: 3.73s\n",
      "118:\tlearn: 0.2191074\ttotal: 235ms\tremaining: 3.72s\n",
      "119:\tlearn: 0.2190551\ttotal: 237ms\tremaining: 3.72s\n",
      "120:\tlearn: 0.2190146\ttotal: 239ms\tremaining: 3.72s\n",
      "121:\tlearn: 0.2189916\ttotal: 241ms\tremaining: 3.71s\n",
      "122:\tlearn: 0.2189391\ttotal: 243ms\tremaining: 3.71s\n",
      "123:\tlearn: 0.2189101\ttotal: 245ms\tremaining: 3.71s\n",
      "124:\tlearn: 0.2188731\ttotal: 247ms\tremaining: 3.71s\n",
      "125:\tlearn: 0.2188532\ttotal: 249ms\tremaining: 3.71s\n",
      "126:\tlearn: 0.2188318\ttotal: 251ms\tremaining: 3.7s\n",
      "127:\tlearn: 0.2188005\ttotal: 253ms\tremaining: 3.7s\n",
      "128:\tlearn: 0.2187529\ttotal: 255ms\tremaining: 3.7s\n",
      "129:\tlearn: 0.2187257\ttotal: 257ms\tremaining: 3.7s\n",
      "130:\tlearn: 0.2187085\ttotal: 259ms\tremaining: 3.69s\n",
      "131:\tlearn: 0.2186720\ttotal: 261ms\tremaining: 3.69s\n",
      "132:\tlearn: 0.2186425\ttotal: 263ms\tremaining: 3.69s\n",
      "133:\tlearn: 0.2186089\ttotal: 265ms\tremaining: 3.69s\n",
      "134:\tlearn: 0.2185787\ttotal: 267ms\tremaining: 3.69s\n",
      "135:\tlearn: 0.2185551\ttotal: 269ms\tremaining: 3.68s\n",
      "136:\tlearn: 0.2185368\ttotal: 271ms\tremaining: 3.68s\n",
      "137:\tlearn: 0.2185068\ttotal: 273ms\tremaining: 3.68s\n",
      "138:\tlearn: 0.2184729\ttotal: 275ms\tremaining: 3.67s\n",
      "139:\tlearn: 0.2184562\ttotal: 276ms\tremaining: 3.67s\n",
      "140:\tlearn: 0.2184245\ttotal: 278ms\tremaining: 3.67s\n",
      "141:\tlearn: 0.2184066\ttotal: 280ms\tremaining: 3.67s\n",
      "142:\tlearn: 0.2183925\ttotal: 282ms\tremaining: 3.66s\n",
      "143:\tlearn: 0.2183554\ttotal: 284ms\tremaining: 3.66s\n",
      "144:\tlearn: 0.2183513\ttotal: 286ms\tremaining: 3.66s\n",
      "145:\tlearn: 0.2183223\ttotal: 288ms\tremaining: 3.66s\n",
      "146:\tlearn: 0.2182847\ttotal: 290ms\tremaining: 3.66s\n",
      "147:\tlearn: 0.2182644\ttotal: 292ms\tremaining: 3.65s\n",
      "148:\tlearn: 0.2182125\ttotal: 294ms\tremaining: 3.65s\n",
      "149:\tlearn: 0.2181958\ttotal: 296ms\tremaining: 3.65s\n",
      "150:\tlearn: 0.2181824\ttotal: 298ms\tremaining: 3.65s\n",
      "151:\tlearn: 0.2181278\ttotal: 300ms\tremaining: 3.65s\n",
      "152:\tlearn: 0.2181027\ttotal: 302ms\tremaining: 3.64s\n",
      "153:\tlearn: 0.2180800\ttotal: 304ms\tremaining: 3.64s\n",
      "154:\tlearn: 0.2180353\ttotal: 306ms\tremaining: 3.64s\n",
      "155:\tlearn: 0.2180084\ttotal: 308ms\tremaining: 3.64s\n",
      "156:\tlearn: 0.2179650\ttotal: 310ms\tremaining: 3.64s\n",
      "157:\tlearn: 0.2179480\ttotal: 312ms\tremaining: 3.63s\n",
      "158:\tlearn: 0.2179273\ttotal: 314ms\tremaining: 3.63s\n",
      "159:\tlearn: 0.2179106\ttotal: 316ms\tremaining: 3.63s\n",
      "160:\tlearn: 0.2178660\ttotal: 318ms\tremaining: 3.63s\n",
      "161:\tlearn: 0.2178406\ttotal: 319ms\tremaining: 3.62s\n",
      "162:\tlearn: 0.2177982\ttotal: 321ms\tremaining: 3.62s\n",
      "163:\tlearn: 0.2177737\ttotal: 323ms\tremaining: 3.62s\n",
      "164:\tlearn: 0.2177637\ttotal: 325ms\tremaining: 3.62s\n",
      "165:\tlearn: 0.2177180\ttotal: 327ms\tremaining: 3.61s\n",
      "166:\tlearn: 0.2176959\ttotal: 329ms\tremaining: 3.61s\n",
      "167:\tlearn: 0.2176840\ttotal: 331ms\tremaining: 3.61s\n",
      "168:\tlearn: 0.2176671\ttotal: 333ms\tremaining: 3.6s\n",
      "169:\tlearn: 0.2176352\ttotal: 335ms\tremaining: 3.6s\n",
      "170:\tlearn: 0.2176011\ttotal: 337ms\tremaining: 3.6s\n",
      "171:\tlearn: 0.2175816\ttotal: 338ms\tremaining: 3.6s\n",
      "172:\tlearn: 0.2175514\ttotal: 340ms\tremaining: 3.59s\n",
      "173:\tlearn: 0.2174861\ttotal: 342ms\tremaining: 3.59s\n",
      "174:\tlearn: 0.2174815\ttotal: 344ms\tremaining: 3.59s\n",
      "175:\tlearn: 0.2174310\ttotal: 346ms\tremaining: 3.59s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176:\tlearn: 0.2174178\ttotal: 349ms\tremaining: 3.59s\n",
      "177:\tlearn: 0.2173830\ttotal: 350ms\tremaining: 3.59s\n",
      "178:\tlearn: 0.2173656\ttotal: 352ms\tremaining: 3.58s\n",
      "179:\tlearn: 0.2173269\ttotal: 354ms\tremaining: 3.58s\n",
      "180:\tlearn: 0.2173126\ttotal: 356ms\tremaining: 3.58s\n",
      "181:\tlearn: 0.2172935\ttotal: 359ms\tremaining: 3.58s\n",
      "182:\tlearn: 0.2172765\ttotal: 361ms\tremaining: 3.58s\n",
      "183:\tlearn: 0.2172507\ttotal: 363ms\tremaining: 3.59s\n",
      "184:\tlearn: 0.2172074\ttotal: 366ms\tremaining: 3.59s\n",
      "185:\tlearn: 0.2171856\ttotal: 368ms\tremaining: 3.58s\n",
      "186:\tlearn: 0.2171508\ttotal: 370ms\tremaining: 3.58s\n",
      "187:\tlearn: 0.2170648\ttotal: 372ms\tremaining: 3.58s\n",
      "188:\tlearn: 0.2170266\ttotal: 374ms\tremaining: 3.58s\n",
      "189:\tlearn: 0.2170141\ttotal: 376ms\tremaining: 3.58s\n",
      "190:\tlearn: 0.2169870\ttotal: 378ms\tremaining: 3.58s\n",
      "191:\tlearn: 0.2169708\ttotal: 380ms\tremaining: 3.57s\n",
      "192:\tlearn: 0.2169224\ttotal: 382ms\tremaining: 3.57s\n",
      "193:\tlearn: 0.2168401\ttotal: 383ms\tremaining: 3.57s\n",
      "194:\tlearn: 0.2168061\ttotal: 385ms\tremaining: 3.57s\n",
      "195:\tlearn: 0.2167366\ttotal: 387ms\tremaining: 3.56s\n",
      "196:\tlearn: 0.2167066\ttotal: 389ms\tremaining: 3.56s\n",
      "197:\tlearn: 0.2166545\ttotal: 391ms\tremaining: 3.56s\n",
      "198:\tlearn: 0.2166246\ttotal: 393ms\tremaining: 3.56s\n",
      "199:\tlearn: 0.2166035\ttotal: 395ms\tremaining: 3.56s\n",
      "200:\tlearn: 0.2165677\ttotal: 397ms\tremaining: 3.56s\n",
      "201:\tlearn: 0.2165554\ttotal: 399ms\tremaining: 3.55s\n",
      "202:\tlearn: 0.2165486\ttotal: 401ms\tremaining: 3.55s\n",
      "203:\tlearn: 0.2165098\ttotal: 403ms\tremaining: 3.55s\n",
      "204:\tlearn: 0.2164824\ttotal: 405ms\tremaining: 3.55s\n",
      "205:\tlearn: 0.2164519\ttotal: 407ms\tremaining: 3.54s\n",
      "206:\tlearn: 0.2164247\ttotal: 409ms\tremaining: 3.54s\n",
      "207:\tlearn: 0.2164049\ttotal: 411ms\tremaining: 3.54s\n",
      "208:\tlearn: 0.2163669\ttotal: 413ms\tremaining: 3.54s\n",
      "209:\tlearn: 0.2163187\ttotal: 415ms\tremaining: 3.54s\n",
      "210:\tlearn: 0.2163011\ttotal: 417ms\tremaining: 3.53s\n",
      "211:\tlearn: 0.2162735\ttotal: 419ms\tremaining: 3.53s\n",
      "212:\tlearn: 0.2162121\ttotal: 421ms\tremaining: 3.53s\n",
      "213:\tlearn: 0.2161786\ttotal: 423ms\tremaining: 3.53s\n",
      "214:\tlearn: 0.2161334\ttotal: 425ms\tremaining: 3.52s\n",
      "215:\tlearn: 0.2160836\ttotal: 427ms\tremaining: 3.52s\n",
      "216:\tlearn: 0.2160280\ttotal: 429ms\tremaining: 3.52s\n",
      "217:\tlearn: 0.2160023\ttotal: 431ms\tremaining: 3.52s\n",
      "218:\tlearn: 0.2159858\ttotal: 432ms\tremaining: 3.52s\n",
      "219:\tlearn: 0.2159612\ttotal: 434ms\tremaining: 3.51s\n",
      "220:\tlearn: 0.2159204\ttotal: 436ms\tremaining: 3.51s\n",
      "221:\tlearn: 0.2158748\ttotal: 438ms\tremaining: 3.51s\n",
      "222:\tlearn: 0.2158444\ttotal: 440ms\tremaining: 3.51s\n",
      "223:\tlearn: 0.2158130\ttotal: 442ms\tremaining: 3.51s\n",
      "224:\tlearn: 0.2157911\ttotal: 444ms\tremaining: 3.5s\n",
      "225:\tlearn: 0.2157828\ttotal: 446ms\tremaining: 3.5s\n",
      "226:\tlearn: 0.2157545\ttotal: 448ms\tremaining: 3.5s\n",
      "227:\tlearn: 0.2157292\ttotal: 450ms\tremaining: 3.5s\n",
      "228:\tlearn: 0.2156915\ttotal: 452ms\tremaining: 3.5s\n",
      "229:\tlearn: 0.2156239\ttotal: 454ms\tremaining: 3.5s\n",
      "230:\tlearn: 0.2155365\ttotal: 456ms\tremaining: 3.49s\n",
      "231:\tlearn: 0.2154995\ttotal: 458ms\tremaining: 3.49s\n",
      "232:\tlearn: 0.2154394\ttotal: 460ms\tremaining: 3.49s\n",
      "233:\tlearn: 0.2153986\ttotal: 462ms\tremaining: 3.49s\n",
      "234:\tlearn: 0.2153413\ttotal: 464ms\tremaining: 3.49s\n",
      "235:\tlearn: 0.2153293\ttotal: 466ms\tremaining: 3.48s\n",
      "236:\tlearn: 0.2153185\ttotal: 468ms\tremaining: 3.48s\n",
      "237:\tlearn: 0.2152882\ttotal: 470ms\tremaining: 3.48s\n",
      "238:\tlearn: 0.2152697\ttotal: 472ms\tremaining: 3.48s\n",
      "239:\tlearn: 0.2152356\ttotal: 474ms\tremaining: 3.48s\n",
      "240:\tlearn: 0.2151960\ttotal: 476ms\tremaining: 3.47s\n",
      "241:\tlearn: 0.2151736\ttotal: 478ms\tremaining: 3.47s\n",
      "242:\tlearn: 0.2151024\ttotal: 480ms\tremaining: 3.47s\n",
      "243:\tlearn: 0.2150649\ttotal: 482ms\tremaining: 3.47s\n",
      "244:\tlearn: 0.2150575\ttotal: 484ms\tremaining: 3.46s\n",
      "245:\tlearn: 0.2150341\ttotal: 486ms\tremaining: 3.46s\n",
      "246:\tlearn: 0.2149894\ttotal: 488ms\tremaining: 3.46s\n",
      "247:\tlearn: 0.2149820\ttotal: 490ms\tremaining: 3.46s\n",
      "248:\tlearn: 0.2149522\ttotal: 491ms\tremaining: 3.46s\n",
      "249:\tlearn: 0.2149021\ttotal: 497ms\tremaining: 3.48s\n",
      "250:\tlearn: 0.2148615\ttotal: 499ms\tremaining: 3.48s\n",
      "251:\tlearn: 0.2148099\ttotal: 501ms\tremaining: 3.48s\n",
      "252:\tlearn: 0.2147837\ttotal: 503ms\tremaining: 3.47s\n",
      "253:\tlearn: 0.2147399\ttotal: 505ms\tremaining: 3.47s\n",
      "254:\tlearn: 0.2147030\ttotal: 507ms\tremaining: 3.47s\n",
      "255:\tlearn: 0.2146773\ttotal: 509ms\tremaining: 3.46s\n",
      "256:\tlearn: 0.2146624\ttotal: 511ms\tremaining: 3.46s\n",
      "257:\tlearn: 0.2146241\ttotal: 512ms\tremaining: 3.46s\n",
      "258:\tlearn: 0.2145766\ttotal: 514ms\tremaining: 3.46s\n",
      "259:\tlearn: 0.2145605\ttotal: 516ms\tremaining: 3.46s\n",
      "260:\tlearn: 0.2145076\ttotal: 518ms\tremaining: 3.45s\n",
      "261:\tlearn: 0.2144665\ttotal: 520ms\tremaining: 3.45s\n",
      "262:\tlearn: 0.2144414\ttotal: 522ms\tremaining: 3.45s\n",
      "263:\tlearn: 0.2144286\ttotal: 525ms\tremaining: 3.45s\n",
      "264:\tlearn: 0.2144120\ttotal: 527ms\tremaining: 3.45s\n",
      "265:\tlearn: 0.2143657\ttotal: 529ms\tremaining: 3.45s\n",
      "266:\tlearn: 0.2143432\ttotal: 531ms\tremaining: 3.44s\n",
      "267:\tlearn: 0.2143013\ttotal: 533ms\tremaining: 3.44s\n",
      "268:\tlearn: 0.2142658\ttotal: 535ms\tremaining: 3.44s\n",
      "269:\tlearn: 0.2142318\ttotal: 537ms\tremaining: 3.44s\n",
      "270:\tlearn: 0.2141419\ttotal: 539ms\tremaining: 3.44s\n",
      "271:\tlearn: 0.2141270\ttotal: 541ms\tremaining: 3.44s\n",
      "272:\tlearn: 0.2140975\ttotal: 543ms\tremaining: 3.43s\n",
      "273:\tlearn: 0.2140528\ttotal: 545ms\tremaining: 3.43s\n",
      "274:\tlearn: 0.2139939\ttotal: 547ms\tremaining: 3.43s\n",
      "275:\tlearn: 0.2139399\ttotal: 549ms\tremaining: 3.43s\n",
      "276:\tlearn: 0.2139167\ttotal: 551ms\tremaining: 3.42s\n",
      "277:\tlearn: 0.2138806\ttotal: 553ms\tremaining: 3.42s\n",
      "278:\tlearn: 0.2138368\ttotal: 555ms\tremaining: 3.42s\n",
      "279:\tlearn: 0.2138105\ttotal: 557ms\tremaining: 3.42s\n",
      "280:\tlearn: 0.2137912\ttotal: 558ms\tremaining: 3.42s\n",
      "281:\tlearn: 0.2137586\ttotal: 560ms\tremaining: 3.41s\n",
      "282:\tlearn: 0.2137385\ttotal: 562ms\tremaining: 3.41s\n",
      "283:\tlearn: 0.2136933\ttotal: 564ms\tremaining: 3.41s\n",
      "284:\tlearn: 0.2136723\ttotal: 566ms\tremaining: 3.41s\n",
      "285:\tlearn: 0.2136412\ttotal: 568ms\tremaining: 3.41s\n",
      "286:\tlearn: 0.2135939\ttotal: 570ms\tremaining: 3.4s\n",
      "287:\tlearn: 0.2135670\ttotal: 572ms\tremaining: 3.4s\n",
      "288:\tlearn: 0.2134974\ttotal: 575ms\tremaining: 3.4s\n",
      "289:\tlearn: 0.2134790\ttotal: 577ms\tremaining: 3.4s\n",
      "290:\tlearn: 0.2134300\ttotal: 579ms\tremaining: 3.4s\n",
      "291:\tlearn: 0.2133983\ttotal: 581ms\tremaining: 3.4s\n",
      "292:\tlearn: 0.2133715\ttotal: 583ms\tremaining: 3.4s\n",
      "293:\tlearn: 0.2133574\ttotal: 585ms\tremaining: 3.39s\n",
      "294:\tlearn: 0.2133359\ttotal: 587ms\tremaining: 3.39s\n",
      "295:\tlearn: 0.2132968\ttotal: 589ms\tremaining: 3.39s\n",
      "296:\tlearn: 0.2132375\ttotal: 591ms\tremaining: 3.39s\n",
      "297:\tlearn: 0.2132130\ttotal: 593ms\tremaining: 3.38s\n",
      "298:\tlearn: 0.2131726\ttotal: 595ms\tremaining: 3.38s\n",
      "299:\tlearn: 0.2131165\ttotal: 597ms\tremaining: 3.38s\n",
      "300:\tlearn: 0.2130794\ttotal: 599ms\tremaining: 3.38s\n",
      "301:\tlearn: 0.2130469\ttotal: 601ms\tremaining: 3.38s\n",
      "302:\tlearn: 0.2130277\ttotal: 602ms\tremaining: 3.37s\n",
      "303:\tlearn: 0.2129876\ttotal: 604ms\tremaining: 3.37s\n",
      "304:\tlearn: 0.2129238\ttotal: 606ms\tremaining: 3.37s\n",
      "305:\tlearn: 0.2128906\ttotal: 608ms\tremaining: 3.37s\n",
      "306:\tlearn: 0.2128698\ttotal: 610ms\tremaining: 3.36s\n",
      "307:\tlearn: 0.2128184\ttotal: 612ms\tremaining: 3.36s\n",
      "308:\tlearn: 0.2127855\ttotal: 614ms\tremaining: 3.36s\n",
      "309:\tlearn: 0.2127707\ttotal: 616ms\tremaining: 3.36s\n",
      "310:\tlearn: 0.2126967\ttotal: 618ms\tremaining: 3.36s\n",
      "311:\tlearn: 0.2126443\ttotal: 620ms\tremaining: 3.36s\n",
      "312:\tlearn: 0.2125754\ttotal: 622ms\tremaining: 3.35s\n",
      "313:\tlearn: 0.2125453\ttotal: 624ms\tremaining: 3.35s\n",
      "314:\tlearn: 0.2125247\ttotal: 626ms\tremaining: 3.35s\n",
      "315:\tlearn: 0.2124900\ttotal: 628ms\tremaining: 3.35s\n",
      "316:\tlearn: 0.2124499\ttotal: 630ms\tremaining: 3.35s\n",
      "317:\tlearn: 0.2123889\ttotal: 632ms\tremaining: 3.34s\n",
      "318:\tlearn: 0.2123282\ttotal: 634ms\tremaining: 3.34s\n",
      "319:\tlearn: 0.2123155\ttotal: 636ms\tremaining: 3.34s\n",
      "320:\tlearn: 0.2122992\ttotal: 638ms\tremaining: 3.33s\n",
      "321:\tlearn: 0.2122575\ttotal: 640ms\tremaining: 3.33s\n",
      "322:\tlearn: 0.2122481\ttotal: 642ms\tremaining: 3.33s\n",
      "323:\tlearn: 0.2122284\ttotal: 644ms\tremaining: 3.33s\n",
      "324:\tlearn: 0.2122167\ttotal: 646ms\tremaining: 3.33s\n",
      "325:\tlearn: 0.2121975\ttotal: 648ms\tremaining: 3.33s\n",
      "326:\tlearn: 0.2121279\ttotal: 649ms\tremaining: 3.32s\n",
      "327:\tlearn: 0.2120985\ttotal: 651ms\tremaining: 3.32s\n",
      "328:\tlearn: 0.2120683\ttotal: 653ms\tremaining: 3.32s\n",
      "329:\tlearn: 0.2120539\ttotal: 655ms\tremaining: 3.32s\n",
      "330:\tlearn: 0.2120108\ttotal: 657ms\tremaining: 3.31s\n",
      "331:\tlearn: 0.2119878\ttotal: 659ms\tremaining: 3.31s\n",
      "332:\tlearn: 0.2119413\ttotal: 661ms\tremaining: 3.31s\n",
      "333:\tlearn: 0.2118845\ttotal: 663ms\tremaining: 3.31s\n",
      "334:\tlearn: 0.2118533\ttotal: 665ms\tremaining: 3.31s\n",
      "335:\tlearn: 0.2118351\ttotal: 667ms\tremaining: 3.31s\n",
      "336:\tlearn: 0.2117879\ttotal: 669ms\tremaining: 3.3s\n",
      "337:\tlearn: 0.2117692\ttotal: 671ms\tremaining: 3.3s\n",
      "338:\tlearn: 0.2117581\ttotal: 673ms\tremaining: 3.3s\n",
      "339:\tlearn: 0.2117343\ttotal: 675ms\tremaining: 3.3s\n",
      "340:\tlearn: 0.2116867\ttotal: 677ms\tremaining: 3.29s\n",
      "341:\tlearn: 0.2116498\ttotal: 679ms\tremaining: 3.29s\n",
      "342:\tlearn: 0.2116257\ttotal: 681ms\tremaining: 3.29s\n",
      "343:\tlearn: 0.2115691\ttotal: 683ms\tremaining: 3.29s\n",
      "344:\tlearn: 0.2115150\ttotal: 685ms\tremaining: 3.29s\n",
      "345:\tlearn: 0.2114476\ttotal: 687ms\tremaining: 3.28s\n",
      "346:\tlearn: 0.2113904\ttotal: 689ms\tremaining: 3.28s\n",
      "347:\tlearn: 0.2113706\ttotal: 691ms\tremaining: 3.28s\n",
      "348:\tlearn: 0.2113452\ttotal: 693ms\tremaining: 3.28s\n",
      "349:\tlearn: 0.2112968\ttotal: 696ms\tremaining: 3.28s\n",
      "350:\tlearn: 0.2112523\ttotal: 698ms\tremaining: 3.28s\n",
      "351:\tlearn: 0.2112099\ttotal: 700ms\tremaining: 3.28s\n",
      "352:\tlearn: 0.2111642\ttotal: 702ms\tremaining: 3.27s\n",
      "353:\tlearn: 0.2111249\ttotal: 704ms\tremaining: 3.27s\n",
      "354:\tlearn: 0.2111006\ttotal: 706ms\tremaining: 3.27s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355:\tlearn: 0.2110624\ttotal: 708ms\tremaining: 3.27s\n",
      "356:\tlearn: 0.2110042\ttotal: 710ms\tremaining: 3.27s\n",
      "357:\tlearn: 0.2109817\ttotal: 712ms\tremaining: 3.27s\n",
      "358:\tlearn: 0.2109324\ttotal: 714ms\tremaining: 3.27s\n",
      "359:\tlearn: 0.2108885\ttotal: 716ms\tremaining: 3.26s\n",
      "360:\tlearn: 0.2108660\ttotal: 718ms\tremaining: 3.26s\n",
      "361:\tlearn: 0.2108483\ttotal: 720ms\tremaining: 3.26s\n",
      "362:\tlearn: 0.2108069\ttotal: 722ms\tremaining: 3.26s\n",
      "363:\tlearn: 0.2107455\ttotal: 725ms\tremaining: 3.26s\n",
      "364:\tlearn: 0.2106876\ttotal: 727ms\tremaining: 3.25s\n",
      "365:\tlearn: 0.2106664\ttotal: 729ms\tremaining: 3.25s\n",
      "366:\tlearn: 0.2106300\ttotal: 731ms\tremaining: 3.25s\n",
      "367:\tlearn: 0.2106159\ttotal: 733ms\tremaining: 3.25s\n",
      "368:\tlearn: 0.2105729\ttotal: 735ms\tremaining: 3.25s\n",
      "369:\tlearn: 0.2105384\ttotal: 737ms\tremaining: 3.25s\n",
      "370:\tlearn: 0.2105164\ttotal: 739ms\tremaining: 3.24s\n",
      "371:\tlearn: 0.2104997\ttotal: 741ms\tremaining: 3.24s\n",
      "372:\tlearn: 0.2104685\ttotal: 743ms\tremaining: 3.24s\n",
      "373:\tlearn: 0.2104310\ttotal: 745ms\tremaining: 3.24s\n",
      "374:\tlearn: 0.2104189\ttotal: 747ms\tremaining: 3.24s\n",
      "375:\tlearn: 0.2103767\ttotal: 749ms\tremaining: 3.23s\n",
      "376:\tlearn: 0.2103588\ttotal: 751ms\tremaining: 3.23s\n",
      "377:\tlearn: 0.2103234\ttotal: 753ms\tremaining: 3.23s\n",
      "378:\tlearn: 0.2103039\ttotal: 755ms\tremaining: 3.23s\n",
      "379:\tlearn: 0.2102905\ttotal: 757ms\tremaining: 3.23s\n",
      "380:\tlearn: 0.2102702\ttotal: 759ms\tremaining: 3.22s\n",
      "381:\tlearn: 0.2102488\ttotal: 761ms\tremaining: 3.22s\n",
      "382:\tlearn: 0.2102142\ttotal: 763ms\tremaining: 3.22s\n",
      "383:\tlearn: 0.2101689\ttotal: 765ms\tremaining: 3.22s\n",
      "384:\tlearn: 0.2101336\ttotal: 767ms\tremaining: 3.21s\n",
      "385:\tlearn: 0.2101015\ttotal: 769ms\tremaining: 3.21s\n",
      "386:\tlearn: 0.2100311\ttotal: 771ms\tremaining: 3.21s\n",
      "387:\tlearn: 0.2100180\ttotal: 773ms\tremaining: 3.21s\n",
      "388:\tlearn: 0.2099965\ttotal: 775ms\tremaining: 3.21s\n",
      "389:\tlearn: 0.2099583\ttotal: 777ms\tremaining: 3.21s\n",
      "390:\tlearn: 0.2099348\ttotal: 779ms\tremaining: 3.2s\n",
      "391:\tlearn: 0.2099213\ttotal: 781ms\tremaining: 3.2s\n",
      "392:\tlearn: 0.2098855\ttotal: 782ms\tremaining: 3.2s\n",
      "393:\tlearn: 0.2098257\ttotal: 784ms\tremaining: 3.2s\n",
      "394:\tlearn: 0.2098095\ttotal: 786ms\tremaining: 3.19s\n",
      "395:\tlearn: 0.2097970\ttotal: 788ms\tremaining: 3.19s\n",
      "396:\tlearn: 0.2097738\ttotal: 790ms\tremaining: 3.19s\n",
      "397:\tlearn: 0.2097178\ttotal: 792ms\tremaining: 3.19s\n",
      "398:\tlearn: 0.2096468\ttotal: 794ms\tremaining: 3.19s\n",
      "399:\tlearn: 0.2096155\ttotal: 796ms\tremaining: 3.18s\n",
      "400:\tlearn: 0.2095777\ttotal: 798ms\tremaining: 3.18s\n",
      "401:\tlearn: 0.2095368\ttotal: 800ms\tremaining: 3.18s\n",
      "402:\tlearn: 0.2095162\ttotal: 802ms\tremaining: 3.18s\n",
      "403:\tlearn: 0.2094736\ttotal: 804ms\tremaining: 3.18s\n",
      "404:\tlearn: 0.2094608\ttotal: 806ms\tremaining: 3.17s\n",
      "405:\tlearn: 0.2094150\ttotal: 808ms\tremaining: 3.17s\n",
      "406:\tlearn: 0.2094002\ttotal: 810ms\tremaining: 3.17s\n",
      "407:\tlearn: 0.2093710\ttotal: 812ms\tremaining: 3.17s\n",
      "408:\tlearn: 0.2093219\ttotal: 814ms\tremaining: 3.17s\n",
      "409:\tlearn: 0.2092860\ttotal: 816ms\tremaining: 3.17s\n",
      "410:\tlearn: 0.2092503\ttotal: 818ms\tremaining: 3.16s\n",
      "411:\tlearn: 0.2091876\ttotal: 821ms\tremaining: 3.16s\n",
      "412:\tlearn: 0.2091583\ttotal: 823ms\tremaining: 3.16s\n",
      "413:\tlearn: 0.2090963\ttotal: 825ms\tremaining: 3.16s\n",
      "414:\tlearn: 0.2090730\ttotal: 827ms\tremaining: 3.16s\n",
      "415:\tlearn: 0.2090116\ttotal: 829ms\tremaining: 3.16s\n",
      "416:\tlearn: 0.2089817\ttotal: 831ms\tremaining: 3.15s\n",
      "417:\tlearn: 0.2089436\ttotal: 833ms\tremaining: 3.15s\n",
      "418:\tlearn: 0.2088850\ttotal: 835ms\tremaining: 3.15s\n",
      "419:\tlearn: 0.2088290\ttotal: 838ms\tremaining: 3.15s\n",
      "420:\tlearn: 0.2087872\ttotal: 840ms\tremaining: 3.15s\n",
      "421:\tlearn: 0.2087659\ttotal: 842ms\tremaining: 3.15s\n",
      "422:\tlearn: 0.2087312\ttotal: 844ms\tremaining: 3.15s\n",
      "423:\tlearn: 0.2087109\ttotal: 846ms\tremaining: 3.14s\n",
      "424:\tlearn: 0.2086991\ttotal: 848ms\tremaining: 3.14s\n",
      "425:\tlearn: 0.2086864\ttotal: 850ms\tremaining: 3.14s\n",
      "426:\tlearn: 0.2086536\ttotal: 852ms\tremaining: 3.14s\n",
      "427:\tlearn: 0.2086259\ttotal: 854ms\tremaining: 3.14s\n",
      "428:\tlearn: 0.2086033\ttotal: 856ms\tremaining: 3.13s\n",
      "429:\tlearn: 0.2085912\ttotal: 858ms\tremaining: 3.13s\n",
      "430:\tlearn: 0.2085352\ttotal: 860ms\tremaining: 3.13s\n",
      "431:\tlearn: 0.2085093\ttotal: 862ms\tremaining: 3.13s\n",
      "432:\tlearn: 0.2084704\ttotal: 864ms\tremaining: 3.13s\n",
      "433:\tlearn: 0.2084285\ttotal: 866ms\tremaining: 3.13s\n",
      "434:\tlearn: 0.2083751\ttotal: 869ms\tremaining: 3.13s\n",
      "435:\tlearn: 0.2083434\ttotal: 871ms\tremaining: 3.12s\n",
      "436:\tlearn: 0.2083170\ttotal: 873ms\tremaining: 3.12s\n",
      "437:\tlearn: 0.2082990\ttotal: 875ms\tremaining: 3.12s\n",
      "438:\tlearn: 0.2082340\ttotal: 877ms\tremaining: 3.12s\n",
      "439:\tlearn: 0.2081886\ttotal: 879ms\tremaining: 3.12s\n",
      "440:\tlearn: 0.2081442\ttotal: 881ms\tremaining: 3.11s\n",
      "441:\tlearn: 0.2081248\ttotal: 883ms\tremaining: 3.11s\n",
      "442:\tlearn: 0.2081074\ttotal: 885ms\tremaining: 3.11s\n",
      "443:\tlearn: 0.2080751\ttotal: 888ms\tremaining: 3.11s\n",
      "444:\tlearn: 0.2080120\ttotal: 890ms\tremaining: 3.11s\n",
      "445:\tlearn: 0.2079717\ttotal: 892ms\tremaining: 3.11s\n",
      "446:\tlearn: 0.2079629\ttotal: 895ms\tremaining: 3.11s\n",
      "447:\tlearn: 0.2079514\ttotal: 897ms\tremaining: 3.11s\n",
      "448:\tlearn: 0.2079263\ttotal: 900ms\tremaining: 3.11s\n",
      "449:\tlearn: 0.2079159\ttotal: 902ms\tremaining: 3.11s\n",
      "450:\tlearn: 0.2078868\ttotal: 904ms\tremaining: 3.1s\n",
      "451:\tlearn: 0.2078607\ttotal: 906ms\tremaining: 3.1s\n",
      "452:\tlearn: 0.2078220\ttotal: 908ms\tremaining: 3.1s\n",
      "453:\tlearn: 0.2078039\ttotal: 910ms\tremaining: 3.1s\n",
      "454:\tlearn: 0.2077530\ttotal: 912ms\tremaining: 3.1s\n",
      "455:\tlearn: 0.2077245\ttotal: 914ms\tremaining: 3.1s\n",
      "456:\tlearn: 0.2076881\ttotal: 917ms\tremaining: 3.1s\n",
      "457:\tlearn: 0.2076456\ttotal: 919ms\tremaining: 3.09s\n",
      "458:\tlearn: 0.2076125\ttotal: 921ms\tremaining: 3.09s\n",
      "459:\tlearn: 0.2075956\ttotal: 924ms\tremaining: 3.09s\n",
      "460:\tlearn: 0.2075812\ttotal: 926ms\tremaining: 3.09s\n",
      "461:\tlearn: 0.2075494\ttotal: 928ms\tremaining: 3.09s\n",
      "462:\tlearn: 0.2075047\ttotal: 929ms\tremaining: 3.08s\n",
      "463:\tlearn: 0.2074693\ttotal: 932ms\tremaining: 3.08s\n",
      "464:\tlearn: 0.2074386\ttotal: 934ms\tremaining: 3.08s\n",
      "465:\tlearn: 0.2074312\ttotal: 936ms\tremaining: 3.08s\n",
      "466:\tlearn: 0.2073804\ttotal: 938ms\tremaining: 3.08s\n",
      "467:\tlearn: 0.2073694\ttotal: 940ms\tremaining: 3.08s\n",
      "468:\tlearn: 0.2073358\ttotal: 942ms\tremaining: 3.08s\n",
      "469:\tlearn: 0.2072982\ttotal: 944ms\tremaining: 3.07s\n",
      "470:\tlearn: 0.2072713\ttotal: 946ms\tremaining: 3.07s\n",
      "471:\tlearn: 0.2072627\ttotal: 948ms\tremaining: 3.07s\n",
      "472:\tlearn: 0.2072522\ttotal: 950ms\tremaining: 3.07s\n",
      "473:\tlearn: 0.2072366\ttotal: 952ms\tremaining: 3.07s\n",
      "474:\tlearn: 0.2071952\ttotal: 954ms\tremaining: 3.06s\n",
      "475:\tlearn: 0.2071853\ttotal: 956ms\tremaining: 3.06s\n",
      "476:\tlearn: 0.2071568\ttotal: 958ms\tremaining: 3.06s\n",
      "477:\tlearn: 0.2071154\ttotal: 960ms\tremaining: 3.06s\n",
      "478:\tlearn: 0.2071049\ttotal: 962ms\tremaining: 3.05s\n",
      "479:\tlearn: 0.2070641\ttotal: 964ms\tremaining: 3.05s\n",
      "480:\tlearn: 0.2070246\ttotal: 967ms\tremaining: 3.05s\n",
      "481:\tlearn: 0.2069840\ttotal: 969ms\tremaining: 3.05s\n",
      "482:\tlearn: 0.2069672\ttotal: 971ms\tremaining: 3.05s\n",
      "483:\tlearn: 0.2069350\ttotal: 973ms\tremaining: 3.05s\n",
      "484:\tlearn: 0.2068985\ttotal: 975ms\tremaining: 3.04s\n",
      "485:\tlearn: 0.2068725\ttotal: 977ms\tremaining: 3.04s\n",
      "486:\tlearn: 0.2068333\ttotal: 979ms\tremaining: 3.04s\n",
      "487:\tlearn: 0.2067883\ttotal: 981ms\tremaining: 3.04s\n",
      "488:\tlearn: 0.2067492\ttotal: 983ms\tremaining: 3.04s\n",
      "489:\tlearn: 0.2067118\ttotal: 985ms\tremaining: 3.04s\n",
      "490:\tlearn: 0.2066810\ttotal: 987ms\tremaining: 3.03s\n",
      "491:\tlearn: 0.2066681\ttotal: 989ms\tremaining: 3.03s\n",
      "492:\tlearn: 0.2066443\ttotal: 991ms\tremaining: 3.03s\n",
      "493:\tlearn: 0.2065939\ttotal: 993ms\tremaining: 3.03s\n",
      "494:\tlearn: 0.2065635\ttotal: 995ms\tremaining: 3.02s\n",
      "495:\tlearn: 0.2065282\ttotal: 997ms\tremaining: 3.02s\n",
      "496:\tlearn: 0.2065169\ttotal: 1000ms\tremaining: 3.02s\n",
      "497:\tlearn: 0.2065139\ttotal: 1s\tremaining: 3.02s\n",
      "498:\tlearn: 0.2064644\ttotal: 1s\tremaining: 3.02s\n",
      "499:\tlearn: 0.2064397\ttotal: 1.01s\tremaining: 3.02s\n",
      "500:\tlearn: 0.2064269\ttotal: 1.01s\tremaining: 3.02s\n",
      "501:\tlearn: 0.2063898\ttotal: 1.01s\tremaining: 3.02s\n",
      "502:\tlearn: 0.2063612\ttotal: 1.01s\tremaining: 3.01s\n",
      "503:\tlearn: 0.2063077\ttotal: 1.01s\tremaining: 3.01s\n",
      "504:\tlearn: 0.2062954\ttotal: 1.02s\tremaining: 3.01s\n",
      "505:\tlearn: 0.2062714\ttotal: 1.02s\tremaining: 3.01s\n",
      "506:\tlearn: 0.2062511\ttotal: 1.02s\tremaining: 3.01s\n",
      "507:\tlearn: 0.2062276\ttotal: 1.02s\tremaining: 3s\n",
      "508:\tlearn: 0.2062037\ttotal: 1.02s\tremaining: 3s\n",
      "509:\tlearn: 0.2061877\ttotal: 1.03s\tremaining: 3s\n",
      "510:\tlearn: 0.2061528\ttotal: 1.03s\tremaining: 3s\n",
      "511:\tlearn: 0.2061445\ttotal: 1.03s\tremaining: 3s\n",
      "512:\tlearn: 0.2061202\ttotal: 1.03s\tremaining: 3s\n",
      "513:\tlearn: 0.2060983\ttotal: 1.04s\tremaining: 3s\n",
      "514:\tlearn: 0.2060869\ttotal: 1.04s\tremaining: 2.99s\n",
      "515:\tlearn: 0.2060680\ttotal: 1.04s\tremaining: 2.99s\n",
      "516:\tlearn: 0.2060602\ttotal: 1.04s\tremaining: 2.99s\n",
      "517:\tlearn: 0.2060264\ttotal: 1.04s\tremaining: 2.99s\n",
      "518:\tlearn: 0.2060187\ttotal: 1.05s\tremaining: 2.99s\n",
      "519:\tlearn: 0.2060104\ttotal: 1.05s\tremaining: 2.98s\n",
      "520:\tlearn: 0.2059809\ttotal: 1.05s\tremaining: 2.98s\n",
      "521:\tlearn: 0.2059586\ttotal: 1.05s\tremaining: 2.98s\n",
      "522:\tlearn: 0.2059415\ttotal: 1.05s\tremaining: 2.98s\n",
      "523:\tlearn: 0.2059004\ttotal: 1.06s\tremaining: 2.97s\n",
      "524:\tlearn: 0.2058590\ttotal: 1.06s\tremaining: 2.97s\n",
      "525:\tlearn: 0.2058260\ttotal: 1.06s\tremaining: 2.97s\n",
      "526:\tlearn: 0.2057852\ttotal: 1.06s\tremaining: 2.97s\n",
      "527:\tlearn: 0.2057480\ttotal: 1.06s\tremaining: 2.97s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528:\tlearn: 0.2057086\ttotal: 1.07s\tremaining: 2.97s\n",
      "529:\tlearn: 0.2056865\ttotal: 1.07s\tremaining: 2.96s\n",
      "530:\tlearn: 0.2056627\ttotal: 1.07s\tremaining: 2.96s\n",
      "531:\tlearn: 0.2056260\ttotal: 1.07s\tremaining: 2.96s\n",
      "532:\tlearn: 0.2055777\ttotal: 1.07s\tremaining: 2.96s\n",
      "533:\tlearn: 0.2055614\ttotal: 1.08s\tremaining: 2.96s\n",
      "534:\tlearn: 0.2055267\ttotal: 1.08s\tremaining: 2.96s\n",
      "535:\tlearn: 0.2054930\ttotal: 1.08s\tremaining: 2.96s\n",
      "536:\tlearn: 0.2054819\ttotal: 1.08s\tremaining: 2.95s\n",
      "537:\tlearn: 0.2054300\ttotal: 1.09s\tremaining: 2.96s\n",
      "538:\tlearn: 0.2053871\ttotal: 1.09s\tremaining: 2.96s\n",
      "539:\tlearn: 0.2053505\ttotal: 1.09s\tremaining: 2.96s\n",
      "540:\tlearn: 0.2053153\ttotal: 1.09s\tremaining: 2.95s\n",
      "541:\tlearn: 0.2052862\ttotal: 1.1s\tremaining: 2.95s\n",
      "542:\tlearn: 0.2052324\ttotal: 1.1s\tremaining: 2.95s\n",
      "543:\tlearn: 0.2051991\ttotal: 1.1s\tremaining: 2.95s\n",
      "544:\tlearn: 0.2051757\ttotal: 1.1s\tremaining: 2.95s\n",
      "545:\tlearn: 0.2051348\ttotal: 1.1s\tremaining: 2.94s\n",
      "546:\tlearn: 0.2050864\ttotal: 1.11s\tremaining: 2.94s\n",
      "547:\tlearn: 0.2050450\ttotal: 1.11s\tremaining: 2.94s\n",
      "548:\tlearn: 0.2049953\ttotal: 1.11s\tremaining: 2.94s\n",
      "549:\tlearn: 0.2049532\ttotal: 1.11s\tremaining: 2.94s\n",
      "550:\tlearn: 0.2049140\ttotal: 1.12s\tremaining: 2.94s\n",
      "551:\tlearn: 0.2048614\ttotal: 1.12s\tremaining: 2.94s\n",
      "552:\tlearn: 0.2048245\ttotal: 1.12s\tremaining: 2.93s\n",
      "553:\tlearn: 0.2047961\ttotal: 1.12s\tremaining: 2.93s\n",
      "554:\tlearn: 0.2047888\ttotal: 1.13s\tremaining: 2.93s\n",
      "555:\tlearn: 0.2047739\ttotal: 1.13s\tremaining: 2.93s\n",
      "556:\tlearn: 0.2047665\ttotal: 1.13s\tremaining: 2.93s\n",
      "557:\tlearn: 0.2047514\ttotal: 1.13s\tremaining: 2.92s\n",
      "558:\tlearn: 0.2047229\ttotal: 1.13s\tremaining: 2.92s\n",
      "559:\tlearn: 0.2047001\ttotal: 1.14s\tremaining: 2.92s\n",
      "560:\tlearn: 0.2046795\ttotal: 1.14s\tremaining: 2.92s\n",
      "561:\tlearn: 0.2046320\ttotal: 1.14s\tremaining: 2.92s\n",
      "562:\tlearn: 0.2046019\ttotal: 1.14s\tremaining: 2.91s\n",
      "563:\tlearn: 0.2045921\ttotal: 1.14s\tremaining: 2.91s\n",
      "564:\tlearn: 0.2045522\ttotal: 1.15s\tremaining: 2.91s\n",
      "565:\tlearn: 0.2045127\ttotal: 1.15s\tremaining: 2.91s\n",
      "566:\tlearn: 0.2044643\ttotal: 1.15s\tremaining: 2.9s\n",
      "567:\tlearn: 0.2044312\ttotal: 1.15s\tremaining: 2.9s\n",
      "568:\tlearn: 0.2043948\ttotal: 1.15s\tremaining: 2.9s\n",
      "569:\tlearn: 0.2043680\ttotal: 1.16s\tremaining: 2.9s\n",
      "570:\tlearn: 0.2043167\ttotal: 1.16s\tremaining: 2.9s\n",
      "571:\tlearn: 0.2042708\ttotal: 1.16s\tremaining: 2.89s\n",
      "572:\tlearn: 0.2042208\ttotal: 1.16s\tremaining: 2.89s\n",
      "573:\tlearn: 0.2041771\ttotal: 1.16s\tremaining: 2.89s\n",
      "574:\tlearn: 0.2041518\ttotal: 1.17s\tremaining: 2.89s\n",
      "575:\tlearn: 0.2041041\ttotal: 1.17s\tremaining: 2.89s\n",
      "576:\tlearn: 0.2040568\ttotal: 1.17s\tremaining: 2.88s\n",
      "577:\tlearn: 0.2040220\ttotal: 1.17s\tremaining: 2.88s\n",
      "578:\tlearn: 0.2039970\ttotal: 1.17s\tremaining: 2.88s\n",
      "579:\tlearn: 0.2039482\ttotal: 1.18s\tremaining: 2.88s\n",
      "580:\tlearn: 0.2039173\ttotal: 1.18s\tremaining: 2.88s\n",
      "581:\tlearn: 0.2038903\ttotal: 1.18s\tremaining: 2.87s\n",
      "582:\tlearn: 0.2038511\ttotal: 1.18s\tremaining: 2.87s\n",
      "583:\tlearn: 0.2038359\ttotal: 1.18s\tremaining: 2.87s\n",
      "584:\tlearn: 0.2038001\ttotal: 1.19s\tremaining: 2.87s\n",
      "585:\tlearn: 0.2037781\ttotal: 1.19s\tremaining: 2.86s\n",
      "586:\tlearn: 0.2037262\ttotal: 1.19s\tremaining: 2.86s\n",
      "587:\tlearn: 0.2036781\ttotal: 1.19s\tremaining: 2.86s\n",
      "588:\tlearn: 0.2036569\ttotal: 1.19s\tremaining: 2.86s\n",
      "589:\tlearn: 0.2036351\ttotal: 1.2s\tremaining: 2.86s\n",
      "590:\tlearn: 0.2036027\ttotal: 1.2s\tremaining: 2.85s\n",
      "591:\tlearn: 0.2035399\ttotal: 1.2s\tremaining: 2.85s\n",
      "592:\tlearn: 0.2035312\ttotal: 1.2s\tremaining: 2.85s\n",
      "593:\tlearn: 0.2034983\ttotal: 1.2s\tremaining: 2.85s\n",
      "594:\tlearn: 0.2034746\ttotal: 1.21s\tremaining: 2.85s\n",
      "595:\tlearn: 0.2034550\ttotal: 1.21s\tremaining: 2.85s\n",
      "596:\tlearn: 0.2034213\ttotal: 1.21s\tremaining: 2.84s\n",
      "597:\tlearn: 0.2033929\ttotal: 1.21s\tremaining: 2.84s\n",
      "598:\tlearn: 0.2033841\ttotal: 1.21s\tremaining: 2.84s\n",
      "599:\tlearn: 0.2033574\ttotal: 1.22s\tremaining: 2.84s\n",
      "600:\tlearn: 0.2033478\ttotal: 1.22s\tremaining: 2.84s\n",
      "601:\tlearn: 0.2033259\ttotal: 1.22s\tremaining: 2.83s\n",
      "602:\tlearn: 0.2032876\ttotal: 1.22s\tremaining: 2.83s\n",
      "603:\tlearn: 0.2032588\ttotal: 1.23s\tremaining: 2.83s\n",
      "604:\tlearn: 0.2032323\ttotal: 1.23s\tremaining: 2.83s\n",
      "605:\tlearn: 0.2031858\ttotal: 1.23s\tremaining: 2.83s\n",
      "606:\tlearn: 0.2031488\ttotal: 1.23s\tremaining: 2.83s\n",
      "607:\tlearn: 0.2031316\ttotal: 1.23s\tremaining: 2.82s\n",
      "608:\tlearn: 0.2030713\ttotal: 1.24s\tremaining: 2.82s\n",
      "609:\tlearn: 0.2030569\ttotal: 1.24s\tremaining: 2.82s\n",
      "610:\tlearn: 0.2030320\ttotal: 1.24s\tremaining: 2.82s\n",
      "611:\tlearn: 0.2029791\ttotal: 1.24s\tremaining: 2.82s\n",
      "612:\tlearn: 0.2029219\ttotal: 1.24s\tremaining: 2.81s\n",
      "613:\tlearn: 0.2028973\ttotal: 1.25s\tremaining: 2.81s\n",
      "614:\tlearn: 0.2028726\ttotal: 1.25s\tremaining: 2.81s\n",
      "615:\tlearn: 0.2028169\ttotal: 1.25s\tremaining: 2.81s\n",
      "616:\tlearn: 0.2027829\ttotal: 1.25s\tremaining: 2.81s\n",
      "617:\tlearn: 0.2027568\ttotal: 1.25s\tremaining: 2.81s\n",
      "618:\tlearn: 0.2027352\ttotal: 1.26s\tremaining: 2.8s\n",
      "619:\tlearn: 0.2027061\ttotal: 1.26s\tremaining: 2.8s\n",
      "620:\tlearn: 0.2026696\ttotal: 1.26s\tremaining: 2.8s\n",
      "621:\tlearn: 0.2026261\ttotal: 1.26s\tremaining: 2.8s\n",
      "622:\tlearn: 0.2025994\ttotal: 1.26s\tremaining: 2.8s\n",
      "623:\tlearn: 0.2025584\ttotal: 1.27s\tremaining: 2.79s\n",
      "624:\tlearn: 0.2025112\ttotal: 1.27s\tremaining: 2.79s\n",
      "625:\tlearn: 0.2024870\ttotal: 1.27s\tremaining: 2.79s\n",
      "626:\tlearn: 0.2024790\ttotal: 1.27s\tremaining: 2.79s\n",
      "627:\tlearn: 0.2024552\ttotal: 1.27s\tremaining: 2.79s\n",
      "628:\tlearn: 0.2024310\ttotal: 1.28s\tremaining: 2.79s\n",
      "629:\tlearn: 0.2023778\ttotal: 1.28s\tremaining: 2.78s\n",
      "630:\tlearn: 0.2023696\ttotal: 1.28s\tremaining: 2.78s\n",
      "631:\tlearn: 0.2023475\ttotal: 1.28s\tremaining: 2.78s\n",
      "632:\tlearn: 0.2023029\ttotal: 1.29s\tremaining: 2.78s\n",
      "633:\tlearn: 0.2022881\ttotal: 1.29s\tremaining: 2.78s\n",
      "634:\tlearn: 0.2022657\ttotal: 1.29s\tremaining: 2.77s\n",
      "635:\tlearn: 0.2022427\ttotal: 1.29s\tremaining: 2.77s\n",
      "636:\tlearn: 0.2022120\ttotal: 1.29s\tremaining: 2.77s\n",
      "637:\tlearn: 0.2021690\ttotal: 1.3s\tremaining: 2.77s\n",
      "638:\tlearn: 0.2021330\ttotal: 1.3s\tremaining: 2.77s\n",
      "639:\tlearn: 0.2021082\ttotal: 1.3s\tremaining: 2.76s\n",
      "640:\tlearn: 0.2021020\ttotal: 1.3s\tremaining: 2.76s\n",
      "641:\tlearn: 0.2020945\ttotal: 1.3s\tremaining: 2.76s\n",
      "642:\tlearn: 0.2020744\ttotal: 1.31s\tremaining: 2.76s\n",
      "643:\tlearn: 0.2020600\ttotal: 1.31s\tremaining: 2.75s\n",
      "644:\tlearn: 0.2020179\ttotal: 1.31s\tremaining: 2.75s\n",
      "645:\tlearn: 0.2019999\ttotal: 1.31s\tremaining: 2.75s\n",
      "646:\tlearn: 0.2019757\ttotal: 1.31s\tremaining: 2.75s\n",
      "647:\tlearn: 0.2019545\ttotal: 1.32s\tremaining: 2.75s\n",
      "648:\tlearn: 0.2018988\ttotal: 1.32s\tremaining: 2.75s\n",
      "649:\tlearn: 0.2018589\ttotal: 1.32s\tremaining: 2.75s\n",
      "650:\tlearn: 0.2018299\ttotal: 1.32s\tremaining: 2.74s\n",
      "651:\tlearn: 0.2018166\ttotal: 1.33s\tremaining: 2.74s\n",
      "652:\tlearn: 0.2017726\ttotal: 1.33s\tremaining: 2.74s\n",
      "653:\tlearn: 0.2017197\ttotal: 1.33s\tremaining: 2.74s\n",
      "654:\tlearn: 0.2016808\ttotal: 1.33s\tremaining: 2.74s\n",
      "655:\tlearn: 0.2016596\ttotal: 1.33s\tremaining: 2.73s\n",
      "656:\tlearn: 0.2016190\ttotal: 1.34s\tremaining: 2.73s\n",
      "657:\tlearn: 0.2015904\ttotal: 1.34s\tremaining: 2.73s\n",
      "658:\tlearn: 0.2015633\ttotal: 1.34s\tremaining: 2.73s\n",
      "659:\tlearn: 0.2015407\ttotal: 1.34s\tremaining: 2.73s\n",
      "660:\tlearn: 0.2015072\ttotal: 1.34s\tremaining: 2.72s\n",
      "661:\tlearn: 0.2014931\ttotal: 1.35s\tremaining: 2.72s\n",
      "662:\tlearn: 0.2014718\ttotal: 1.35s\tremaining: 2.72s\n",
      "663:\tlearn: 0.2014226\ttotal: 1.35s\tremaining: 2.72s\n",
      "664:\tlearn: 0.2014004\ttotal: 1.35s\tremaining: 2.72s\n",
      "665:\tlearn: 0.2013661\ttotal: 1.35s\tremaining: 2.71s\n",
      "666:\tlearn: 0.2013493\ttotal: 1.36s\tremaining: 2.71s\n",
      "667:\tlearn: 0.2013281\ttotal: 1.36s\tremaining: 2.71s\n",
      "668:\tlearn: 0.2013051\ttotal: 1.36s\tremaining: 2.71s\n",
      "669:\tlearn: 0.2012798\ttotal: 1.36s\tremaining: 2.71s\n",
      "670:\tlearn: 0.2012526\ttotal: 1.36s\tremaining: 2.7s\n",
      "671:\tlearn: 0.2011954\ttotal: 1.37s\tremaining: 2.7s\n",
      "672:\tlearn: 0.2011765\ttotal: 1.37s\tremaining: 2.7s\n",
      "673:\tlearn: 0.2011405\ttotal: 1.37s\tremaining: 2.7s\n",
      "674:\tlearn: 0.2011089\ttotal: 1.37s\tremaining: 2.69s\n",
      "675:\tlearn: 0.2010928\ttotal: 1.38s\tremaining: 2.69s\n",
      "676:\tlearn: 0.2010538\ttotal: 1.38s\tremaining: 2.69s\n",
      "677:\tlearn: 0.2010178\ttotal: 1.38s\tremaining: 2.69s\n",
      "678:\tlearn: 0.2010070\ttotal: 1.38s\tremaining: 2.69s\n",
      "679:\tlearn: 0.2009806\ttotal: 1.38s\tremaining: 2.69s\n",
      "680:\tlearn: 0.2009655\ttotal: 1.39s\tremaining: 2.69s\n",
      "681:\tlearn: 0.2009422\ttotal: 1.39s\tremaining: 2.68s\n",
      "682:\tlearn: 0.2009027\ttotal: 1.39s\tremaining: 2.68s\n",
      "683:\tlearn: 0.2008886\ttotal: 1.39s\tremaining: 2.68s\n",
      "684:\tlearn: 0.2008509\ttotal: 1.39s\tremaining: 2.68s\n",
      "685:\tlearn: 0.2008434\ttotal: 1.4s\tremaining: 2.67s\n",
      "686:\tlearn: 0.2008246\ttotal: 1.4s\tremaining: 2.67s\n",
      "687:\tlearn: 0.2007953\ttotal: 1.4s\tremaining: 2.67s\n",
      "688:\tlearn: 0.2007864\ttotal: 1.4s\tremaining: 2.67s\n",
      "689:\tlearn: 0.2007660\ttotal: 1.4s\tremaining: 2.67s\n",
      "690:\tlearn: 0.2007348\ttotal: 1.41s\tremaining: 2.67s\n",
      "691:\tlearn: 0.2007128\ttotal: 1.41s\tremaining: 2.66s\n",
      "692:\tlearn: 0.2006921\ttotal: 1.41s\tremaining: 2.66s\n",
      "693:\tlearn: 0.2006593\ttotal: 1.41s\tremaining: 2.66s\n",
      "694:\tlearn: 0.2006452\ttotal: 1.42s\tremaining: 2.66s\n",
      "695:\tlearn: 0.2006403\ttotal: 1.42s\tremaining: 2.66s\n",
      "696:\tlearn: 0.2006151\ttotal: 1.42s\tremaining: 2.65s\n",
      "697:\tlearn: 0.2005895\ttotal: 1.42s\tremaining: 2.65s\n",
      "698:\tlearn: 0.2005701\ttotal: 1.42s\tremaining: 2.65s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699:\tlearn: 0.2005593\ttotal: 1.43s\tremaining: 2.65s\n",
      "700:\tlearn: 0.2005202\ttotal: 1.43s\tremaining: 2.65s\n",
      "701:\tlearn: 0.2004890\ttotal: 1.43s\tremaining: 2.65s\n",
      "702:\tlearn: 0.2004355\ttotal: 1.43s\tremaining: 2.65s\n",
      "703:\tlearn: 0.2004026\ttotal: 1.44s\tremaining: 2.64s\n",
      "704:\tlearn: 0.2003898\ttotal: 1.44s\tremaining: 2.64s\n",
      "705:\tlearn: 0.2003726\ttotal: 1.44s\tremaining: 2.64s\n",
      "706:\tlearn: 0.2003388\ttotal: 1.44s\tremaining: 2.64s\n",
      "707:\tlearn: 0.2003037\ttotal: 1.44s\tremaining: 2.63s\n",
      "708:\tlearn: 0.2002742\ttotal: 1.45s\tremaining: 2.63s\n",
      "709:\tlearn: 0.2002385\ttotal: 1.45s\tremaining: 2.63s\n",
      "710:\tlearn: 0.2002179\ttotal: 1.45s\tremaining: 2.63s\n",
      "711:\tlearn: 0.2002011\ttotal: 1.45s\tremaining: 2.63s\n",
      "712:\tlearn: 0.2001642\ttotal: 1.45s\tremaining: 2.62s\n",
      "713:\tlearn: 0.2001285\ttotal: 1.46s\tremaining: 2.62s\n",
      "714:\tlearn: 0.2000804\ttotal: 1.46s\tremaining: 2.62s\n",
      "715:\tlearn: 0.2000690\ttotal: 1.46s\tremaining: 2.62s\n",
      "716:\tlearn: 0.2000568\ttotal: 1.46s\tremaining: 2.62s\n",
      "717:\tlearn: 0.2000437\ttotal: 1.46s\tremaining: 2.62s\n",
      "718:\tlearn: 0.2000191\ttotal: 1.47s\tremaining: 2.61s\n",
      "719:\tlearn: 0.2000004\ttotal: 1.47s\tremaining: 2.61s\n",
      "720:\tlearn: 0.1999836\ttotal: 1.47s\tremaining: 2.61s\n",
      "721:\tlearn: 0.1999702\ttotal: 1.47s\tremaining: 2.61s\n",
      "722:\tlearn: 0.1999606\ttotal: 1.48s\tremaining: 2.6s\n",
      "723:\tlearn: 0.1999406\ttotal: 1.48s\tremaining: 2.6s\n",
      "724:\tlearn: 0.1999316\ttotal: 1.48s\tremaining: 2.6s\n",
      "725:\tlearn: 0.1998991\ttotal: 1.48s\tremaining: 2.6s\n",
      "726:\tlearn: 0.1998712\ttotal: 1.48s\tremaining: 2.6s\n",
      "727:\tlearn: 0.1998557\ttotal: 1.49s\tremaining: 2.6s\n",
      "728:\tlearn: 0.1998283\ttotal: 1.49s\tremaining: 2.59s\n",
      "729:\tlearn: 0.1998114\ttotal: 1.49s\tremaining: 2.59s\n",
      "730:\tlearn: 0.1997827\ttotal: 1.49s\tremaining: 2.59s\n",
      "731:\tlearn: 0.1997740\ttotal: 1.49s\tremaining: 2.59s\n",
      "732:\tlearn: 0.1997641\ttotal: 1.5s\tremaining: 2.58s\n",
      "733:\tlearn: 0.1997321\ttotal: 1.5s\tremaining: 2.58s\n",
      "734:\tlearn: 0.1997192\ttotal: 1.5s\tremaining: 2.58s\n",
      "735:\tlearn: 0.1996700\ttotal: 1.5s\tremaining: 2.58s\n",
      "736:\tlearn: 0.1996440\ttotal: 1.5s\tremaining: 2.58s\n",
      "737:\tlearn: 0.1996090\ttotal: 1.51s\tremaining: 2.58s\n",
      "738:\tlearn: 0.1995930\ttotal: 1.51s\tremaining: 2.57s\n",
      "739:\tlearn: 0.1995612\ttotal: 1.51s\tremaining: 2.57s\n",
      "740:\tlearn: 0.1995445\ttotal: 1.51s\tremaining: 2.57s\n",
      "741:\tlearn: 0.1995110\ttotal: 1.51s\tremaining: 2.57s\n",
      "742:\tlearn: 0.1994689\ttotal: 1.52s\tremaining: 2.57s\n",
      "743:\tlearn: 0.1994364\ttotal: 1.52s\tremaining: 2.56s\n",
      "744:\tlearn: 0.1994205\ttotal: 1.52s\tremaining: 2.56s\n",
      "745:\tlearn: 0.1994077\ttotal: 1.52s\tremaining: 2.56s\n",
      "746:\tlearn: 0.1993891\ttotal: 1.53s\tremaining: 2.56s\n",
      "747:\tlearn: 0.1993626\ttotal: 1.53s\tremaining: 2.56s\n",
      "748:\tlearn: 0.1993505\ttotal: 1.53s\tremaining: 2.56s\n",
      "749:\tlearn: 0.1993267\ttotal: 1.53s\tremaining: 2.56s\n",
      "750:\tlearn: 0.1992810\ttotal: 1.53s\tremaining: 2.55s\n",
      "751:\tlearn: 0.1992401\ttotal: 1.54s\tremaining: 2.55s\n",
      "752:\tlearn: 0.1992249\ttotal: 1.54s\tremaining: 2.55s\n",
      "753:\tlearn: 0.1992202\ttotal: 1.54s\tremaining: 2.55s\n",
      "754:\tlearn: 0.1991921\ttotal: 1.54s\tremaining: 2.55s\n",
      "755:\tlearn: 0.1991658\ttotal: 1.55s\tremaining: 2.54s\n",
      "756:\tlearn: 0.1991423\ttotal: 1.55s\tremaining: 2.54s\n",
      "757:\tlearn: 0.1991112\ttotal: 1.55s\tremaining: 2.54s\n",
      "758:\tlearn: 0.1990797\ttotal: 1.55s\tremaining: 2.54s\n",
      "759:\tlearn: 0.1990544\ttotal: 1.55s\tremaining: 2.54s\n",
      "760:\tlearn: 0.1990249\ttotal: 1.56s\tremaining: 2.53s\n",
      "761:\tlearn: 0.1989971\ttotal: 1.56s\tremaining: 2.53s\n",
      "762:\tlearn: 0.1989677\ttotal: 1.56s\tremaining: 2.53s\n",
      "763:\tlearn: 0.1989530\ttotal: 1.56s\tremaining: 2.53s\n",
      "764:\tlearn: 0.1989291\ttotal: 1.56s\tremaining: 2.52s\n",
      "765:\tlearn: 0.1989012\ttotal: 1.57s\tremaining: 2.52s\n",
      "766:\tlearn: 0.1988599\ttotal: 1.57s\tremaining: 2.52s\n",
      "767:\tlearn: 0.1988395\ttotal: 1.57s\tremaining: 2.52s\n",
      "768:\tlearn: 0.1988014\ttotal: 1.57s\tremaining: 2.52s\n",
      "769:\tlearn: 0.1987742\ttotal: 1.57s\tremaining: 2.52s\n",
      "770:\tlearn: 0.1987519\ttotal: 1.58s\tremaining: 2.51s\n",
      "771:\tlearn: 0.1987363\ttotal: 1.58s\tremaining: 2.51s\n",
      "772:\tlearn: 0.1987115\ttotal: 1.58s\tremaining: 2.51s\n",
      "773:\tlearn: 0.1986811\ttotal: 1.58s\tremaining: 2.51s\n",
      "774:\tlearn: 0.1986663\ttotal: 1.58s\tremaining: 2.51s\n",
      "775:\tlearn: 0.1986316\ttotal: 1.59s\tremaining: 2.5s\n",
      "776:\tlearn: 0.1985989\ttotal: 1.59s\tremaining: 2.5s\n",
      "777:\tlearn: 0.1985601\ttotal: 1.59s\tremaining: 2.5s\n",
      "778:\tlearn: 0.1985417\ttotal: 1.59s\tremaining: 2.5s\n",
      "779:\tlearn: 0.1985022\ttotal: 1.6s\tremaining: 2.5s\n",
      "780:\tlearn: 0.1984934\ttotal: 1.6s\tremaining: 2.49s\n",
      "781:\tlearn: 0.1984518\ttotal: 1.6s\tremaining: 2.49s\n",
      "782:\tlearn: 0.1984304\ttotal: 1.6s\tremaining: 2.49s\n",
      "783:\tlearn: 0.1983978\ttotal: 1.6s\tremaining: 2.49s\n",
      "784:\tlearn: 0.1983832\ttotal: 1.61s\tremaining: 2.49s\n",
      "785:\tlearn: 0.1983495\ttotal: 1.61s\tremaining: 2.48s\n",
      "786:\tlearn: 0.1983274\ttotal: 1.61s\tremaining: 2.48s\n",
      "787:\tlearn: 0.1983175\ttotal: 1.61s\tremaining: 2.48s\n",
      "788:\tlearn: 0.1983054\ttotal: 1.61s\tremaining: 2.48s\n",
      "789:\tlearn: 0.1982987\ttotal: 1.62s\tremaining: 2.48s\n",
      "790:\tlearn: 0.1982827\ttotal: 1.62s\tremaining: 2.48s\n",
      "791:\tlearn: 0.1982370\ttotal: 1.62s\tremaining: 2.47s\n",
      "792:\tlearn: 0.1982140\ttotal: 1.62s\tremaining: 2.47s\n",
      "793:\tlearn: 0.1981853\ttotal: 1.63s\tremaining: 2.47s\n",
      "794:\tlearn: 0.1981754\ttotal: 1.63s\tremaining: 2.47s\n",
      "795:\tlearn: 0.1981645\ttotal: 1.63s\tremaining: 2.46s\n",
      "796:\tlearn: 0.1981301\ttotal: 1.63s\tremaining: 2.46s\n",
      "797:\tlearn: 0.1980862\ttotal: 1.63s\tremaining: 2.46s\n",
      "798:\tlearn: 0.1980765\ttotal: 1.64s\tremaining: 2.46s\n",
      "799:\tlearn: 0.1980652\ttotal: 1.64s\tremaining: 2.46s\n",
      "800:\tlearn: 0.1980349\ttotal: 1.64s\tremaining: 2.46s\n",
      "801:\tlearn: 0.1980083\ttotal: 1.64s\tremaining: 2.45s\n",
      "802:\tlearn: 0.1979740\ttotal: 1.64s\tremaining: 2.45s\n",
      "803:\tlearn: 0.1979351\ttotal: 1.65s\tremaining: 2.45s\n",
      "804:\tlearn: 0.1979305\ttotal: 1.65s\tremaining: 2.45s\n",
      "805:\tlearn: 0.1979203\ttotal: 1.65s\tremaining: 2.44s\n",
      "806:\tlearn: 0.1978914\ttotal: 1.65s\tremaining: 2.44s\n",
      "807:\tlearn: 0.1978772\ttotal: 1.66s\tremaining: 2.44s\n",
      "808:\tlearn: 0.1978437\ttotal: 1.66s\tremaining: 2.44s\n",
      "809:\tlearn: 0.1978121\ttotal: 1.66s\tremaining: 2.44s\n",
      "810:\tlearn: 0.1977824\ttotal: 1.66s\tremaining: 2.44s\n",
      "811:\tlearn: 0.1977608\ttotal: 1.66s\tremaining: 2.43s\n",
      "812:\tlearn: 0.1977306\ttotal: 1.67s\tremaining: 2.43s\n",
      "813:\tlearn: 0.1977079\ttotal: 1.67s\tremaining: 2.43s\n",
      "814:\tlearn: 0.1976763\ttotal: 1.67s\tremaining: 2.43s\n",
      "815:\tlearn: 0.1976489\ttotal: 1.67s\tremaining: 2.42s\n",
      "816:\tlearn: 0.1976178\ttotal: 1.67s\tremaining: 2.42s\n",
      "817:\tlearn: 0.1975880\ttotal: 1.68s\tremaining: 2.42s\n",
      "818:\tlearn: 0.1975639\ttotal: 1.68s\tremaining: 2.42s\n",
      "819:\tlearn: 0.1975336\ttotal: 1.68s\tremaining: 2.42s\n",
      "820:\tlearn: 0.1975122\ttotal: 1.68s\tremaining: 2.42s\n",
      "821:\tlearn: 0.1974696\ttotal: 1.68s\tremaining: 2.41s\n",
      "822:\tlearn: 0.1974595\ttotal: 1.69s\tremaining: 2.41s\n",
      "823:\tlearn: 0.1974328\ttotal: 1.69s\tremaining: 2.41s\n",
      "824:\tlearn: 0.1974113\ttotal: 1.69s\tremaining: 2.41s\n",
      "825:\tlearn: 0.1974040\ttotal: 1.69s\tremaining: 2.4s\n",
      "826:\tlearn: 0.1973708\ttotal: 1.69s\tremaining: 2.4s\n",
      "827:\tlearn: 0.1973441\ttotal: 1.7s\tremaining: 2.4s\n",
      "828:\tlearn: 0.1973209\ttotal: 1.7s\tremaining: 2.4s\n",
      "829:\tlearn: 0.1972945\ttotal: 1.7s\tremaining: 2.4s\n",
      "830:\tlearn: 0.1972796\ttotal: 1.7s\tremaining: 2.39s\n",
      "831:\tlearn: 0.1972478\ttotal: 1.7s\tremaining: 2.39s\n",
      "832:\tlearn: 0.1972140\ttotal: 1.71s\tremaining: 2.39s\n",
      "833:\tlearn: 0.1972051\ttotal: 1.71s\tremaining: 2.39s\n",
      "834:\tlearn: 0.1971738\ttotal: 1.71s\tremaining: 2.38s\n",
      "835:\tlearn: 0.1971460\ttotal: 1.71s\tremaining: 2.38s\n",
      "836:\tlearn: 0.1971295\ttotal: 1.71s\tremaining: 2.38s\n",
      "837:\tlearn: 0.1971047\ttotal: 1.72s\tremaining: 2.38s\n",
      "838:\tlearn: 0.1970842\ttotal: 1.72s\tremaining: 2.38s\n",
      "839:\tlearn: 0.1970461\ttotal: 1.72s\tremaining: 2.37s\n",
      "840:\tlearn: 0.1970410\ttotal: 1.72s\tremaining: 2.37s\n",
      "841:\tlearn: 0.1970237\ttotal: 1.72s\tremaining: 2.37s\n",
      "842:\tlearn: 0.1970115\ttotal: 1.73s\tremaining: 2.37s\n",
      "843:\tlearn: 0.1969884\ttotal: 1.73s\tremaining: 2.37s\n",
      "844:\tlearn: 0.1969654\ttotal: 1.73s\tremaining: 2.36s\n",
      "845:\tlearn: 0.1969389\ttotal: 1.73s\tremaining: 2.36s\n",
      "846:\tlearn: 0.1969088\ttotal: 1.73s\tremaining: 2.36s\n",
      "847:\tlearn: 0.1968976\ttotal: 1.74s\tremaining: 2.36s\n",
      "848:\tlearn: 0.1968650\ttotal: 1.74s\tremaining: 2.35s\n",
      "849:\tlearn: 0.1968224\ttotal: 1.74s\tremaining: 2.35s\n",
      "850:\tlearn: 0.1967868\ttotal: 1.74s\tremaining: 2.35s\n",
      "851:\tlearn: 0.1967700\ttotal: 1.74s\tremaining: 2.35s\n",
      "852:\tlearn: 0.1967568\ttotal: 1.75s\tremaining: 2.35s\n",
      "853:\tlearn: 0.1967150\ttotal: 1.75s\tremaining: 2.34s\n",
      "854:\tlearn: 0.1966904\ttotal: 1.75s\tremaining: 2.34s\n",
      "855:\tlearn: 0.1966701\ttotal: 1.75s\tremaining: 2.34s\n",
      "856:\tlearn: 0.1966585\ttotal: 1.75s\tremaining: 2.34s\n",
      "857:\tlearn: 0.1966537\ttotal: 1.75s\tremaining: 2.33s\n",
      "858:\tlearn: 0.1966289\ttotal: 1.76s\tremaining: 2.33s\n",
      "859:\tlearn: 0.1966078\ttotal: 1.76s\tremaining: 2.33s\n",
      "860:\tlearn: 0.1965897\ttotal: 1.76s\tremaining: 2.33s\n",
      "861:\tlearn: 0.1965836\ttotal: 1.76s\tremaining: 2.33s\n",
      "862:\tlearn: 0.1965666\ttotal: 1.76s\tremaining: 2.32s\n",
      "863:\tlearn: 0.1965543\ttotal: 1.77s\tremaining: 2.32s\n",
      "864:\tlearn: 0.1965358\ttotal: 1.77s\tremaining: 2.32s\n",
      "865:\tlearn: 0.1965065\ttotal: 1.77s\tremaining: 2.32s\n",
      "866:\tlearn: 0.1964711\ttotal: 1.77s\tremaining: 2.32s\n",
      "867:\tlearn: 0.1964348\ttotal: 1.77s\tremaining: 2.31s\n",
      "868:\tlearn: 0.1964109\ttotal: 1.78s\tremaining: 2.31s\n",
      "869:\tlearn: 0.1963813\ttotal: 1.78s\tremaining: 2.31s\n",
      "870:\tlearn: 0.1963666\ttotal: 1.78s\tremaining: 2.31s\n",
      "871:\tlearn: 0.1963423\ttotal: 1.78s\tremaining: 2.31s\n",
      "872:\tlearn: 0.1963149\ttotal: 1.78s\tremaining: 2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "873:\tlearn: 0.1963057\ttotal: 1.79s\tremaining: 2.3s\n",
      "874:\tlearn: 0.1962889\ttotal: 1.79s\tremaining: 2.3s\n",
      "875:\tlearn: 0.1962650\ttotal: 1.79s\tremaining: 2.3s\n",
      "876:\tlearn: 0.1962419\ttotal: 1.79s\tremaining: 2.29s\n",
      "877:\tlearn: 0.1962104\ttotal: 1.79s\tremaining: 2.29s\n",
      "878:\tlearn: 0.1961683\ttotal: 1.8s\tremaining: 2.29s\n",
      "879:\tlearn: 0.1961510\ttotal: 1.8s\tremaining: 2.29s\n",
      "880:\tlearn: 0.1961297\ttotal: 1.8s\tremaining: 2.29s\n",
      "881:\tlearn: 0.1961127\ttotal: 1.8s\tremaining: 2.29s\n",
      "882:\tlearn: 0.1960746\ttotal: 1.8s\tremaining: 2.28s\n",
      "883:\tlearn: 0.1960468\ttotal: 1.81s\tremaining: 2.28s\n",
      "884:\tlearn: 0.1960242\ttotal: 1.81s\tremaining: 2.28s\n",
      "885:\tlearn: 0.1960025\ttotal: 1.81s\tremaining: 2.28s\n",
      "886:\tlearn: 0.1959671\ttotal: 1.81s\tremaining: 2.27s\n",
      "887:\tlearn: 0.1959542\ttotal: 1.81s\tremaining: 2.27s\n",
      "888:\tlearn: 0.1959231\ttotal: 1.82s\tremaining: 2.27s\n",
      "889:\tlearn: 0.1959051\ttotal: 1.82s\tremaining: 2.27s\n",
      "890:\tlearn: 0.1958858\ttotal: 1.82s\tremaining: 2.27s\n",
      "891:\tlearn: 0.1958713\ttotal: 1.82s\tremaining: 2.26s\n",
      "892:\tlearn: 0.1958395\ttotal: 1.82s\tremaining: 2.26s\n",
      "893:\tlearn: 0.1958122\ttotal: 1.83s\tremaining: 2.26s\n",
      "894:\tlearn: 0.1957803\ttotal: 1.83s\tremaining: 2.26s\n",
      "895:\tlearn: 0.1957337\ttotal: 1.83s\tremaining: 2.26s\n",
      "896:\tlearn: 0.1957098\ttotal: 1.83s\tremaining: 2.25s\n",
      "897:\tlearn: 0.1956699\ttotal: 1.83s\tremaining: 2.25s\n",
      "898:\tlearn: 0.1956531\ttotal: 1.84s\tremaining: 2.25s\n",
      "899:\tlearn: 0.1956398\ttotal: 1.84s\tremaining: 2.25s\n",
      "900:\tlearn: 0.1956058\ttotal: 1.84s\tremaining: 2.25s\n",
      "901:\tlearn: 0.1955813\ttotal: 1.84s\tremaining: 2.24s\n",
      "902:\tlearn: 0.1955435\ttotal: 1.84s\tremaining: 2.24s\n",
      "903:\tlearn: 0.1955253\ttotal: 1.85s\tremaining: 2.24s\n",
      "904:\tlearn: 0.1955092\ttotal: 1.85s\tremaining: 2.24s\n",
      "905:\tlearn: 0.1955047\ttotal: 1.85s\tremaining: 2.23s\n",
      "906:\tlearn: 0.1954750\ttotal: 1.85s\tremaining: 2.23s\n",
      "907:\tlearn: 0.1954549\ttotal: 1.85s\tremaining: 2.23s\n",
      "908:\tlearn: 0.1954148\ttotal: 1.86s\tremaining: 2.23s\n",
      "909:\tlearn: 0.1953746\ttotal: 1.86s\tremaining: 2.23s\n",
      "910:\tlearn: 0.1953543\ttotal: 1.86s\tremaining: 2.23s\n",
      "911:\tlearn: 0.1953161\ttotal: 1.86s\tremaining: 2.22s\n",
      "912:\tlearn: 0.1952926\ttotal: 1.86s\tremaining: 2.22s\n",
      "913:\tlearn: 0.1952599\ttotal: 1.87s\tremaining: 2.22s\n",
      "914:\tlearn: 0.1952495\ttotal: 1.87s\tremaining: 2.22s\n",
      "915:\tlearn: 0.1952419\ttotal: 1.87s\tremaining: 2.21s\n",
      "916:\tlearn: 0.1952124\ttotal: 1.87s\tremaining: 2.21s\n",
      "917:\tlearn: 0.1951904\ttotal: 1.88s\tremaining: 2.21s\n",
      "918:\tlearn: 0.1951752\ttotal: 1.88s\tremaining: 2.21s\n",
      "919:\tlearn: 0.1951441\ttotal: 1.88s\tremaining: 2.21s\n",
      "920:\tlearn: 0.1951159\ttotal: 1.88s\tremaining: 2.21s\n",
      "921:\tlearn: 0.1950907\ttotal: 1.88s\tremaining: 2.2s\n",
      "922:\tlearn: 0.1950728\ttotal: 1.89s\tremaining: 2.2s\n",
      "923:\tlearn: 0.1950454\ttotal: 1.89s\tremaining: 2.2s\n",
      "924:\tlearn: 0.1950177\ttotal: 1.89s\tremaining: 2.2s\n",
      "925:\tlearn: 0.1949987\ttotal: 1.89s\tremaining: 2.19s\n",
      "926:\tlearn: 0.1949765\ttotal: 1.9s\tremaining: 2.19s\n",
      "927:\tlearn: 0.1949534\ttotal: 1.9s\tremaining: 2.19s\n",
      "928:\tlearn: 0.1949288\ttotal: 1.9s\tremaining: 2.19s\n",
      "929:\tlearn: 0.1949109\ttotal: 1.9s\tremaining: 2.19s\n",
      "930:\tlearn: 0.1949018\ttotal: 1.9s\tremaining: 2.19s\n",
      "931:\tlearn: 0.1948729\ttotal: 1.91s\tremaining: 2.18s\n",
      "932:\tlearn: 0.1948471\ttotal: 1.91s\tremaining: 2.18s\n",
      "933:\tlearn: 0.1948209\ttotal: 1.91s\tremaining: 2.18s\n",
      "934:\tlearn: 0.1947921\ttotal: 1.91s\tremaining: 2.18s\n",
      "935:\tlearn: 0.1947627\ttotal: 1.91s\tremaining: 2.17s\n",
      "936:\tlearn: 0.1947400\ttotal: 1.92s\tremaining: 2.17s\n",
      "937:\tlearn: 0.1947165\ttotal: 1.92s\tremaining: 2.17s\n",
      "938:\tlearn: 0.1946960\ttotal: 1.92s\tremaining: 2.17s\n",
      "939:\tlearn: 0.1946822\ttotal: 1.92s\tremaining: 2.17s\n",
      "940:\tlearn: 0.1946476\ttotal: 1.92s\tremaining: 2.16s\n",
      "941:\tlearn: 0.1946257\ttotal: 1.93s\tremaining: 2.16s\n",
      "942:\tlearn: 0.1945970\ttotal: 1.93s\tremaining: 2.16s\n",
      "943:\tlearn: 0.1945620\ttotal: 1.93s\tremaining: 2.16s\n",
      "944:\tlearn: 0.1945538\ttotal: 1.93s\tremaining: 2.16s\n",
      "945:\tlearn: 0.1945201\ttotal: 1.93s\tremaining: 2.15s\n",
      "946:\tlearn: 0.1944941\ttotal: 1.94s\tremaining: 2.15s\n",
      "947:\tlearn: 0.1944691\ttotal: 1.94s\tremaining: 2.15s\n",
      "948:\tlearn: 0.1944505\ttotal: 1.94s\tremaining: 2.15s\n",
      "949:\tlearn: 0.1944306\ttotal: 1.94s\tremaining: 2.15s\n",
      "950:\tlearn: 0.1944221\ttotal: 1.94s\tremaining: 2.14s\n",
      "951:\tlearn: 0.1943984\ttotal: 1.95s\tremaining: 2.14s\n",
      "952:\tlearn: 0.1943769\ttotal: 1.95s\tremaining: 2.14s\n",
      "953:\tlearn: 0.1943401\ttotal: 1.95s\tremaining: 2.14s\n",
      "954:\tlearn: 0.1943316\ttotal: 1.95s\tremaining: 2.13s\n",
      "955:\tlearn: 0.1943138\ttotal: 1.95s\tremaining: 2.13s\n",
      "956:\tlearn: 0.1942990\ttotal: 1.96s\tremaining: 2.13s\n",
      "957:\tlearn: 0.1942720\ttotal: 1.96s\tremaining: 2.13s\n",
      "958:\tlearn: 0.1942515\ttotal: 1.96s\tremaining: 2.13s\n",
      "959:\tlearn: 0.1942386\ttotal: 1.96s\tremaining: 2.13s\n",
      "960:\tlearn: 0.1942065\ttotal: 1.96s\tremaining: 2.12s\n",
      "961:\tlearn: 0.1941847\ttotal: 1.97s\tremaining: 2.12s\n",
      "962:\tlearn: 0.1941495\ttotal: 1.97s\tremaining: 2.12s\n",
      "963:\tlearn: 0.1941320\ttotal: 1.97s\tremaining: 2.12s\n",
      "964:\tlearn: 0.1941196\ttotal: 1.97s\tremaining: 2.12s\n",
      "965:\tlearn: 0.1940991\ttotal: 1.97s\tremaining: 2.11s\n",
      "966:\tlearn: 0.1940521\ttotal: 1.98s\tremaining: 2.11s\n",
      "967:\tlearn: 0.1940095\ttotal: 1.98s\tremaining: 2.11s\n",
      "968:\tlearn: 0.1939874\ttotal: 1.98s\tremaining: 2.11s\n",
      "969:\tlearn: 0.1939691\ttotal: 1.98s\tremaining: 2.1s\n",
      "970:\tlearn: 0.1939520\ttotal: 1.98s\tremaining: 2.1s\n",
      "971:\tlearn: 0.1939365\ttotal: 1.99s\tremaining: 2.1s\n",
      "972:\tlearn: 0.1939115\ttotal: 1.99s\tremaining: 2.1s\n",
      "973:\tlearn: 0.1938833\ttotal: 1.99s\tremaining: 2.1s\n",
      "974:\tlearn: 0.1938549\ttotal: 1.99s\tremaining: 2.1s\n",
      "975:\tlearn: 0.1938325\ttotal: 2s\tremaining: 2.09s\n",
      "976:\tlearn: 0.1938057\ttotal: 2s\tremaining: 2.09s\n",
      "977:\tlearn: 0.1937807\ttotal: 2s\tremaining: 2.09s\n",
      "978:\tlearn: 0.1937692\ttotal: 2s\tremaining: 2.09s\n",
      "979:\tlearn: 0.1937483\ttotal: 2s\tremaining: 2.08s\n",
      "980:\tlearn: 0.1937246\ttotal: 2s\tremaining: 2.08s\n",
      "981:\tlearn: 0.1937109\ttotal: 2.01s\tremaining: 2.08s\n",
      "982:\tlearn: 0.1936900\ttotal: 2.01s\tremaining: 2.08s\n",
      "983:\tlearn: 0.1936676\ttotal: 2.01s\tremaining: 2.08s\n",
      "984:\tlearn: 0.1936552\ttotal: 2.01s\tremaining: 2.07s\n",
      "985:\tlearn: 0.1936338\ttotal: 2.02s\tremaining: 2.07s\n",
      "986:\tlearn: 0.1936156\ttotal: 2.02s\tremaining: 2.07s\n",
      "987:\tlearn: 0.1935991\ttotal: 2.02s\tremaining: 2.07s\n",
      "988:\tlearn: 0.1935730\ttotal: 2.02s\tremaining: 2.07s\n",
      "989:\tlearn: 0.1935538\ttotal: 2.02s\tremaining: 2.06s\n",
      "990:\tlearn: 0.1935128\ttotal: 2.02s\tremaining: 2.06s\n",
      "991:\tlearn: 0.1934836\ttotal: 2.03s\tremaining: 2.06s\n",
      "992:\tlearn: 0.1934620\ttotal: 2.03s\tremaining: 2.06s\n",
      "993:\tlearn: 0.1934513\ttotal: 2.03s\tremaining: 2.06s\n",
      "994:\tlearn: 0.1934431\ttotal: 2.03s\tremaining: 2.05s\n",
      "995:\tlearn: 0.1934182\ttotal: 2.04s\tremaining: 2.05s\n",
      "996:\tlearn: 0.1934087\ttotal: 2.04s\tremaining: 2.05s\n",
      "997:\tlearn: 0.1933976\ttotal: 2.04s\tremaining: 2.05s\n",
      "998:\tlearn: 0.1933757\ttotal: 2.04s\tremaining: 2.04s\n",
      "999:\tlearn: 0.1933613\ttotal: 2.04s\tremaining: 2.04s\n",
      "1000:\tlearn: 0.1933391\ttotal: 2.04s\tremaining: 2.04s\n",
      "1001:\tlearn: 0.1933189\ttotal: 2.05s\tremaining: 2.04s\n",
      "1002:\tlearn: 0.1932973\ttotal: 2.05s\tremaining: 2.04s\n",
      "1003:\tlearn: 0.1932926\ttotal: 2.05s\tremaining: 2.04s\n",
      "1004:\tlearn: 0.1932717\ttotal: 2.05s\tremaining: 2.03s\n",
      "1005:\tlearn: 0.1932587\ttotal: 2.06s\tremaining: 2.03s\n",
      "1006:\tlearn: 0.1932246\ttotal: 2.06s\tremaining: 2.03s\n",
      "1007:\tlearn: 0.1931972\ttotal: 2.06s\tremaining: 2.03s\n",
      "1008:\tlearn: 0.1931763\ttotal: 2.06s\tremaining: 2.02s\n",
      "1009:\tlearn: 0.1931579\ttotal: 2.06s\tremaining: 2.02s\n",
      "1010:\tlearn: 0.1931295\ttotal: 2.06s\tremaining: 2.02s\n",
      "1011:\tlearn: 0.1931012\ttotal: 2.07s\tremaining: 2.02s\n",
      "1012:\tlearn: 0.1930808\ttotal: 2.07s\tremaining: 2.02s\n",
      "1013:\tlearn: 0.1930550\ttotal: 2.07s\tremaining: 2.01s\n",
      "1014:\tlearn: 0.1930339\ttotal: 2.07s\tremaining: 2.01s\n",
      "1015:\tlearn: 0.1929989\ttotal: 2.08s\tremaining: 2.01s\n",
      "1016:\tlearn: 0.1929831\ttotal: 2.08s\tremaining: 2.01s\n",
      "1017:\tlearn: 0.1929510\ttotal: 2.08s\tremaining: 2.01s\n",
      "1018:\tlearn: 0.1929333\ttotal: 2.08s\tremaining: 2s\n",
      "1019:\tlearn: 0.1929217\ttotal: 2.08s\tremaining: 2s\n",
      "1020:\tlearn: 0.1929037\ttotal: 2.09s\tremaining: 2s\n",
      "1021:\tlearn: 0.1928817\ttotal: 2.09s\tremaining: 2s\n",
      "1022:\tlearn: 0.1928612\ttotal: 2.09s\tremaining: 2s\n",
      "1023:\tlearn: 0.1928506\ttotal: 2.09s\tremaining: 1.99s\n",
      "1024:\tlearn: 0.1928167\ttotal: 2.09s\tremaining: 1.99s\n",
      "1025:\tlearn: 0.1927996\ttotal: 2.1s\tremaining: 1.99s\n",
      "1026:\tlearn: 0.1927831\ttotal: 2.1s\tremaining: 1.99s\n",
      "1027:\tlearn: 0.1927755\ttotal: 2.1s\tremaining: 1.99s\n",
      "1028:\tlearn: 0.1927509\ttotal: 2.1s\tremaining: 1.98s\n",
      "1029:\tlearn: 0.1927197\ttotal: 2.1s\tremaining: 1.98s\n",
      "1030:\tlearn: 0.1926999\ttotal: 2.1s\tremaining: 1.98s\n",
      "1031:\tlearn: 0.1926674\ttotal: 2.11s\tremaining: 1.98s\n",
      "1032:\tlearn: 0.1926576\ttotal: 2.11s\tremaining: 1.97s\n",
      "1033:\tlearn: 0.1926307\ttotal: 2.11s\tremaining: 1.97s\n",
      "1034:\tlearn: 0.1926075\ttotal: 2.11s\tremaining: 1.97s\n",
      "1035:\tlearn: 0.1925899\ttotal: 2.12s\tremaining: 1.97s\n",
      "1036:\tlearn: 0.1925578\ttotal: 2.12s\tremaining: 1.97s\n",
      "1037:\tlearn: 0.1925343\ttotal: 2.12s\tremaining: 1.96s\n",
      "1038:\tlearn: 0.1925034\ttotal: 2.12s\tremaining: 1.96s\n",
      "1039:\tlearn: 0.1924784\ttotal: 2.12s\tremaining: 1.96s\n",
      "1040:\tlearn: 0.1924712\ttotal: 2.13s\tremaining: 1.96s\n",
      "1041:\tlearn: 0.1924621\ttotal: 2.13s\tremaining: 1.96s\n",
      "1042:\tlearn: 0.1924253\ttotal: 2.13s\tremaining: 1.95s\n",
      "1043:\tlearn: 0.1924174\ttotal: 2.13s\tremaining: 1.95s\n",
      "1044:\tlearn: 0.1924041\ttotal: 2.13s\tremaining: 1.95s\n",
      "1045:\tlearn: 0.1923941\ttotal: 2.13s\tremaining: 1.95s\n",
      "1046:\tlearn: 0.1923832\ttotal: 2.14s\tremaining: 1.95s\n",
      "1047:\tlearn: 0.1923596\ttotal: 2.14s\tremaining: 1.94s\n",
      "1048:\tlearn: 0.1923256\ttotal: 2.14s\tremaining: 1.94s\n",
      "1049:\tlearn: 0.1923180\ttotal: 2.14s\tremaining: 1.94s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050:\tlearn: 0.1923108\ttotal: 2.14s\tremaining: 1.94s\n",
      "1051:\tlearn: 0.1922785\ttotal: 2.15s\tremaining: 1.93s\n",
      "1052:\tlearn: 0.1922485\ttotal: 2.15s\tremaining: 1.93s\n",
      "1053:\tlearn: 0.1922262\ttotal: 2.15s\tremaining: 1.93s\n",
      "1054:\tlearn: 0.1922111\ttotal: 2.15s\tremaining: 1.93s\n",
      "1055:\tlearn: 0.1921869\ttotal: 2.15s\tremaining: 1.93s\n",
      "1056:\tlearn: 0.1921767\ttotal: 2.16s\tremaining: 1.92s\n",
      "1057:\tlearn: 0.1921533\ttotal: 2.16s\tremaining: 1.92s\n",
      "1058:\tlearn: 0.1921247\ttotal: 2.16s\tremaining: 1.92s\n",
      "1059:\tlearn: 0.1921029\ttotal: 2.16s\tremaining: 1.92s\n",
      "1060:\tlearn: 0.1920803\ttotal: 2.17s\tremaining: 1.92s\n",
      "1061:\tlearn: 0.1920737\ttotal: 2.17s\tremaining: 1.91s\n",
      "1062:\tlearn: 0.1920697\ttotal: 2.17s\tremaining: 1.91s\n",
      "1063:\tlearn: 0.1920621\ttotal: 2.17s\tremaining: 1.91s\n",
      "1064:\tlearn: 0.1920399\ttotal: 2.17s\tremaining: 1.91s\n",
      "1065:\tlearn: 0.1920022\ttotal: 2.17s\tremaining: 1.91s\n",
      "1066:\tlearn: 0.1919829\ttotal: 2.18s\tremaining: 1.9s\n",
      "1067:\tlearn: 0.1919571\ttotal: 2.18s\tremaining: 1.9s\n",
      "1068:\tlearn: 0.1919510\ttotal: 2.18s\tremaining: 1.9s\n",
      "1069:\tlearn: 0.1919321\ttotal: 2.18s\tremaining: 1.9s\n",
      "1070:\tlearn: 0.1919127\ttotal: 2.18s\tremaining: 1.9s\n",
      "1071:\tlearn: 0.1918872\ttotal: 2.19s\tremaining: 1.89s\n",
      "1072:\tlearn: 0.1918643\ttotal: 2.19s\tremaining: 1.89s\n",
      "1073:\tlearn: 0.1918446\ttotal: 2.19s\tremaining: 1.89s\n",
      "1074:\tlearn: 0.1918303\ttotal: 2.19s\tremaining: 1.89s\n",
      "1075:\tlearn: 0.1918010\ttotal: 2.19s\tremaining: 1.88s\n",
      "1076:\tlearn: 0.1917943\ttotal: 2.2s\tremaining: 1.88s\n",
      "1077:\tlearn: 0.1917832\ttotal: 2.2s\tremaining: 1.88s\n",
      "1078:\tlearn: 0.1917650\ttotal: 2.2s\tremaining: 1.88s\n",
      "1079:\tlearn: 0.1917524\ttotal: 2.2s\tremaining: 1.88s\n",
      "1080:\tlearn: 0.1917320\ttotal: 2.2s\tremaining: 1.87s\n",
      "1081:\tlearn: 0.1917228\ttotal: 2.21s\tremaining: 1.87s\n",
      "1082:\tlearn: 0.1916970\ttotal: 2.21s\tremaining: 1.87s\n",
      "1083:\tlearn: 0.1916695\ttotal: 2.21s\tremaining: 1.87s\n",
      "1084:\tlearn: 0.1916352\ttotal: 2.21s\tremaining: 1.86s\n",
      "1085:\tlearn: 0.1916311\ttotal: 2.21s\tremaining: 1.86s\n",
      "1086:\tlearn: 0.1916044\ttotal: 2.22s\tremaining: 1.86s\n",
      "1087:\tlearn: 0.1915803\ttotal: 2.22s\tremaining: 1.86s\n",
      "1088:\tlearn: 0.1915622\ttotal: 2.22s\tremaining: 1.86s\n",
      "1089:\tlearn: 0.1915384\ttotal: 2.22s\tremaining: 1.85s\n",
      "1090:\tlearn: 0.1915187\ttotal: 2.22s\tremaining: 1.85s\n",
      "1091:\tlearn: 0.1915067\ttotal: 2.23s\tremaining: 1.85s\n",
      "1092:\tlearn: 0.1914962\ttotal: 2.23s\tremaining: 1.85s\n",
      "1093:\tlearn: 0.1914776\ttotal: 2.23s\tremaining: 1.85s\n",
      "1094:\tlearn: 0.1914624\ttotal: 2.23s\tremaining: 1.84s\n",
      "1095:\tlearn: 0.1914539\ttotal: 2.23s\tremaining: 1.84s\n",
      "1096:\tlearn: 0.1914227\ttotal: 2.23s\tremaining: 1.84s\n",
      "1097:\tlearn: 0.1913946\ttotal: 2.24s\tremaining: 1.84s\n",
      "1098:\tlearn: 0.1913779\ttotal: 2.24s\tremaining: 1.83s\n",
      "1099:\tlearn: 0.1913586\ttotal: 2.24s\tremaining: 1.83s\n",
      "1100:\tlearn: 0.1913299\ttotal: 2.24s\tremaining: 1.83s\n",
      "1101:\tlearn: 0.1913006\ttotal: 2.25s\tremaining: 1.83s\n",
      "1102:\tlearn: 0.1912819\ttotal: 2.25s\tremaining: 1.83s\n",
      "1103:\tlearn: 0.1912644\ttotal: 2.25s\tremaining: 1.82s\n",
      "1104:\tlearn: 0.1912414\ttotal: 2.25s\tremaining: 1.82s\n",
      "1105:\tlearn: 0.1912215\ttotal: 2.25s\tremaining: 1.82s\n",
      "1106:\tlearn: 0.1911995\ttotal: 2.25s\tremaining: 1.82s\n",
      "1107:\tlearn: 0.1911806\ttotal: 2.26s\tremaining: 1.82s\n",
      "1108:\tlearn: 0.1911669\ttotal: 2.26s\tremaining: 1.82s\n",
      "1109:\tlearn: 0.1911582\ttotal: 2.26s\tremaining: 1.81s\n",
      "1110:\tlearn: 0.1911452\ttotal: 2.27s\tremaining: 1.81s\n",
      "1111:\tlearn: 0.1911372\ttotal: 2.27s\tremaining: 1.81s\n",
      "1112:\tlearn: 0.1911216\ttotal: 2.27s\tremaining: 1.81s\n",
      "1113:\tlearn: 0.1911118\ttotal: 2.27s\tremaining: 1.81s\n",
      "1114:\tlearn: 0.1910847\ttotal: 2.27s\tremaining: 1.8s\n",
      "1115:\tlearn: 0.1910799\ttotal: 2.27s\tremaining: 1.8s\n",
      "1116:\tlearn: 0.1910580\ttotal: 2.28s\tremaining: 1.8s\n",
      "1117:\tlearn: 0.1910389\ttotal: 2.28s\tremaining: 1.8s\n",
      "1118:\tlearn: 0.1910149\ttotal: 2.28s\tremaining: 1.79s\n",
      "1119:\tlearn: 0.1910089\ttotal: 2.28s\tremaining: 1.79s\n",
      "1120:\tlearn: 0.1909846\ttotal: 2.28s\tremaining: 1.79s\n",
      "1121:\tlearn: 0.1909625\ttotal: 2.29s\tremaining: 1.79s\n",
      "1122:\tlearn: 0.1909502\ttotal: 2.29s\tremaining: 1.79s\n",
      "1123:\tlearn: 0.1909357\ttotal: 2.29s\tremaining: 1.78s\n",
      "1124:\tlearn: 0.1909248\ttotal: 2.29s\tremaining: 1.78s\n",
      "1125:\tlearn: 0.1909109\ttotal: 2.29s\tremaining: 1.78s\n",
      "1126:\tlearn: 0.1908811\ttotal: 2.3s\tremaining: 1.78s\n",
      "1127:\tlearn: 0.1908557\ttotal: 2.3s\tremaining: 1.78s\n",
      "1128:\tlearn: 0.1908388\ttotal: 2.3s\tremaining: 1.77s\n",
      "1129:\tlearn: 0.1908173\ttotal: 2.3s\tremaining: 1.77s\n",
      "1130:\tlearn: 0.1908003\ttotal: 2.3s\tremaining: 1.77s\n",
      "1131:\tlearn: 0.1907898\ttotal: 2.31s\tremaining: 1.77s\n",
      "1132:\tlearn: 0.1907677\ttotal: 2.31s\tremaining: 1.77s\n",
      "1133:\tlearn: 0.1907565\ttotal: 2.31s\tremaining: 1.76s\n",
      "1134:\tlearn: 0.1907377\ttotal: 2.31s\tremaining: 1.76s\n",
      "1135:\tlearn: 0.1907132\ttotal: 2.31s\tremaining: 1.76s\n",
      "1136:\tlearn: 0.1906782\ttotal: 2.32s\tremaining: 1.76s\n",
      "1137:\tlearn: 0.1906604\ttotal: 2.32s\tremaining: 1.76s\n",
      "1138:\tlearn: 0.1906303\ttotal: 2.32s\tremaining: 1.75s\n",
      "1139:\tlearn: 0.1906123\ttotal: 2.32s\tremaining: 1.75s\n",
      "1140:\tlearn: 0.1905944\ttotal: 2.32s\tremaining: 1.75s\n",
      "1141:\tlearn: 0.1905897\ttotal: 2.33s\tremaining: 1.75s\n",
      "1142:\tlearn: 0.1905720\ttotal: 2.33s\tremaining: 1.75s\n",
      "1143:\tlearn: 0.1905638\ttotal: 2.33s\tremaining: 1.74s\n",
      "1144:\tlearn: 0.1905400\ttotal: 2.33s\tremaining: 1.74s\n",
      "1145:\tlearn: 0.1905355\ttotal: 2.33s\tremaining: 1.74s\n",
      "1146:\tlearn: 0.1905141\ttotal: 2.34s\tremaining: 1.74s\n",
      "1147:\tlearn: 0.1904915\ttotal: 2.34s\tremaining: 1.74s\n",
      "1148:\tlearn: 0.1904529\ttotal: 2.34s\tremaining: 1.73s\n",
      "1149:\tlearn: 0.1904354\ttotal: 2.34s\tremaining: 1.73s\n",
      "1150:\tlearn: 0.1904168\ttotal: 2.35s\tremaining: 1.73s\n",
      "1151:\tlearn: 0.1904040\ttotal: 2.35s\tremaining: 1.73s\n",
      "1152:\tlearn: 0.1903808\ttotal: 2.35s\tremaining: 1.73s\n",
      "1153:\tlearn: 0.1903528\ttotal: 2.35s\tremaining: 1.72s\n",
      "1154:\tlearn: 0.1903263\ttotal: 2.35s\tremaining: 1.72s\n",
      "1155:\tlearn: 0.1903117\ttotal: 2.35s\tremaining: 1.72s\n",
      "1156:\tlearn: 0.1902996\ttotal: 2.36s\tremaining: 1.72s\n",
      "1157:\tlearn: 0.1902833\ttotal: 2.36s\tremaining: 1.72s\n",
      "1158:\tlearn: 0.1902649\ttotal: 2.36s\tremaining: 1.71s\n",
      "1159:\tlearn: 0.1902563\ttotal: 2.36s\tremaining: 1.71s\n",
      "1160:\tlearn: 0.1902482\ttotal: 2.36s\tremaining: 1.71s\n",
      "1161:\tlearn: 0.1902314\ttotal: 2.37s\tremaining: 1.71s\n",
      "1162:\tlearn: 0.1902161\ttotal: 2.37s\tremaining: 1.7s\n",
      "1163:\tlearn: 0.1902061\ttotal: 2.37s\tremaining: 1.7s\n",
      "1164:\tlearn: 0.1901887\ttotal: 2.37s\tremaining: 1.7s\n",
      "1165:\tlearn: 0.1901781\ttotal: 2.37s\tremaining: 1.7s\n",
      "1166:\tlearn: 0.1901429\ttotal: 2.38s\tremaining: 1.7s\n",
      "1167:\tlearn: 0.1901331\ttotal: 2.38s\tremaining: 1.69s\n",
      "1168:\tlearn: 0.1901293\ttotal: 2.38s\tremaining: 1.69s\n",
      "1169:\tlearn: 0.1901082\ttotal: 2.38s\tremaining: 1.69s\n",
      "1170:\tlearn: 0.1900780\ttotal: 2.38s\tremaining: 1.69s\n",
      "1171:\tlearn: 0.1900689\ttotal: 2.39s\tremaining: 1.69s\n",
      "1172:\tlearn: 0.1900519\ttotal: 2.39s\tremaining: 1.68s\n",
      "1173:\tlearn: 0.1900224\ttotal: 2.39s\tremaining: 1.68s\n",
      "1174:\tlearn: 0.1899958\ttotal: 2.39s\tremaining: 1.68s\n",
      "1175:\tlearn: 0.1899757\ttotal: 2.39s\tremaining: 1.68s\n",
      "1176:\tlearn: 0.1899575\ttotal: 2.4s\tremaining: 1.68s\n",
      "1177:\tlearn: 0.1899356\ttotal: 2.4s\tremaining: 1.67s\n",
      "1178:\tlearn: 0.1899115\ttotal: 2.4s\tremaining: 1.67s\n",
      "1179:\tlearn: 0.1898934\ttotal: 2.4s\tremaining: 1.67s\n",
      "1180:\tlearn: 0.1898836\ttotal: 2.4s\tremaining: 1.67s\n",
      "1181:\tlearn: 0.1898667\ttotal: 2.4s\tremaining: 1.67s\n",
      "1182:\tlearn: 0.1898601\ttotal: 2.41s\tremaining: 1.66s\n",
      "1183:\tlearn: 0.1898452\ttotal: 2.41s\tremaining: 1.66s\n",
      "1184:\tlearn: 0.1898264\ttotal: 2.41s\tremaining: 1.66s\n",
      "1185:\tlearn: 0.1898117\ttotal: 2.41s\tremaining: 1.66s\n",
      "1186:\tlearn: 0.1897825\ttotal: 2.42s\tremaining: 1.65s\n",
      "1187:\tlearn: 0.1897682\ttotal: 2.42s\tremaining: 1.65s\n",
      "1188:\tlearn: 0.1897490\ttotal: 2.42s\tremaining: 1.65s\n",
      "1189:\tlearn: 0.1897316\ttotal: 2.42s\tremaining: 1.65s\n",
      "1190:\tlearn: 0.1897167\ttotal: 2.42s\tremaining: 1.65s\n",
      "1191:\tlearn: 0.1897020\ttotal: 2.42s\tremaining: 1.64s\n",
      "1192:\tlearn: 0.1896764\ttotal: 2.43s\tremaining: 1.64s\n",
      "1193:\tlearn: 0.1896676\ttotal: 2.43s\tremaining: 1.64s\n",
      "1194:\tlearn: 0.1896585\ttotal: 2.43s\tremaining: 1.64s\n",
      "1195:\tlearn: 0.1896500\ttotal: 2.43s\tremaining: 1.64s\n",
      "1196:\tlearn: 0.1896352\ttotal: 2.44s\tremaining: 1.63s\n",
      "1197:\tlearn: 0.1896196\ttotal: 2.44s\tremaining: 1.63s\n",
      "1198:\tlearn: 0.1896131\ttotal: 2.44s\tremaining: 1.63s\n",
      "1199:\tlearn: 0.1895854\ttotal: 2.44s\tremaining: 1.63s\n",
      "1200:\tlearn: 0.1895712\ttotal: 2.44s\tremaining: 1.63s\n",
      "1201:\tlearn: 0.1895501\ttotal: 2.44s\tremaining: 1.62s\n",
      "1202:\tlearn: 0.1895353\ttotal: 2.45s\tremaining: 1.62s\n",
      "1203:\tlearn: 0.1895053\ttotal: 2.45s\tremaining: 1.62s\n",
      "1204:\tlearn: 0.1894870\ttotal: 2.45s\tremaining: 1.62s\n",
      "1205:\tlearn: 0.1894728\ttotal: 2.45s\tremaining: 1.61s\n",
      "1206:\tlearn: 0.1894358\ttotal: 2.46s\tremaining: 1.61s\n",
      "1207:\tlearn: 0.1894246\ttotal: 2.46s\tremaining: 1.61s\n",
      "1208:\tlearn: 0.1894113\ttotal: 2.46s\tremaining: 1.61s\n",
      "1209:\tlearn: 0.1893855\ttotal: 2.46s\tremaining: 1.61s\n",
      "1210:\tlearn: 0.1893602\ttotal: 2.46s\tremaining: 1.6s\n",
      "1211:\tlearn: 0.1893285\ttotal: 2.46s\tremaining: 1.6s\n",
      "1212:\tlearn: 0.1893122\ttotal: 2.47s\tremaining: 1.6s\n",
      "1213:\tlearn: 0.1892864\ttotal: 2.47s\tremaining: 1.6s\n",
      "1214:\tlearn: 0.1892738\ttotal: 2.47s\tremaining: 1.6s\n",
      "1215:\tlearn: 0.1892704\ttotal: 2.47s\tremaining: 1.59s\n",
      "1216:\tlearn: 0.1892591\ttotal: 2.48s\tremaining: 1.59s\n",
      "1217:\tlearn: 0.1892379\ttotal: 2.48s\tremaining: 1.59s\n",
      "1218:\tlearn: 0.1892158\ttotal: 2.48s\tremaining: 1.59s\n",
      "1219:\tlearn: 0.1891962\ttotal: 2.48s\tremaining: 1.59s\n",
      "1220:\tlearn: 0.1891722\ttotal: 2.48s\tremaining: 1.58s\n",
      "1221:\tlearn: 0.1891657\ttotal: 2.48s\tremaining: 1.58s\n",
      "1222:\tlearn: 0.1891448\ttotal: 2.49s\tremaining: 1.58s\n",
      "1223:\tlearn: 0.1891316\ttotal: 2.49s\tremaining: 1.58s\n",
      "1224:\tlearn: 0.1891075\ttotal: 2.49s\tremaining: 1.58s\n",
      "1225:\tlearn: 0.1890797\ttotal: 2.49s\tremaining: 1.57s\n",
      "1226:\tlearn: 0.1890614\ttotal: 2.5s\tremaining: 1.57s\n",
      "1227:\tlearn: 0.1890465\ttotal: 2.5s\tremaining: 1.57s\n",
      "1228:\tlearn: 0.1890430\ttotal: 2.5s\tremaining: 1.57s\n",
      "1229:\tlearn: 0.1890297\ttotal: 2.5s\tremaining: 1.57s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1230:\tlearn: 0.1890100\ttotal: 2.5s\tremaining: 1.56s\n",
      "1231:\tlearn: 0.1889795\ttotal: 2.51s\tremaining: 1.56s\n",
      "1232:\tlearn: 0.1889711\ttotal: 2.51s\tremaining: 1.56s\n",
      "1233:\tlearn: 0.1889467\ttotal: 2.51s\tremaining: 1.56s\n",
      "1234:\tlearn: 0.1889406\ttotal: 2.51s\tremaining: 1.56s\n",
      "1235:\tlearn: 0.1889057\ttotal: 2.52s\tremaining: 1.55s\n",
      "1236:\tlearn: 0.1888974\ttotal: 2.52s\tremaining: 1.55s\n",
      "1237:\tlearn: 0.1888749\ttotal: 2.52s\tremaining: 1.55s\n",
      "1238:\tlearn: 0.1888607\ttotal: 2.52s\tremaining: 1.55s\n",
      "1239:\tlearn: 0.1888555\ttotal: 2.52s\tremaining: 1.55s\n",
      "1240:\tlearn: 0.1888277\ttotal: 2.52s\tremaining: 1.54s\n",
      "1241:\tlearn: 0.1888217\ttotal: 2.53s\tremaining: 1.54s\n",
      "1242:\tlearn: 0.1888042\ttotal: 2.53s\tremaining: 1.54s\n",
      "1243:\tlearn: 0.1887871\ttotal: 2.53s\tremaining: 1.54s\n",
      "1244:\tlearn: 0.1887707\ttotal: 2.53s\tremaining: 1.53s\n",
      "1245:\tlearn: 0.1887565\ttotal: 2.53s\tremaining: 1.53s\n",
      "1246:\tlearn: 0.1887532\ttotal: 2.54s\tremaining: 1.53s\n",
      "1247:\tlearn: 0.1887484\ttotal: 2.54s\tremaining: 1.53s\n",
      "1248:\tlearn: 0.1887298\ttotal: 2.54s\tremaining: 1.53s\n",
      "1249:\tlearn: 0.1887151\ttotal: 2.54s\tremaining: 1.52s\n",
      "1250:\tlearn: 0.1887072\ttotal: 2.54s\tremaining: 1.52s\n",
      "1251:\tlearn: 0.1886844\ttotal: 2.55s\tremaining: 1.52s\n",
      "1252:\tlearn: 0.1886763\ttotal: 2.55s\tremaining: 1.52s\n",
      "1253:\tlearn: 0.1886542\ttotal: 2.55s\tremaining: 1.52s\n",
      "1254:\tlearn: 0.1886448\ttotal: 2.55s\tremaining: 1.51s\n",
      "1255:\tlearn: 0.1886230\ttotal: 2.55s\tremaining: 1.51s\n",
      "1256:\tlearn: 0.1886094\ttotal: 2.56s\tremaining: 1.51s\n",
      "1257:\tlearn: 0.1885845\ttotal: 2.56s\tremaining: 1.51s\n",
      "1258:\tlearn: 0.1885627\ttotal: 2.56s\tremaining: 1.51s\n",
      "1259:\tlearn: 0.1885501\ttotal: 2.56s\tremaining: 1.5s\n",
      "1260:\tlearn: 0.1885274\ttotal: 2.56s\tremaining: 1.5s\n",
      "1261:\tlearn: 0.1885099\ttotal: 2.57s\tremaining: 1.5s\n",
      "1262:\tlearn: 0.1884974\ttotal: 2.57s\tremaining: 1.5s\n",
      "1263:\tlearn: 0.1884855\ttotal: 2.57s\tremaining: 1.5s\n",
      "1264:\tlearn: 0.1884795\ttotal: 2.57s\tremaining: 1.49s\n",
      "1265:\tlearn: 0.1884604\ttotal: 2.57s\tremaining: 1.49s\n",
      "1266:\tlearn: 0.1884211\ttotal: 2.58s\tremaining: 1.49s\n",
      "1267:\tlearn: 0.1883982\ttotal: 2.58s\tremaining: 1.49s\n",
      "1268:\tlearn: 0.1883778\ttotal: 2.58s\tremaining: 1.49s\n",
      "1269:\tlearn: 0.1883638\ttotal: 2.58s\tremaining: 1.48s\n",
      "1270:\tlearn: 0.1883516\ttotal: 2.58s\tremaining: 1.48s\n",
      "1271:\tlearn: 0.1883355\ttotal: 2.59s\tremaining: 1.48s\n",
      "1272:\tlearn: 0.1883278\ttotal: 2.59s\tremaining: 1.48s\n",
      "1273:\tlearn: 0.1883080\ttotal: 2.59s\tremaining: 1.48s\n",
      "1274:\tlearn: 0.1882837\ttotal: 2.59s\tremaining: 1.47s\n",
      "1275:\tlearn: 0.1882641\ttotal: 2.59s\tremaining: 1.47s\n",
      "1276:\tlearn: 0.1882426\ttotal: 2.6s\tremaining: 1.47s\n",
      "1277:\tlearn: 0.1882254\ttotal: 2.6s\tremaining: 1.47s\n",
      "1278:\tlearn: 0.1882129\ttotal: 2.6s\tremaining: 1.47s\n",
      "1279:\tlearn: 0.1882089\ttotal: 2.6s\tremaining: 1.46s\n",
      "1280:\tlearn: 0.1881896\ttotal: 2.6s\tremaining: 1.46s\n",
      "1281:\tlearn: 0.1881808\ttotal: 2.61s\tremaining: 1.46s\n",
      "1282:\tlearn: 0.1881465\ttotal: 2.61s\tremaining: 1.46s\n",
      "1283:\tlearn: 0.1881417\ttotal: 2.61s\tremaining: 1.46s\n",
      "1284:\tlearn: 0.1881240\ttotal: 2.61s\tremaining: 1.45s\n",
      "1285:\tlearn: 0.1881144\ttotal: 2.62s\tremaining: 1.45s\n",
      "1286:\tlearn: 0.1881055\ttotal: 2.62s\tremaining: 1.45s\n",
      "1287:\tlearn: 0.1880938\ttotal: 2.62s\tremaining: 1.45s\n",
      "1288:\tlearn: 0.1880723\ttotal: 2.62s\tremaining: 1.45s\n",
      "1289:\tlearn: 0.1880699\ttotal: 2.62s\tremaining: 1.44s\n",
      "1290:\tlearn: 0.1880416\ttotal: 2.63s\tremaining: 1.44s\n",
      "1291:\tlearn: 0.1880348\ttotal: 2.63s\tremaining: 1.44s\n",
      "1292:\tlearn: 0.1880224\ttotal: 2.63s\tremaining: 1.44s\n",
      "1293:\tlearn: 0.1880084\ttotal: 2.63s\tremaining: 1.44s\n",
      "1294:\tlearn: 0.1879979\ttotal: 2.63s\tremaining: 1.43s\n",
      "1295:\tlearn: 0.1879703\ttotal: 2.64s\tremaining: 1.43s\n",
      "1296:\tlearn: 0.1879491\ttotal: 2.64s\tremaining: 1.43s\n",
      "1297:\tlearn: 0.1879203\ttotal: 2.64s\tremaining: 1.43s\n",
      "1298:\tlearn: 0.1879008\ttotal: 2.64s\tremaining: 1.43s\n",
      "1299:\tlearn: 0.1878698\ttotal: 2.65s\tremaining: 1.42s\n",
      "1300:\tlearn: 0.1878512\ttotal: 2.65s\tremaining: 1.42s\n",
      "1301:\tlearn: 0.1878335\ttotal: 2.65s\tremaining: 1.42s\n",
      "1302:\tlearn: 0.1878258\ttotal: 2.65s\tremaining: 1.42s\n",
      "1303:\tlearn: 0.1878127\ttotal: 2.65s\tremaining: 1.42s\n",
      "1304:\tlearn: 0.1878058\ttotal: 2.66s\tremaining: 1.41s\n",
      "1305:\tlearn: 0.1877875\ttotal: 2.66s\tremaining: 1.41s\n",
      "1306:\tlearn: 0.1877672\ttotal: 2.66s\tremaining: 1.41s\n",
      "1307:\tlearn: 0.1877504\ttotal: 2.66s\tremaining: 1.41s\n",
      "1308:\tlearn: 0.1877479\ttotal: 2.66s\tremaining: 1.41s\n",
      "1309:\tlearn: 0.1877347\ttotal: 2.67s\tremaining: 1.4s\n",
      "1310:\tlearn: 0.1877323\ttotal: 2.67s\tremaining: 1.4s\n",
      "1311:\tlearn: 0.1877247\ttotal: 2.67s\tremaining: 1.4s\n",
      "1312:\tlearn: 0.1876992\ttotal: 2.67s\tremaining: 1.4s\n",
      "1313:\tlearn: 0.1876949\ttotal: 2.67s\tremaining: 1.4s\n",
      "1314:\tlearn: 0.1876876\ttotal: 2.68s\tremaining: 1.39s\n",
      "1315:\tlearn: 0.1876839\ttotal: 2.68s\tremaining: 1.39s\n",
      "1316:\tlearn: 0.1876799\ttotal: 2.68s\tremaining: 1.39s\n",
      "1317:\tlearn: 0.1876666\ttotal: 2.68s\tremaining: 1.39s\n",
      "1318:\tlearn: 0.1876388\ttotal: 2.69s\tremaining: 1.39s\n",
      "1319:\tlearn: 0.1876215\ttotal: 2.69s\tremaining: 1.38s\n",
      "1320:\tlearn: 0.1876048\ttotal: 2.69s\tremaining: 1.38s\n",
      "1321:\tlearn: 0.1875958\ttotal: 2.69s\tremaining: 1.38s\n",
      "1322:\tlearn: 0.1875923\ttotal: 2.69s\tremaining: 1.38s\n",
      "1323:\tlearn: 0.1875776\ttotal: 2.7s\tremaining: 1.38s\n",
      "1324:\tlearn: 0.1875601\ttotal: 2.7s\tremaining: 1.38s\n",
      "1325:\tlearn: 0.1875416\ttotal: 2.7s\tremaining: 1.37s\n",
      "1326:\tlearn: 0.1875324\ttotal: 2.7s\tremaining: 1.37s\n",
      "1327:\tlearn: 0.1875140\ttotal: 2.71s\tremaining: 1.37s\n",
      "1328:\tlearn: 0.1875051\ttotal: 2.71s\tremaining: 1.37s\n",
      "1329:\tlearn: 0.1874997\ttotal: 2.71s\tremaining: 1.36s\n",
      "1330:\tlearn: 0.1874914\ttotal: 2.71s\tremaining: 1.36s\n",
      "1331:\tlearn: 0.1874739\ttotal: 2.71s\tremaining: 1.36s\n",
      "1332:\tlearn: 0.1874627\ttotal: 2.72s\tremaining: 1.36s\n",
      "1333:\tlearn: 0.1874605\ttotal: 2.72s\tremaining: 1.36s\n",
      "1334:\tlearn: 0.1874364\ttotal: 2.72s\tremaining: 1.35s\n",
      "1335:\tlearn: 0.1874102\ttotal: 2.72s\tremaining: 1.35s\n",
      "1336:\tlearn: 0.1873952\ttotal: 2.72s\tremaining: 1.35s\n",
      "1337:\tlearn: 0.1873803\ttotal: 2.73s\tremaining: 1.35s\n",
      "1338:\tlearn: 0.1873736\ttotal: 2.73s\tremaining: 1.35s\n",
      "1339:\tlearn: 0.1873657\ttotal: 2.73s\tremaining: 1.34s\n",
      "1340:\tlearn: 0.1873431\ttotal: 2.73s\tremaining: 1.34s\n",
      "1341:\tlearn: 0.1873194\ttotal: 2.73s\tremaining: 1.34s\n",
      "1342:\tlearn: 0.1873111\ttotal: 2.74s\tremaining: 1.34s\n",
      "1343:\tlearn: 0.1872894\ttotal: 2.74s\tremaining: 1.34s\n",
      "1344:\tlearn: 0.1872597\ttotal: 2.74s\tremaining: 1.33s\n",
      "1345:\tlearn: 0.1872391\ttotal: 2.74s\tremaining: 1.33s\n",
      "1346:\tlearn: 0.1872140\ttotal: 2.75s\tremaining: 1.33s\n",
      "1347:\tlearn: 0.1872033\ttotal: 2.75s\tremaining: 1.33s\n",
      "1348:\tlearn: 0.1871915\ttotal: 2.75s\tremaining: 1.33s\n",
      "1349:\tlearn: 0.1871690\ttotal: 2.75s\tremaining: 1.32s\n",
      "1350:\tlearn: 0.1871478\ttotal: 2.75s\tremaining: 1.32s\n",
      "1351:\tlearn: 0.1871264\ttotal: 2.76s\tremaining: 1.32s\n",
      "1352:\tlearn: 0.1871242\ttotal: 2.76s\tremaining: 1.32s\n",
      "1353:\tlearn: 0.1870988\ttotal: 2.76s\tremaining: 1.32s\n",
      "1354:\tlearn: 0.1870924\ttotal: 2.76s\tremaining: 1.31s\n",
      "1355:\tlearn: 0.1870768\ttotal: 2.76s\tremaining: 1.31s\n",
      "1356:\tlearn: 0.1870527\ttotal: 2.77s\tremaining: 1.31s\n",
      "1357:\tlearn: 0.1870410\ttotal: 2.77s\tremaining: 1.31s\n",
      "1358:\tlearn: 0.1870258\ttotal: 2.77s\tremaining: 1.31s\n",
      "1359:\tlearn: 0.1870120\ttotal: 2.77s\tremaining: 1.3s\n",
      "1360:\tlearn: 0.1870080\ttotal: 2.77s\tremaining: 1.3s\n",
      "1361:\tlearn: 0.1869842\ttotal: 2.78s\tremaining: 1.3s\n",
      "1362:\tlearn: 0.1869551\ttotal: 2.78s\tremaining: 1.3s\n",
      "1363:\tlearn: 0.1869386\ttotal: 2.78s\tremaining: 1.3s\n",
      "1364:\tlearn: 0.1869114\ttotal: 2.78s\tremaining: 1.29s\n",
      "1365:\tlearn: 0.1868949\ttotal: 2.79s\tremaining: 1.29s\n",
      "1366:\tlearn: 0.1868808\ttotal: 2.79s\tremaining: 1.29s\n",
      "1367:\tlearn: 0.1868629\ttotal: 2.79s\tremaining: 1.29s\n",
      "1368:\tlearn: 0.1868602\ttotal: 2.79s\tremaining: 1.29s\n",
      "1369:\tlearn: 0.1868564\ttotal: 2.79s\tremaining: 1.28s\n",
      "1370:\tlearn: 0.1868346\ttotal: 2.8s\tremaining: 1.28s\n",
      "1371:\tlearn: 0.1868257\ttotal: 2.8s\tremaining: 1.28s\n",
      "1372:\tlearn: 0.1868096\ttotal: 2.8s\tremaining: 1.28s\n",
      "1373:\tlearn: 0.1867912\ttotal: 2.8s\tremaining: 1.28s\n",
      "1374:\tlearn: 0.1867639\ttotal: 2.81s\tremaining: 1.27s\n",
      "1375:\tlearn: 0.1867479\ttotal: 2.81s\tremaining: 1.27s\n",
      "1376:\tlearn: 0.1867344\ttotal: 2.81s\tremaining: 1.27s\n",
      "1377:\tlearn: 0.1867108\ttotal: 2.81s\tremaining: 1.27s\n",
      "1378:\tlearn: 0.1866864\ttotal: 2.81s\tremaining: 1.27s\n",
      "1379:\tlearn: 0.1866694\ttotal: 2.82s\tremaining: 1.26s\n",
      "1380:\tlearn: 0.1866657\ttotal: 2.82s\tremaining: 1.26s\n",
      "1381:\tlearn: 0.1866526\ttotal: 2.82s\tremaining: 1.26s\n",
      "1382:\tlearn: 0.1866393\ttotal: 2.82s\tremaining: 1.26s\n",
      "1383:\tlearn: 0.1866283\ttotal: 2.82s\tremaining: 1.26s\n",
      "1384:\tlearn: 0.1866095\ttotal: 2.83s\tremaining: 1.25s\n",
      "1385:\tlearn: 0.1865956\ttotal: 2.83s\tremaining: 1.25s\n",
      "1386:\tlearn: 0.1865821\ttotal: 2.83s\tremaining: 1.25s\n",
      "1387:\tlearn: 0.1865662\ttotal: 2.83s\tremaining: 1.25s\n",
      "1388:\tlearn: 0.1865522\ttotal: 2.83s\tremaining: 1.25s\n",
      "1389:\tlearn: 0.1865339\ttotal: 2.84s\tremaining: 1.25s\n",
      "1390:\tlearn: 0.1865165\ttotal: 2.84s\tremaining: 1.24s\n",
      "1391:\tlearn: 0.1865116\ttotal: 2.84s\tremaining: 1.24s\n",
      "1392:\tlearn: 0.1864769\ttotal: 2.84s\tremaining: 1.24s\n",
      "1393:\tlearn: 0.1864656\ttotal: 2.85s\tremaining: 1.24s\n",
      "1394:\tlearn: 0.1864388\ttotal: 2.85s\tremaining: 1.24s\n",
      "1395:\tlearn: 0.1864133\ttotal: 2.85s\tremaining: 1.23s\n",
      "1396:\tlearn: 0.1864044\ttotal: 2.85s\tremaining: 1.23s\n",
      "1397:\tlearn: 0.1863845\ttotal: 2.85s\tremaining: 1.23s\n",
      "1398:\tlearn: 0.1863738\ttotal: 2.86s\tremaining: 1.23s\n",
      "1399:\tlearn: 0.1863500\ttotal: 2.86s\tremaining: 1.23s\n",
      "1400:\tlearn: 0.1863412\ttotal: 2.86s\tremaining: 1.22s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1401:\tlearn: 0.1863236\ttotal: 2.86s\tremaining: 1.22s\n",
      "1402:\tlearn: 0.1863020\ttotal: 2.87s\tremaining: 1.22s\n",
      "1403:\tlearn: 0.1862820\ttotal: 2.87s\tremaining: 1.22s\n",
      "1404:\tlearn: 0.1862616\ttotal: 2.87s\tremaining: 1.22s\n",
      "1405:\tlearn: 0.1862299\ttotal: 2.87s\tremaining: 1.21s\n",
      "1406:\tlearn: 0.1862192\ttotal: 2.87s\tremaining: 1.21s\n",
      "1407:\tlearn: 0.1862088\ttotal: 2.88s\tremaining: 1.21s\n",
      "1408:\tlearn: 0.1861952\ttotal: 2.88s\tremaining: 1.21s\n",
      "1409:\tlearn: 0.1861786\ttotal: 2.88s\tremaining: 1.21s\n",
      "1410:\tlearn: 0.1861655\ttotal: 2.88s\tremaining: 1.2s\n",
      "1411:\tlearn: 0.1861601\ttotal: 2.88s\tremaining: 1.2s\n",
      "1412:\tlearn: 0.1861549\ttotal: 2.89s\tremaining: 1.2s\n",
      "1413:\tlearn: 0.1861466\ttotal: 2.89s\tremaining: 1.2s\n",
      "1414:\tlearn: 0.1861326\ttotal: 2.89s\tremaining: 1.2s\n",
      "1415:\tlearn: 0.1861223\ttotal: 2.89s\tremaining: 1.19s\n",
      "1416:\tlearn: 0.1860981\ttotal: 2.9s\tremaining: 1.19s\n",
      "1417:\tlearn: 0.1860833\ttotal: 2.9s\tremaining: 1.19s\n",
      "1418:\tlearn: 0.1860656\ttotal: 2.9s\tremaining: 1.19s\n",
      "1419:\tlearn: 0.1860620\ttotal: 2.9s\tremaining: 1.19s\n",
      "1420:\tlearn: 0.1860520\ttotal: 2.9s\tremaining: 1.18s\n",
      "1421:\tlearn: 0.1860413\ttotal: 2.91s\tremaining: 1.18s\n",
      "1422:\tlearn: 0.1860153\ttotal: 2.91s\tremaining: 1.18s\n",
      "1423:\tlearn: 0.1860059\ttotal: 2.91s\tremaining: 1.18s\n",
      "1424:\tlearn: 0.1859878\ttotal: 2.91s\tremaining: 1.17s\n",
      "1425:\tlearn: 0.1859616\ttotal: 2.91s\tremaining: 1.17s\n",
      "1426:\tlearn: 0.1859432\ttotal: 2.92s\tremaining: 1.17s\n",
      "1427:\tlearn: 0.1859288\ttotal: 2.92s\tremaining: 1.17s\n",
      "1428:\tlearn: 0.1859040\ttotal: 2.92s\tremaining: 1.17s\n",
      "1429:\tlearn: 0.1858712\ttotal: 2.92s\tremaining: 1.16s\n",
      "1430:\tlearn: 0.1858606\ttotal: 2.92s\tremaining: 1.16s\n",
      "1431:\tlearn: 0.1858504\ttotal: 2.92s\tremaining: 1.16s\n",
      "1432:\tlearn: 0.1858173\ttotal: 2.93s\tremaining: 1.16s\n",
      "1433:\tlearn: 0.1858041\ttotal: 2.93s\tremaining: 1.16s\n",
      "1434:\tlearn: 0.1857839\ttotal: 2.93s\tremaining: 1.15s\n",
      "1435:\tlearn: 0.1857609\ttotal: 2.93s\tremaining: 1.15s\n",
      "1436:\tlearn: 0.1857555\ttotal: 2.94s\tremaining: 1.15s\n",
      "1437:\tlearn: 0.1857469\ttotal: 2.94s\tremaining: 1.15s\n",
      "1438:\tlearn: 0.1857209\ttotal: 2.94s\tremaining: 1.15s\n",
      "1439:\tlearn: 0.1857055\ttotal: 2.94s\tremaining: 1.14s\n",
      "1440:\tlearn: 0.1856809\ttotal: 2.94s\tremaining: 1.14s\n",
      "1441:\tlearn: 0.1856654\ttotal: 2.95s\tremaining: 1.14s\n",
      "1442:\tlearn: 0.1856619\ttotal: 2.95s\tremaining: 1.14s\n",
      "1443:\tlearn: 0.1856333\ttotal: 2.95s\tremaining: 1.14s\n",
      "1444:\tlearn: 0.1856267\ttotal: 2.95s\tremaining: 1.13s\n",
      "1445:\tlearn: 0.1856235\ttotal: 2.95s\tremaining: 1.13s\n",
      "1446:\tlearn: 0.1856144\ttotal: 2.96s\tremaining: 1.13s\n",
      "1447:\tlearn: 0.1855901\ttotal: 2.96s\tremaining: 1.13s\n",
      "1448:\tlearn: 0.1855723\ttotal: 2.96s\tremaining: 1.13s\n",
      "1449:\tlearn: 0.1855477\ttotal: 2.96s\tremaining: 1.12s\n",
      "1450:\tlearn: 0.1855163\ttotal: 2.96s\tremaining: 1.12s\n",
      "1451:\tlearn: 0.1854965\ttotal: 2.97s\tremaining: 1.12s\n",
      "1452:\tlearn: 0.1854886\ttotal: 2.97s\tremaining: 1.12s\n",
      "1453:\tlearn: 0.1854740\ttotal: 2.97s\tremaining: 1.12s\n",
      "1454:\tlearn: 0.1854449\ttotal: 2.97s\tremaining: 1.11s\n",
      "1455:\tlearn: 0.1854289\ttotal: 2.98s\tremaining: 1.11s\n",
      "1456:\tlearn: 0.1854205\ttotal: 2.98s\tremaining: 1.11s\n",
      "1457:\tlearn: 0.1854008\ttotal: 2.98s\tremaining: 1.11s\n",
      "1458:\tlearn: 0.1853656\ttotal: 2.98s\tremaining: 1.1s\n",
      "1459:\tlearn: 0.1853469\ttotal: 2.98s\tremaining: 1.1s\n",
      "1460:\tlearn: 0.1853309\ttotal: 2.99s\tremaining: 1.1s\n",
      "1461:\tlearn: 0.1853226\ttotal: 2.99s\tremaining: 1.1s\n",
      "1462:\tlearn: 0.1853069\ttotal: 2.99s\tremaining: 1.1s\n",
      "1463:\tlearn: 0.1852796\ttotal: 2.99s\tremaining: 1.09s\n",
      "1464:\tlearn: 0.1852626\ttotal: 3s\tremaining: 1.09s\n",
      "1465:\tlearn: 0.1852582\ttotal: 3s\tremaining: 1.09s\n",
      "1466:\tlearn: 0.1852434\ttotal: 3s\tremaining: 1.09s\n",
      "1467:\tlearn: 0.1852051\ttotal: 3s\tremaining: 1.09s\n",
      "1468:\tlearn: 0.1851928\ttotal: 3s\tremaining: 1.08s\n",
      "1469:\tlearn: 0.1851728\ttotal: 3s\tremaining: 1.08s\n",
      "1470:\tlearn: 0.1851417\ttotal: 3.01s\tremaining: 1.08s\n",
      "1471:\tlearn: 0.1851244\ttotal: 3.01s\tremaining: 1.08s\n",
      "1472:\tlearn: 0.1850953\ttotal: 3.01s\tremaining: 1.08s\n",
      "1473:\tlearn: 0.1850744\ttotal: 3.01s\tremaining: 1.07s\n",
      "1474:\tlearn: 0.1850483\ttotal: 3.02s\tremaining: 1.07s\n",
      "1475:\tlearn: 0.1850431\ttotal: 3.02s\tremaining: 1.07s\n",
      "1476:\tlearn: 0.1850116\ttotal: 3.02s\tremaining: 1.07s\n",
      "1477:\tlearn: 0.1849916\ttotal: 3.02s\tremaining: 1.07s\n",
      "1478:\tlearn: 0.1849775\ttotal: 3.02s\tremaining: 1.06s\n",
      "1479:\tlearn: 0.1849702\ttotal: 3.03s\tremaining: 1.06s\n",
      "1480:\tlearn: 0.1849620\ttotal: 3.03s\tremaining: 1.06s\n",
      "1481:\tlearn: 0.1849544\ttotal: 3.03s\tremaining: 1.06s\n",
      "1482:\tlearn: 0.1849419\ttotal: 3.03s\tremaining: 1.06s\n",
      "1483:\tlearn: 0.1849303\ttotal: 3.04s\tremaining: 1.05s\n",
      "1484:\tlearn: 0.1849053\ttotal: 3.04s\tremaining: 1.05s\n",
      "1485:\tlearn: 0.1849010\ttotal: 3.04s\tremaining: 1.05s\n",
      "1486:\tlearn: 0.1848935\ttotal: 3.04s\tremaining: 1.05s\n",
      "1487:\tlearn: 0.1848721\ttotal: 3.04s\tremaining: 1.05s\n",
      "1488:\tlearn: 0.1848591\ttotal: 3.05s\tremaining: 1.05s\n",
      "1489:\tlearn: 0.1848269\ttotal: 3.05s\tremaining: 1.04s\n",
      "1490:\tlearn: 0.1848069\ttotal: 3.05s\tremaining: 1.04s\n",
      "1491:\tlearn: 0.1847818\ttotal: 3.05s\tremaining: 1.04s\n",
      "1492:\tlearn: 0.1847679\ttotal: 3.06s\tremaining: 1.04s\n",
      "1493:\tlearn: 0.1847516\ttotal: 3.06s\tremaining: 1.03s\n",
      "1494:\tlearn: 0.1847485\ttotal: 3.06s\tremaining: 1.03s\n",
      "1495:\tlearn: 0.1847248\ttotal: 3.06s\tremaining: 1.03s\n",
      "1496:\tlearn: 0.1847067\ttotal: 3.06s\tremaining: 1.03s\n",
      "1497:\tlearn: 0.1846806\ttotal: 3.07s\tremaining: 1.03s\n",
      "1498:\tlearn: 0.1846571\ttotal: 3.07s\tremaining: 1.02s\n",
      "1499:\tlearn: 0.1846373\ttotal: 3.07s\tremaining: 1.02s\n",
      "1500:\tlearn: 0.1846197\ttotal: 3.07s\tremaining: 1.02s\n",
      "1501:\tlearn: 0.1846012\ttotal: 3.08s\tremaining: 1.02s\n",
      "1502:\tlearn: 0.1845897\ttotal: 3.08s\tremaining: 1.02s\n",
      "1503:\tlearn: 0.1845804\ttotal: 3.08s\tremaining: 1.01s\n",
      "1504:\tlearn: 0.1845718\ttotal: 3.08s\tremaining: 1.01s\n",
      "1505:\tlearn: 0.1845621\ttotal: 3.08s\tremaining: 1.01s\n",
      "1506:\tlearn: 0.1845450\ttotal: 3.09s\tremaining: 1.01s\n",
      "1507:\tlearn: 0.1845385\ttotal: 3.09s\tremaining: 1.01s\n",
      "1508:\tlearn: 0.1845316\ttotal: 3.09s\tremaining: 1s\n",
      "1509:\tlearn: 0.1845013\ttotal: 3.09s\tremaining: 1s\n",
      "1510:\tlearn: 0.1844881\ttotal: 3.1s\tremaining: 1s\n",
      "1511:\tlearn: 0.1844751\ttotal: 3.1s\tremaining: 1000ms\n",
      "1512:\tlearn: 0.1844537\ttotal: 3.1s\tremaining: 998ms\n",
      "1513:\tlearn: 0.1844395\ttotal: 3.1s\tremaining: 996ms\n",
      "1514:\tlearn: 0.1844264\ttotal: 3.1s\tremaining: 994ms\n",
      "1515:\tlearn: 0.1844110\ttotal: 3.11s\tremaining: 992ms\n",
      "1516:\tlearn: 0.1843887\ttotal: 3.11s\tremaining: 990ms\n",
      "1517:\tlearn: 0.1843676\ttotal: 3.11s\tremaining: 988ms\n",
      "1518:\tlearn: 0.1843579\ttotal: 3.11s\tremaining: 986ms\n",
      "1519:\tlearn: 0.1843386\ttotal: 3.11s\tremaining: 984ms\n",
      "1520:\tlearn: 0.1843168\ttotal: 3.12s\tremaining: 982ms\n",
      "1521:\tlearn: 0.1842880\ttotal: 3.12s\tremaining: 980ms\n",
      "1522:\tlearn: 0.1842745\ttotal: 3.12s\tremaining: 977ms\n",
      "1523:\tlearn: 0.1842692\ttotal: 3.12s\tremaining: 975ms\n",
      "1524:\tlearn: 0.1842577\ttotal: 3.12s\tremaining: 973ms\n",
      "1525:\tlearn: 0.1842506\ttotal: 3.13s\tremaining: 971ms\n",
      "1526:\tlearn: 0.1842298\ttotal: 3.13s\tremaining: 969ms\n",
      "1527:\tlearn: 0.1842159\ttotal: 3.13s\tremaining: 967ms\n",
      "1528:\tlearn: 0.1842094\ttotal: 3.13s\tremaining: 965ms\n",
      "1529:\tlearn: 0.1841929\ttotal: 3.13s\tremaining: 963ms\n",
      "1530:\tlearn: 0.1841838\ttotal: 3.14s\tremaining: 961ms\n",
      "1531:\tlearn: 0.1841696\ttotal: 3.14s\tremaining: 959ms\n",
      "1532:\tlearn: 0.1841230\ttotal: 3.14s\tremaining: 957ms\n",
      "1533:\tlearn: 0.1841089\ttotal: 3.14s\tremaining: 955ms\n",
      "1534:\tlearn: 0.1840884\ttotal: 3.15s\tremaining: 953ms\n",
      "1535:\tlearn: 0.1840818\ttotal: 3.15s\tremaining: 951ms\n",
      "1536:\tlearn: 0.1840612\ttotal: 3.15s\tremaining: 949ms\n",
      "1537:\tlearn: 0.1840421\ttotal: 3.15s\tremaining: 947ms\n",
      "1538:\tlearn: 0.1840365\ttotal: 3.15s\tremaining: 945ms\n",
      "1539:\tlearn: 0.1840292\ttotal: 3.16s\tremaining: 943ms\n",
      "1540:\tlearn: 0.1840172\ttotal: 3.16s\tremaining: 941ms\n",
      "1541:\tlearn: 0.1840022\ttotal: 3.16s\tremaining: 939ms\n",
      "1542:\tlearn: 0.1839910\ttotal: 3.16s\tremaining: 937ms\n",
      "1543:\tlearn: 0.1839880\ttotal: 3.17s\tremaining: 935ms\n",
      "1544:\tlearn: 0.1839851\ttotal: 3.17s\tremaining: 933ms\n",
      "1545:\tlearn: 0.1839666\ttotal: 3.17s\tremaining: 931ms\n",
      "1546:\tlearn: 0.1839478\ttotal: 3.17s\tremaining: 929ms\n",
      "1547:\tlearn: 0.1839324\ttotal: 3.17s\tremaining: 927ms\n",
      "1548:\tlearn: 0.1839255\ttotal: 3.18s\tremaining: 925ms\n",
      "1549:\tlearn: 0.1839139\ttotal: 3.18s\tremaining: 923ms\n",
      "1550:\tlearn: 0.1838878\ttotal: 3.18s\tremaining: 921ms\n",
      "1551:\tlearn: 0.1838751\ttotal: 3.18s\tremaining: 919ms\n",
      "1552:\tlearn: 0.1838558\ttotal: 3.18s\tremaining: 917ms\n",
      "1553:\tlearn: 0.1838300\ttotal: 3.19s\tremaining: 915ms\n",
      "1554:\tlearn: 0.1838165\ttotal: 3.19s\tremaining: 913ms\n",
      "1555:\tlearn: 0.1838116\ttotal: 3.19s\tremaining: 911ms\n",
      "1556:\tlearn: 0.1837900\ttotal: 3.19s\tremaining: 909ms\n",
      "1557:\tlearn: 0.1837647\ttotal: 3.19s\tremaining: 907ms\n",
      "1558:\tlearn: 0.1837527\ttotal: 3.2s\tremaining: 905ms\n",
      "1559:\tlearn: 0.1837361\ttotal: 3.2s\tremaining: 903ms\n",
      "1560:\tlearn: 0.1837088\ttotal: 3.2s\tremaining: 900ms\n",
      "1561:\tlearn: 0.1836922\ttotal: 3.2s\tremaining: 898ms\n",
      "1562:\tlearn: 0.1836646\ttotal: 3.21s\tremaining: 896ms\n",
      "1563:\tlearn: 0.1836419\ttotal: 3.21s\tremaining: 894ms\n",
      "1564:\tlearn: 0.1836217\ttotal: 3.21s\tremaining: 892ms\n",
      "1565:\tlearn: 0.1835910\ttotal: 3.21s\tremaining: 890ms\n",
      "1566:\tlearn: 0.1835804\ttotal: 3.21s\tremaining: 888ms\n",
      "1567:\tlearn: 0.1835725\ttotal: 3.21s\tremaining: 886ms\n",
      "1568:\tlearn: 0.1835498\ttotal: 3.22s\tremaining: 884ms\n",
      "1569:\tlearn: 0.1835318\ttotal: 3.22s\tremaining: 882ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570:\tlearn: 0.1835160\ttotal: 3.22s\tremaining: 880ms\n",
      "1571:\tlearn: 0.1835051\ttotal: 3.22s\tremaining: 878ms\n",
      "1572:\tlearn: 0.1835035\ttotal: 3.23s\tremaining: 876ms\n",
      "1573:\tlearn: 0.1834791\ttotal: 3.23s\tremaining: 874ms\n",
      "1574:\tlearn: 0.1834723\ttotal: 3.23s\tremaining: 872ms\n",
      "1575:\tlearn: 0.1834625\ttotal: 3.23s\tremaining: 870ms\n",
      "1576:\tlearn: 0.1834491\ttotal: 3.23s\tremaining: 868ms\n",
      "1577:\tlearn: 0.1834390\ttotal: 3.24s\tremaining: 866ms\n",
      "1578:\tlearn: 0.1834324\ttotal: 3.24s\tremaining: 864ms\n",
      "1579:\tlearn: 0.1834199\ttotal: 3.24s\tremaining: 862ms\n",
      "1580:\tlearn: 0.1833997\ttotal: 3.24s\tremaining: 860ms\n",
      "1581:\tlearn: 0.1833705\ttotal: 3.25s\tremaining: 858ms\n",
      "1582:\tlearn: 0.1833478\ttotal: 3.25s\tremaining: 856ms\n",
      "1583:\tlearn: 0.1833276\ttotal: 3.25s\tremaining: 854ms\n",
      "1584:\tlearn: 0.1832923\ttotal: 3.25s\tremaining: 852ms\n",
      "1585:\tlearn: 0.1832787\ttotal: 3.25s\tremaining: 849ms\n",
      "1586:\tlearn: 0.1832539\ttotal: 3.26s\tremaining: 848ms\n",
      "1587:\tlearn: 0.1832324\ttotal: 3.26s\tremaining: 845ms\n",
      "1588:\tlearn: 0.1832113\ttotal: 3.26s\tremaining: 843ms\n",
      "1589:\tlearn: 0.1831817\ttotal: 3.26s\tremaining: 841ms\n",
      "1590:\tlearn: 0.1831745\ttotal: 3.26s\tremaining: 839ms\n",
      "1591:\tlearn: 0.1831568\ttotal: 3.27s\tremaining: 837ms\n",
      "1592:\tlearn: 0.1831456\ttotal: 3.27s\tremaining: 835ms\n",
      "1593:\tlearn: 0.1831392\ttotal: 3.27s\tremaining: 833ms\n",
      "1594:\tlearn: 0.1831288\ttotal: 3.27s\tremaining: 831ms\n",
      "1595:\tlearn: 0.1831160\ttotal: 3.27s\tremaining: 829ms\n",
      "1596:\tlearn: 0.1831145\ttotal: 3.28s\tremaining: 827ms\n",
      "1597:\tlearn: 0.1830929\ttotal: 3.28s\tremaining: 825ms\n",
      "1598:\tlearn: 0.1830782\ttotal: 3.28s\tremaining: 823ms\n",
      "1599:\tlearn: 0.1830701\ttotal: 3.28s\tremaining: 821ms\n",
      "1600:\tlearn: 0.1830597\ttotal: 3.29s\tremaining: 819ms\n",
      "1601:\tlearn: 0.1830400\ttotal: 3.29s\tremaining: 817ms\n",
      "1602:\tlearn: 0.1830229\ttotal: 3.29s\tremaining: 815ms\n",
      "1603:\tlearn: 0.1830042\ttotal: 3.29s\tremaining: 813ms\n",
      "1604:\tlearn: 0.1830016\ttotal: 3.29s\tremaining: 811ms\n",
      "1605:\tlearn: 0.1829844\ttotal: 3.29s\tremaining: 808ms\n",
      "1606:\tlearn: 0.1829722\ttotal: 3.3s\tremaining: 806ms\n",
      "1607:\tlearn: 0.1829655\ttotal: 3.3s\tremaining: 804ms\n",
      "1608:\tlearn: 0.1829604\ttotal: 3.3s\tremaining: 802ms\n",
      "1609:\tlearn: 0.1829276\ttotal: 3.3s\tremaining: 800ms\n",
      "1610:\tlearn: 0.1829024\ttotal: 3.31s\tremaining: 798ms\n",
      "1611:\tlearn: 0.1828834\ttotal: 3.31s\tremaining: 796ms\n",
      "1612:\tlearn: 0.1828513\ttotal: 3.31s\tremaining: 794ms\n",
      "1613:\tlearn: 0.1828317\ttotal: 3.31s\tremaining: 792ms\n",
      "1614:\tlearn: 0.1828146\ttotal: 3.31s\tremaining: 790ms\n",
      "1615:\tlearn: 0.1828027\ttotal: 3.31s\tremaining: 788ms\n",
      "1616:\tlearn: 0.1828012\ttotal: 3.32s\tremaining: 786ms\n",
      "1617:\tlearn: 0.1827779\ttotal: 3.32s\tremaining: 784ms\n",
      "1618:\tlearn: 0.1827446\ttotal: 3.32s\tremaining: 782ms\n",
      "1619:\tlearn: 0.1827432\ttotal: 3.32s\tremaining: 780ms\n",
      "1620:\tlearn: 0.1827330\ttotal: 3.33s\tremaining: 777ms\n",
      "1621:\tlearn: 0.1827316\ttotal: 3.33s\tremaining: 775ms\n",
      "1622:\tlearn: 0.1827239\ttotal: 3.33s\tremaining: 773ms\n",
      "1623:\tlearn: 0.1827053\ttotal: 3.33s\tremaining: 771ms\n",
      "1624:\tlearn: 0.1826942\ttotal: 3.33s\tremaining: 769ms\n",
      "1625:\tlearn: 0.1826829\ttotal: 3.33s\tremaining: 767ms\n",
      "1626:\tlearn: 0.1826785\ttotal: 3.34s\tremaining: 765ms\n",
      "1627:\tlearn: 0.1826475\ttotal: 3.34s\tremaining: 763ms\n",
      "1628:\tlearn: 0.1826158\ttotal: 3.34s\tremaining: 761ms\n",
      "1629:\tlearn: 0.1825958\ttotal: 3.34s\tremaining: 759ms\n",
      "1630:\tlearn: 0.1825576\ttotal: 3.35s\tremaining: 757ms\n",
      "1631:\tlearn: 0.1825428\ttotal: 3.35s\tremaining: 755ms\n",
      "1632:\tlearn: 0.1825366\ttotal: 3.35s\tremaining: 753ms\n",
      "1633:\tlearn: 0.1825208\ttotal: 3.35s\tremaining: 751ms\n",
      "1634:\tlearn: 0.1825008\ttotal: 3.35s\tremaining: 749ms\n",
      "1635:\tlearn: 0.1824895\ttotal: 3.35s\tremaining: 747ms\n",
      "1636:\tlearn: 0.1824746\ttotal: 3.36s\tremaining: 745ms\n",
      "1637:\tlearn: 0.1824721\ttotal: 3.36s\tremaining: 742ms\n",
      "1638:\tlearn: 0.1824612\ttotal: 3.36s\tremaining: 740ms\n",
      "1639:\tlearn: 0.1824576\ttotal: 3.36s\tremaining: 738ms\n",
      "1640:\tlearn: 0.1824387\ttotal: 3.37s\tremaining: 736ms\n",
      "1641:\tlearn: 0.1824245\ttotal: 3.37s\tremaining: 734ms\n",
      "1642:\tlearn: 0.1824221\ttotal: 3.37s\tremaining: 732ms\n",
      "1643:\tlearn: 0.1823972\ttotal: 3.37s\tremaining: 730ms\n",
      "1644:\tlearn: 0.1823858\ttotal: 3.37s\tremaining: 728ms\n",
      "1645:\tlearn: 0.1823756\ttotal: 3.38s\tremaining: 726ms\n",
      "1646:\tlearn: 0.1823322\ttotal: 3.38s\tremaining: 724ms\n",
      "1647:\tlearn: 0.1823012\ttotal: 3.38s\tremaining: 722ms\n",
      "1648:\tlearn: 0.1822875\ttotal: 3.38s\tremaining: 720ms\n",
      "1649:\tlearn: 0.1822805\ttotal: 3.38s\tremaining: 718ms\n",
      "1650:\tlearn: 0.1822533\ttotal: 3.38s\tremaining: 716ms\n",
      "1651:\tlearn: 0.1822346\ttotal: 3.39s\tremaining: 714ms\n",
      "1652:\tlearn: 0.1822258\ttotal: 3.39s\tremaining: 712ms\n",
      "1653:\tlearn: 0.1822234\ttotal: 3.39s\tremaining: 710ms\n",
      "1654:\tlearn: 0.1822091\ttotal: 3.39s\tremaining: 708ms\n",
      "1655:\tlearn: 0.1821913\ttotal: 3.4s\tremaining: 705ms\n",
      "1656:\tlearn: 0.1821779\ttotal: 3.4s\tremaining: 703ms\n",
      "1657:\tlearn: 0.1821667\ttotal: 3.4s\tremaining: 701ms\n",
      "1658:\tlearn: 0.1821387\ttotal: 3.4s\tremaining: 699ms\n",
      "1659:\tlearn: 0.1821233\ttotal: 3.4s\tremaining: 697ms\n",
      "1660:\tlearn: 0.1821081\ttotal: 3.41s\tremaining: 695ms\n",
      "1661:\tlearn: 0.1820950\ttotal: 3.41s\tremaining: 693ms\n",
      "1662:\tlearn: 0.1820712\ttotal: 3.41s\tremaining: 691ms\n",
      "1663:\tlearn: 0.1820518\ttotal: 3.41s\tremaining: 689ms\n",
      "1664:\tlearn: 0.1820425\ttotal: 3.42s\tremaining: 687ms\n",
      "1665:\tlearn: 0.1820249\ttotal: 3.42s\tremaining: 685ms\n",
      "1666:\tlearn: 0.1820106\ttotal: 3.42s\tremaining: 683ms\n",
      "1667:\tlearn: 0.1819956\ttotal: 3.42s\tremaining: 681ms\n",
      "1668:\tlearn: 0.1819823\ttotal: 3.42s\tremaining: 679ms\n",
      "1669:\tlearn: 0.1819545\ttotal: 3.42s\tremaining: 677ms\n",
      "1670:\tlearn: 0.1819426\ttotal: 3.43s\tremaining: 675ms\n",
      "1671:\tlearn: 0.1819328\ttotal: 3.43s\tremaining: 673ms\n",
      "1672:\tlearn: 0.1819124\ttotal: 3.43s\tremaining: 671ms\n",
      "1673:\tlearn: 0.1819065\ttotal: 3.43s\tremaining: 669ms\n",
      "1674:\tlearn: 0.1818907\ttotal: 3.44s\tremaining: 667ms\n",
      "1675:\tlearn: 0.1818803\ttotal: 3.44s\tremaining: 665ms\n",
      "1676:\tlearn: 0.1818530\ttotal: 3.44s\tremaining: 662ms\n",
      "1677:\tlearn: 0.1818473\ttotal: 3.44s\tremaining: 660ms\n",
      "1678:\tlearn: 0.1818371\ttotal: 3.44s\tremaining: 658ms\n",
      "1679:\tlearn: 0.1818094\ttotal: 3.45s\tremaining: 656ms\n",
      "1680:\tlearn: 0.1817801\ttotal: 3.45s\tremaining: 654ms\n",
      "1681:\tlearn: 0.1817536\ttotal: 3.45s\tremaining: 652ms\n",
      "1682:\tlearn: 0.1817250\ttotal: 3.45s\tremaining: 650ms\n",
      "1683:\tlearn: 0.1817105\ttotal: 3.45s\tremaining: 648ms\n",
      "1684:\tlearn: 0.1817035\ttotal: 3.46s\tremaining: 646ms\n",
      "1685:\tlearn: 0.1816944\ttotal: 3.46s\tremaining: 644ms\n",
      "1686:\tlearn: 0.1816890\ttotal: 3.46s\tremaining: 642ms\n",
      "1687:\tlearn: 0.1816758\ttotal: 3.46s\tremaining: 640ms\n",
      "1688:\tlearn: 0.1816640\ttotal: 3.46s\tremaining: 638ms\n",
      "1689:\tlearn: 0.1816591\ttotal: 3.47s\tremaining: 636ms\n",
      "1690:\tlearn: 0.1816411\ttotal: 3.47s\tremaining: 634ms\n",
      "1691:\tlearn: 0.1816283\ttotal: 3.47s\tremaining: 632ms\n",
      "1692:\tlearn: 0.1815923\ttotal: 3.47s\tremaining: 630ms\n",
      "1693:\tlearn: 0.1815810\ttotal: 3.47s\tremaining: 628ms\n",
      "1694:\tlearn: 0.1815707\ttotal: 3.48s\tremaining: 626ms\n",
      "1695:\tlearn: 0.1815519\ttotal: 3.48s\tremaining: 623ms\n",
      "1696:\tlearn: 0.1815400\ttotal: 3.48s\tremaining: 621ms\n",
      "1697:\tlearn: 0.1815231\ttotal: 3.48s\tremaining: 619ms\n",
      "1698:\tlearn: 0.1815100\ttotal: 3.48s\tremaining: 617ms\n",
      "1699:\tlearn: 0.1815045\ttotal: 3.49s\tremaining: 615ms\n",
      "1700:\tlearn: 0.1814899\ttotal: 3.49s\tremaining: 613ms\n",
      "1701:\tlearn: 0.1814819\ttotal: 3.49s\tremaining: 611ms\n",
      "1702:\tlearn: 0.1814498\ttotal: 3.49s\tremaining: 609ms\n",
      "1703:\tlearn: 0.1814294\ttotal: 3.5s\tremaining: 607ms\n",
      "1704:\tlearn: 0.1814034\ttotal: 3.5s\tremaining: 605ms\n",
      "1705:\tlearn: 0.1813808\ttotal: 3.5s\tremaining: 603ms\n",
      "1706:\tlearn: 0.1813402\ttotal: 3.5s\tremaining: 601ms\n",
      "1707:\tlearn: 0.1813234\ttotal: 3.5s\tremaining: 599ms\n",
      "1708:\tlearn: 0.1813142\ttotal: 3.5s\tremaining: 597ms\n",
      "1709:\tlearn: 0.1813056\ttotal: 3.51s\tremaining: 595ms\n",
      "1710:\tlearn: 0.1812943\ttotal: 3.51s\tremaining: 593ms\n",
      "1711:\tlearn: 0.1812814\ttotal: 3.51s\tremaining: 591ms\n",
      "1712:\tlearn: 0.1812761\ttotal: 3.51s\tremaining: 589ms\n",
      "1713:\tlearn: 0.1812479\ttotal: 3.52s\tremaining: 587ms\n",
      "1714:\tlearn: 0.1812423\ttotal: 3.52s\tremaining: 584ms\n",
      "1715:\tlearn: 0.1812289\ttotal: 3.52s\tremaining: 582ms\n",
      "1716:\tlearn: 0.1812172\ttotal: 3.52s\tremaining: 580ms\n",
      "1717:\tlearn: 0.1812064\ttotal: 3.52s\tremaining: 578ms\n",
      "1718:\tlearn: 0.1811804\ttotal: 3.52s\tremaining: 576ms\n",
      "1719:\tlearn: 0.1811464\ttotal: 3.53s\tremaining: 574ms\n",
      "1720:\tlearn: 0.1811363\ttotal: 3.53s\tremaining: 572ms\n",
      "1721:\tlearn: 0.1811245\ttotal: 3.53s\tremaining: 570ms\n",
      "1722:\tlearn: 0.1811032\ttotal: 3.53s\tremaining: 568ms\n",
      "1723:\tlearn: 0.1810989\ttotal: 3.54s\tremaining: 566ms\n",
      "1724:\tlearn: 0.1810782\ttotal: 3.54s\tremaining: 564ms\n",
      "1725:\tlearn: 0.1810618\ttotal: 3.54s\tremaining: 562ms\n",
      "1726:\tlearn: 0.1810360\ttotal: 3.54s\tremaining: 560ms\n",
      "1727:\tlearn: 0.1810121\ttotal: 3.54s\tremaining: 558ms\n",
      "1728:\tlearn: 0.1810011\ttotal: 3.54s\tremaining: 556ms\n",
      "1729:\tlearn: 0.1809854\ttotal: 3.55s\tremaining: 554ms\n",
      "1730:\tlearn: 0.1809560\ttotal: 3.55s\tremaining: 552ms\n",
      "1731:\tlearn: 0.1809424\ttotal: 3.55s\tremaining: 550ms\n",
      "1732:\tlearn: 0.1809309\ttotal: 3.55s\tremaining: 547ms\n",
      "1733:\tlearn: 0.1809286\ttotal: 3.56s\tremaining: 545ms\n",
      "1734:\tlearn: 0.1809045\ttotal: 3.56s\tremaining: 543ms\n",
      "1735:\tlearn: 0.1808931\ttotal: 3.56s\tremaining: 541ms\n",
      "1736:\tlearn: 0.1808753\ttotal: 3.56s\tremaining: 539ms\n",
      "1737:\tlearn: 0.1808624\ttotal: 3.56s\tremaining: 537ms\n",
      "1738:\tlearn: 0.1808338\ttotal: 3.56s\tremaining: 535ms\n",
      "1739:\tlearn: 0.1808253\ttotal: 3.57s\tremaining: 533ms\n",
      "1740:\tlearn: 0.1808110\ttotal: 3.57s\tremaining: 531ms\n",
      "1741:\tlearn: 0.1807830\ttotal: 3.57s\tremaining: 529ms\n",
      "1742:\tlearn: 0.1807561\ttotal: 3.57s\tremaining: 527ms\n",
      "1743:\tlearn: 0.1807311\ttotal: 3.58s\tremaining: 525ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744:\tlearn: 0.1807057\ttotal: 3.58s\tremaining: 523ms\n",
      "1745:\tlearn: 0.1806952\ttotal: 3.58s\tremaining: 521ms\n",
      "1746:\tlearn: 0.1806832\ttotal: 3.58s\tremaining: 519ms\n",
      "1747:\tlearn: 0.1806696\ttotal: 3.58s\tremaining: 517ms\n",
      "1748:\tlearn: 0.1806559\ttotal: 3.59s\tremaining: 515ms\n",
      "1749:\tlearn: 0.1806444\ttotal: 3.59s\tremaining: 513ms\n",
      "1750:\tlearn: 0.1806197\ttotal: 3.59s\tremaining: 511ms\n",
      "1751:\tlearn: 0.1805964\ttotal: 3.6s\tremaining: 509ms\n",
      "1752:\tlearn: 0.1805841\ttotal: 3.6s\tremaining: 507ms\n",
      "1753:\tlearn: 0.1805718\ttotal: 3.6s\tremaining: 505ms\n",
      "1754:\tlearn: 0.1805528\ttotal: 3.6s\tremaining: 503ms\n",
      "1755:\tlearn: 0.1805392\ttotal: 3.6s\tremaining: 501ms\n",
      "1756:\tlearn: 0.1805111\ttotal: 3.61s\tremaining: 499ms\n",
      "1757:\tlearn: 0.1804951\ttotal: 3.61s\tremaining: 497ms\n",
      "1758:\tlearn: 0.1804823\ttotal: 3.61s\tremaining: 495ms\n",
      "1759:\tlearn: 0.1804588\ttotal: 3.61s\tremaining: 493ms\n",
      "1760:\tlearn: 0.1804478\ttotal: 3.62s\tremaining: 491ms\n",
      "1761:\tlearn: 0.1804381\ttotal: 3.62s\tremaining: 489ms\n",
      "1762:\tlearn: 0.1804187\ttotal: 3.62s\tremaining: 487ms\n",
      "1763:\tlearn: 0.1804086\ttotal: 3.62s\tremaining: 484ms\n",
      "1764:\tlearn: 0.1803989\ttotal: 3.62s\tremaining: 482ms\n",
      "1765:\tlearn: 0.1803945\ttotal: 3.62s\tremaining: 480ms\n",
      "1766:\tlearn: 0.1803828\ttotal: 3.63s\tremaining: 478ms\n",
      "1767:\tlearn: 0.1803602\ttotal: 3.63s\tremaining: 476ms\n",
      "1768:\tlearn: 0.1803377\ttotal: 3.63s\tremaining: 474ms\n",
      "1769:\tlearn: 0.1803154\ttotal: 3.63s\tremaining: 472ms\n",
      "1770:\tlearn: 0.1803112\ttotal: 3.63s\tremaining: 470ms\n",
      "1771:\tlearn: 0.1802873\ttotal: 3.64s\tremaining: 468ms\n",
      "1772:\tlearn: 0.1802752\ttotal: 3.64s\tremaining: 466ms\n",
      "1773:\tlearn: 0.1802711\ttotal: 3.64s\tremaining: 464ms\n",
      "1774:\tlearn: 0.1802608\ttotal: 3.64s\tremaining: 462ms\n",
      "1775:\tlearn: 0.1802569\ttotal: 3.64s\tremaining: 460ms\n",
      "1776:\tlearn: 0.1802513\ttotal: 3.65s\tremaining: 458ms\n",
      "1777:\tlearn: 0.1802441\ttotal: 3.65s\tremaining: 456ms\n",
      "1778:\tlearn: 0.1802346\ttotal: 3.65s\tremaining: 453ms\n",
      "1779:\tlearn: 0.1802207\ttotal: 3.65s\tremaining: 451ms\n",
      "1780:\tlearn: 0.1802048\ttotal: 3.65s\tremaining: 449ms\n",
      "1781:\tlearn: 0.1801948\ttotal: 3.65s\tremaining: 447ms\n",
      "1782:\tlearn: 0.1801839\ttotal: 3.66s\tremaining: 445ms\n",
      "1783:\tlearn: 0.1801787\ttotal: 3.66s\tremaining: 443ms\n",
      "1784:\tlearn: 0.1801468\ttotal: 3.66s\tremaining: 441ms\n",
      "1785:\tlearn: 0.1801419\ttotal: 3.66s\tremaining: 439ms\n",
      "1786:\tlearn: 0.1801310\ttotal: 3.67s\tremaining: 437ms\n",
      "1787:\tlearn: 0.1801066\ttotal: 3.67s\tremaining: 435ms\n",
      "1788:\tlearn: 0.1800940\ttotal: 3.67s\tremaining: 433ms\n",
      "1789:\tlearn: 0.1800813\ttotal: 3.67s\tremaining: 431ms\n",
      "1790:\tlearn: 0.1800781\ttotal: 3.67s\tremaining: 429ms\n",
      "1791:\tlearn: 0.1800601\ttotal: 3.67s\tremaining: 427ms\n",
      "1792:\tlearn: 0.1800434\ttotal: 3.68s\tremaining: 425ms\n",
      "1793:\tlearn: 0.1800326\ttotal: 3.68s\tremaining: 422ms\n",
      "1794:\tlearn: 0.1800275\ttotal: 3.68s\tremaining: 420ms\n",
      "1795:\tlearn: 0.1800094\ttotal: 3.68s\tremaining: 418ms\n",
      "1796:\tlearn: 0.1799947\ttotal: 3.69s\tremaining: 416ms\n",
      "1797:\tlearn: 0.1799668\ttotal: 3.69s\tremaining: 414ms\n",
      "1798:\tlearn: 0.1799489\ttotal: 3.69s\tremaining: 412ms\n",
      "1799:\tlearn: 0.1799275\ttotal: 3.69s\tremaining: 410ms\n",
      "1800:\tlearn: 0.1799226\ttotal: 3.69s\tremaining: 408ms\n",
      "1801:\tlearn: 0.1799112\ttotal: 3.69s\tremaining: 406ms\n",
      "1802:\tlearn: 0.1799047\ttotal: 3.7s\tremaining: 404ms\n",
      "1803:\tlearn: 0.1798819\ttotal: 3.7s\tremaining: 402ms\n",
      "1804:\tlearn: 0.1798712\ttotal: 3.7s\tremaining: 400ms\n",
      "1805:\tlearn: 0.1798603\ttotal: 3.7s\tremaining: 398ms\n",
      "1806:\tlearn: 0.1798206\ttotal: 3.7s\tremaining: 396ms\n",
      "1807:\tlearn: 0.1797827\ttotal: 3.71s\tremaining: 394ms\n",
      "1808:\tlearn: 0.1797465\ttotal: 3.71s\tremaining: 392ms\n",
      "1809:\tlearn: 0.1797232\ttotal: 3.71s\tremaining: 389ms\n",
      "1810:\tlearn: 0.1797004\ttotal: 3.71s\tremaining: 387ms\n",
      "1811:\tlearn: 0.1796845\ttotal: 3.71s\tremaining: 385ms\n",
      "1812:\tlearn: 0.1796546\ttotal: 3.72s\tremaining: 383ms\n",
      "1813:\tlearn: 0.1796343\ttotal: 3.72s\tremaining: 381ms\n",
      "1814:\tlearn: 0.1796208\ttotal: 3.72s\tremaining: 379ms\n",
      "1815:\tlearn: 0.1796115\ttotal: 3.72s\tremaining: 377ms\n",
      "1816:\tlearn: 0.1795934\ttotal: 3.72s\tremaining: 375ms\n",
      "1817:\tlearn: 0.1795871\ttotal: 3.73s\tremaining: 373ms\n",
      "1818:\tlearn: 0.1795823\ttotal: 3.73s\tremaining: 371ms\n",
      "1819:\tlearn: 0.1795619\ttotal: 3.73s\tremaining: 369ms\n",
      "1820:\tlearn: 0.1795392\ttotal: 3.73s\tremaining: 367ms\n",
      "1821:\tlearn: 0.1795341\ttotal: 3.73s\tremaining: 365ms\n",
      "1822:\tlearn: 0.1795190\ttotal: 3.73s\tremaining: 363ms\n",
      "1823:\tlearn: 0.1795043\ttotal: 3.74s\tremaining: 361ms\n",
      "1824:\tlearn: 0.1794835\ttotal: 3.74s\tremaining: 359ms\n",
      "1825:\tlearn: 0.1794788\ttotal: 3.74s\tremaining: 357ms\n",
      "1826:\tlearn: 0.1794638\ttotal: 3.74s\tremaining: 354ms\n",
      "1827:\tlearn: 0.1794423\ttotal: 3.75s\tremaining: 352ms\n",
      "1828:\tlearn: 0.1794321\ttotal: 3.75s\tremaining: 350ms\n",
      "1829:\tlearn: 0.1794111\ttotal: 3.75s\tremaining: 348ms\n",
      "1830:\tlearn: 0.1794082\ttotal: 3.75s\tremaining: 346ms\n",
      "1831:\tlearn: 0.1793593\ttotal: 3.75s\tremaining: 344ms\n",
      "1832:\tlearn: 0.1793366\ttotal: 3.76s\tremaining: 342ms\n",
      "1833:\tlearn: 0.1793159\ttotal: 3.76s\tremaining: 340ms\n",
      "1834:\tlearn: 0.1793017\ttotal: 3.76s\tremaining: 338ms\n",
      "1835:\tlearn: 0.1792843\ttotal: 3.76s\tremaining: 336ms\n",
      "1836:\tlearn: 0.1792450\ttotal: 3.76s\tremaining: 334ms\n",
      "1837:\tlearn: 0.1792350\ttotal: 3.77s\tremaining: 332ms\n",
      "1838:\tlearn: 0.1792304\ttotal: 3.77s\tremaining: 330ms\n",
      "1839:\tlearn: 0.1792191\ttotal: 3.77s\tremaining: 328ms\n",
      "1840:\tlearn: 0.1792005\ttotal: 3.77s\tremaining: 326ms\n",
      "1841:\tlearn: 0.1791910\ttotal: 3.77s\tremaining: 324ms\n",
      "1842:\tlearn: 0.1791812\ttotal: 3.78s\tremaining: 322ms\n",
      "1843:\tlearn: 0.1791675\ttotal: 3.78s\tremaining: 320ms\n",
      "1844:\tlearn: 0.1791557\ttotal: 3.78s\tremaining: 318ms\n",
      "1845:\tlearn: 0.1791462\ttotal: 3.78s\tremaining: 316ms\n",
      "1846:\tlearn: 0.1791341\ttotal: 3.78s\tremaining: 314ms\n",
      "1847:\tlearn: 0.1791241\ttotal: 3.79s\tremaining: 311ms\n",
      "1848:\tlearn: 0.1791148\ttotal: 3.79s\tremaining: 309ms\n",
      "1849:\tlearn: 0.1790977\ttotal: 3.79s\tremaining: 307ms\n",
      "1850:\tlearn: 0.1790887\ttotal: 3.79s\tremaining: 305ms\n",
      "1851:\tlearn: 0.1790738\ttotal: 3.79s\tremaining: 303ms\n",
      "1852:\tlearn: 0.1790628\ttotal: 3.8s\tremaining: 301ms\n",
      "1853:\tlearn: 0.1790477\ttotal: 3.8s\tremaining: 299ms\n",
      "1854:\tlearn: 0.1790385\ttotal: 3.8s\tremaining: 297ms\n",
      "1855:\tlearn: 0.1790150\ttotal: 3.8s\tremaining: 295ms\n",
      "1856:\tlearn: 0.1789957\ttotal: 3.8s\tremaining: 293ms\n",
      "1857:\tlearn: 0.1789832\ttotal: 3.81s\tremaining: 291ms\n",
      "1858:\tlearn: 0.1789728\ttotal: 3.81s\tremaining: 289ms\n",
      "1859:\tlearn: 0.1789572\ttotal: 3.81s\tremaining: 287ms\n",
      "1860:\tlearn: 0.1789348\ttotal: 3.81s\tremaining: 285ms\n",
      "1861:\tlearn: 0.1789148\ttotal: 3.81s\tremaining: 283ms\n",
      "1862:\tlearn: 0.1789090\ttotal: 3.81s\tremaining: 281ms\n",
      "1863:\tlearn: 0.1788848\ttotal: 3.82s\tremaining: 279ms\n",
      "1864:\tlearn: 0.1788743\ttotal: 3.82s\tremaining: 277ms\n",
      "1865:\tlearn: 0.1788625\ttotal: 3.82s\tremaining: 274ms\n",
      "1866:\tlearn: 0.1788467\ttotal: 3.82s\tremaining: 272ms\n",
      "1867:\tlearn: 0.1788269\ttotal: 3.83s\tremaining: 270ms\n",
      "1868:\tlearn: 0.1788151\ttotal: 3.83s\tremaining: 268ms\n",
      "1869:\tlearn: 0.1787940\ttotal: 3.83s\tremaining: 266ms\n",
      "1870:\tlearn: 0.1787724\ttotal: 3.83s\tremaining: 264ms\n",
      "1871:\tlearn: 0.1787443\ttotal: 3.83s\tremaining: 262ms\n",
      "1872:\tlearn: 0.1787281\ttotal: 3.84s\tremaining: 260ms\n",
      "1873:\tlearn: 0.1787177\ttotal: 3.84s\tremaining: 258ms\n",
      "1874:\tlearn: 0.1786995\ttotal: 3.84s\tremaining: 256ms\n",
      "1875:\tlearn: 0.1786787\ttotal: 3.84s\tremaining: 254ms\n",
      "1876:\tlearn: 0.1786615\ttotal: 3.84s\tremaining: 252ms\n",
      "1877:\tlearn: 0.1786280\ttotal: 3.85s\tremaining: 250ms\n",
      "1878:\tlearn: 0.1786101\ttotal: 3.85s\tremaining: 248ms\n",
      "1879:\tlearn: 0.1785796\ttotal: 3.85s\tremaining: 246ms\n",
      "1880:\tlearn: 0.1785641\ttotal: 3.85s\tremaining: 244ms\n",
      "1881:\tlearn: 0.1785494\ttotal: 3.85s\tremaining: 242ms\n",
      "1882:\tlearn: 0.1785374\ttotal: 3.85s\tremaining: 240ms\n",
      "1883:\tlearn: 0.1785084\ttotal: 3.86s\tremaining: 238ms\n",
      "1884:\tlearn: 0.1784931\ttotal: 3.86s\tremaining: 235ms\n",
      "1885:\tlearn: 0.1784681\ttotal: 3.86s\tremaining: 233ms\n",
      "1886:\tlearn: 0.1784561\ttotal: 3.86s\tremaining: 231ms\n",
      "1887:\tlearn: 0.1784470\ttotal: 3.87s\tremaining: 229ms\n",
      "1888:\tlearn: 0.1784276\ttotal: 3.87s\tremaining: 227ms\n",
      "1889:\tlearn: 0.1784187\ttotal: 3.87s\tremaining: 225ms\n",
      "1890:\tlearn: 0.1784099\ttotal: 3.87s\tremaining: 223ms\n",
      "1891:\tlearn: 0.1783831\ttotal: 3.87s\tremaining: 221ms\n",
      "1892:\tlearn: 0.1783742\ttotal: 3.88s\tremaining: 219ms\n",
      "1893:\tlearn: 0.1783594\ttotal: 3.88s\tremaining: 217ms\n",
      "1894:\tlearn: 0.1783510\ttotal: 3.88s\tremaining: 215ms\n",
      "1895:\tlearn: 0.1783363\ttotal: 3.88s\tremaining: 213ms\n",
      "1896:\tlearn: 0.1783172\ttotal: 3.88s\tremaining: 211ms\n",
      "1897:\tlearn: 0.1783091\ttotal: 3.88s\tremaining: 209ms\n",
      "1898:\tlearn: 0.1782934\ttotal: 3.89s\tremaining: 207ms\n",
      "1899:\tlearn: 0.1782793\ttotal: 3.89s\tremaining: 205ms\n",
      "1900:\tlearn: 0.1782678\ttotal: 3.89s\tremaining: 203ms\n",
      "1901:\tlearn: 0.1782574\ttotal: 3.89s\tremaining: 201ms\n",
      "1902:\tlearn: 0.1782390\ttotal: 3.9s\tremaining: 199ms\n",
      "1903:\tlearn: 0.1782301\ttotal: 3.9s\tremaining: 197ms\n",
      "1904:\tlearn: 0.1782161\ttotal: 3.9s\tremaining: 194ms\n",
      "1905:\tlearn: 0.1782013\ttotal: 3.9s\tremaining: 192ms\n",
      "1906:\tlearn: 0.1781860\ttotal: 3.9s\tremaining: 190ms\n",
      "1907:\tlearn: 0.1781627\ttotal: 3.9s\tremaining: 188ms\n",
      "1908:\tlearn: 0.1781445\ttotal: 3.91s\tremaining: 186ms\n",
      "1909:\tlearn: 0.1781335\ttotal: 3.91s\tremaining: 184ms\n",
      "1910:\tlearn: 0.1781291\ttotal: 3.91s\tremaining: 182ms\n",
      "1911:\tlearn: 0.1781155\ttotal: 3.91s\tremaining: 180ms\n",
      "1912:\tlearn: 0.1781055\ttotal: 3.92s\tremaining: 178ms\n",
      "1913:\tlearn: 0.1780948\ttotal: 3.92s\tremaining: 176ms\n",
      "1914:\tlearn: 0.1780819\ttotal: 3.92s\tremaining: 174ms\n",
      "1915:\tlearn: 0.1780726\ttotal: 3.92s\tremaining: 172ms\n",
      "1916:\tlearn: 0.1780593\ttotal: 3.92s\tremaining: 170ms\n",
      "1917:\tlearn: 0.1780549\ttotal: 3.92s\tremaining: 168ms\n",
      "1918:\tlearn: 0.1780427\ttotal: 3.93s\tremaining: 166ms\n",
      "1919:\tlearn: 0.1780290\ttotal: 3.93s\tremaining: 164ms\n",
      "1920:\tlearn: 0.1780234\ttotal: 3.93s\tremaining: 162ms\n",
      "1921:\tlearn: 0.1780135\ttotal: 3.93s\tremaining: 160ms\n",
      "1922:\tlearn: 0.1780093\ttotal: 3.93s\tremaining: 158ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1923:\tlearn: 0.1780035\ttotal: 3.94s\tremaining: 156ms\n",
      "1924:\tlearn: 0.1779944\ttotal: 3.94s\tremaining: 153ms\n",
      "1925:\tlearn: 0.1779821\ttotal: 3.94s\tremaining: 151ms\n",
      "1926:\tlearn: 0.1779779\ttotal: 3.94s\tremaining: 149ms\n",
      "1927:\tlearn: 0.1779549\ttotal: 3.94s\tremaining: 147ms\n",
      "1928:\tlearn: 0.1779463\ttotal: 3.95s\tremaining: 145ms\n",
      "1929:\tlearn: 0.1779258\ttotal: 3.95s\tremaining: 143ms\n",
      "1930:\tlearn: 0.1779097\ttotal: 3.95s\tremaining: 141ms\n",
      "1931:\tlearn: 0.1779016\ttotal: 3.95s\tremaining: 139ms\n",
      "1932:\tlearn: 0.1778879\ttotal: 3.96s\tremaining: 137ms\n",
      "1933:\tlearn: 0.1778770\ttotal: 3.96s\tremaining: 135ms\n",
      "1934:\tlearn: 0.1778575\ttotal: 3.96s\tremaining: 133ms\n",
      "1935:\tlearn: 0.1778399\ttotal: 3.96s\tremaining: 131ms\n",
      "1936:\tlearn: 0.1778299\ttotal: 3.96s\tremaining: 129ms\n",
      "1937:\tlearn: 0.1778189\ttotal: 3.96s\tremaining: 127ms\n",
      "1938:\tlearn: 0.1778134\ttotal: 3.97s\tremaining: 125ms\n",
      "1939:\tlearn: 0.1777938\ttotal: 3.97s\tremaining: 123ms\n",
      "1940:\tlearn: 0.1777768\ttotal: 3.97s\tremaining: 121ms\n",
      "1941:\tlearn: 0.1777547\ttotal: 3.97s\tremaining: 119ms\n",
      "1942:\tlearn: 0.1777488\ttotal: 3.98s\tremaining: 117ms\n",
      "1943:\tlearn: 0.1777438\ttotal: 3.98s\tremaining: 115ms\n",
      "1944:\tlearn: 0.1777388\ttotal: 3.98s\tremaining: 113ms\n",
      "1945:\tlearn: 0.1777146\ttotal: 3.98s\tremaining: 110ms\n",
      "1946:\tlearn: 0.1776933\ttotal: 3.98s\tremaining: 108ms\n",
      "1947:\tlearn: 0.1776733\ttotal: 3.98s\tremaining: 106ms\n",
      "1948:\tlearn: 0.1776441\ttotal: 3.99s\tremaining: 104ms\n",
      "1949:\tlearn: 0.1776239\ttotal: 3.99s\tremaining: 102ms\n",
      "1950:\tlearn: 0.1776178\ttotal: 3.99s\tremaining: 100ms\n",
      "1951:\tlearn: 0.1775966\ttotal: 3.99s\tremaining: 98.2ms\n",
      "1952:\tlearn: 0.1775823\ttotal: 3.99s\tremaining: 96.1ms\n",
      "1953:\tlearn: 0.1775764\ttotal: 4s\tremaining: 94.1ms\n",
      "1954:\tlearn: 0.1775654\ttotal: 4s\tremaining: 92.1ms\n",
      "1955:\tlearn: 0.1775435\ttotal: 4s\tremaining: 90.1ms\n",
      "1956:\tlearn: 0.1775234\ttotal: 4.01s\tremaining: 88ms\n",
      "1957:\tlearn: 0.1775158\ttotal: 4.01s\tremaining: 86ms\n",
      "1958:\tlearn: 0.1774922\ttotal: 4.01s\tremaining: 83.9ms\n",
      "1959:\tlearn: 0.1774749\ttotal: 4.01s\tremaining: 81.9ms\n",
      "1960:\tlearn: 0.1774587\ttotal: 4.01s\tremaining: 79.8ms\n",
      "1961:\tlearn: 0.1774450\ttotal: 4.02s\tremaining: 77.8ms\n",
      "1962:\tlearn: 0.1774263\ttotal: 4.02s\tremaining: 75.7ms\n",
      "1963:\tlearn: 0.1774152\ttotal: 4.02s\tremaining: 73.7ms\n",
      "1964:\tlearn: 0.1774083\ttotal: 4.02s\tremaining: 71.6ms\n",
      "1965:\tlearn: 0.1773954\ttotal: 4.02s\tremaining: 69.6ms\n",
      "1966:\tlearn: 0.1773772\ttotal: 4.03s\tremaining: 67.5ms\n",
      "1967:\tlearn: 0.1773715\ttotal: 4.03s\tremaining: 65.5ms\n",
      "1968:\tlearn: 0.1773659\ttotal: 4.03s\tremaining: 63.4ms\n",
      "1969:\tlearn: 0.1773494\ttotal: 4.03s\tremaining: 61.4ms\n",
      "1970:\tlearn: 0.1773376\ttotal: 4.03s\tremaining: 59.4ms\n",
      "1971:\tlearn: 0.1773264\ttotal: 4.04s\tremaining: 57.3ms\n",
      "1972:\tlearn: 0.1773231\ttotal: 4.04s\tremaining: 55.3ms\n",
      "1973:\tlearn: 0.1773019\ttotal: 4.04s\tremaining: 53.2ms\n",
      "1974:\tlearn: 0.1772863\ttotal: 4.04s\tremaining: 51.2ms\n",
      "1975:\tlearn: 0.1772762\ttotal: 4.04s\tremaining: 49.1ms\n",
      "1976:\tlearn: 0.1772693\ttotal: 4.04s\tremaining: 47.1ms\n",
      "1977:\tlearn: 0.1772486\ttotal: 4.05s\tremaining: 45ms\n",
      "1978:\tlearn: 0.1772315\ttotal: 4.05s\tremaining: 43ms\n",
      "1979:\tlearn: 0.1772240\ttotal: 4.05s\tremaining: 40.9ms\n",
      "1980:\tlearn: 0.1772069\ttotal: 4.05s\tremaining: 38.9ms\n",
      "1981:\tlearn: 0.1772042\ttotal: 4.05s\tremaining: 36.8ms\n",
      "1982:\tlearn: 0.1771845\ttotal: 4.06s\tremaining: 34.8ms\n",
      "1983:\tlearn: 0.1771737\ttotal: 4.06s\tremaining: 32.7ms\n",
      "1984:\tlearn: 0.1771573\ttotal: 4.06s\tremaining: 30.7ms\n",
      "1985:\tlearn: 0.1771430\ttotal: 4.06s\tremaining: 28.6ms\n",
      "1986:\tlearn: 0.1771404\ttotal: 4.07s\tremaining: 26.6ms\n",
      "1987:\tlearn: 0.1771275\ttotal: 4.07s\tremaining: 24.6ms\n",
      "1988:\tlearn: 0.1771230\ttotal: 4.07s\tremaining: 22.5ms\n",
      "1989:\tlearn: 0.1771126\ttotal: 4.07s\tremaining: 20.5ms\n",
      "1990:\tlearn: 0.1771076\ttotal: 4.07s\tremaining: 18.4ms\n",
      "1991:\tlearn: 0.1770861\ttotal: 4.08s\tremaining: 16.4ms\n",
      "1992:\tlearn: 0.1770659\ttotal: 4.08s\tremaining: 14.3ms\n",
      "1993:\tlearn: 0.1770441\ttotal: 4.08s\tremaining: 12.3ms\n",
      "1994:\tlearn: 0.1770223\ttotal: 4.08s\tremaining: 10.2ms\n",
      "1995:\tlearn: 0.1770069\ttotal: 4.08s\tremaining: 8.18ms\n",
      "1996:\tlearn: 0.1769980\ttotal: 4.08s\tremaining: 6.14ms\n",
      "1997:\tlearn: 0.1769927\ttotal: 4.09s\tremaining: 4.09ms\n",
      "1998:\tlearn: 0.1769784\ttotal: 4.09s\tremaining: 2.04ms\n",
      "1999:\tlearn: 0.1769732\ttotal: 4.09s\tremaining: 0us\n",
      "0.3141501908969476\n"
     ]
    }
   ],
   "source": [
    "import catboost as cat\n",
    "meta_learner_no_params = cat.CatBoostRegressor(iterations = 2000)\n",
    "meta_learner_no_params.fit(xtrain_new, train_label)\n",
    "\n",
    "##预测\n",
    "pred = meta_learner_no_params.predict(valid_feature.values)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(valid_label,pred))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking贝叶斯优化开始------------\n",
      "\r",
      "  0%|                                                                           | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/50 [00:01<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"D:\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 407, in _process_worker\n    call_item = call_queue.get(block=True, timeout=timeout)\n  File \"D:\\anaconda3\\lib\\multiprocessing\\queues.py\", line 122, in get\n    return _ForkingPickler.loads(res)\n  File \"D:\\anaconda3\\lib\\site-packages\\catboost\\__init__.py\", line 1, in <module>\n    from .core import (\n  File \"D:\\anaconda3\\lib\\site-packages\\catboost\\core.py\", line 46, in <module>\n    from .plot_helpers import save_plot_file, try_plot_offline, OfflineMetricVisualizer\n  File \"D:\\anaconda3\\lib\\site-packages\\catboost\\plot_helpers.py\", line 5, in <module>\n    from . import _catboost\nImportError: DLL load failed while importing _catboost: 页面文件太小，无法完成操作。\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21292/144815339.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparams_best\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Stacking贝叶斯优化开始------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[0mparams_best\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_hyperopt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Stacking贝叶斯优化结束------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21292/144815339.py\u001b[0m in \u001b[0;36mparam_hyperopt\u001b[1;34m(max_evals)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mearly_stop_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mno_progress_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     params_best=fmin(hyperopt_objective # 设定目标函数\n\u001b[0m\u001b[0;32m     42\u001b[0m                      \u001b[1;33m,\u001b[0m\u001b[0mspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid_simple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                      \u001b[1;33m,\u001b[0m\u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fmin\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m         return trials.fmin(\n\u001b[0m\u001b[0;32m    541\u001b[0m             \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m             \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         return fmin(\n\u001b[0m\u001b[0;32m    672\u001b[0m             \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[1;31m# next line is where the fmin is actually executed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                     \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"job exception: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    890\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m             )\n\u001b[1;32m--> 892\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21292/144815339.py\u001b[0m in \u001b[0;36mhyperopt_objective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3612\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     validate_loss=abs(cross_val_score(model,train_feature,train_label\n\u001b[0m\u001b[0;32m     16\u001b[0m                                    \u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                                    \u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_root_mean_squared_error'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m     cv_results = cross_validate(\n\u001b[0m\u001b[0;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;31m# independent, and that it is pickle-able.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                 \u001b[1;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable."
     ]
    }
   ],
   "source": [
    "##模型调参\n",
    "from hyperopt import hp, tpe, fmin,STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "\n",
    "##定义第二层的要优化的参数函数\n",
    "def hyperopt_objective(params):\n",
    "    model=cat.CatBoostRegressor(iterations=int(params['iterations'])\n",
    "              ,max_depth=int(params['max_depth'])\n",
    "              ,l2_leaf_reg=params['l2_leaf_reg']\n",
    "              ,learning_rate=params['learning_rate']\n",
    "              )\n",
    "    \n",
    "    cv=KFold(n_splits=5,shuffle=True,random_state=3612)\n",
    "    validate_loss=abs(cross_val_score(model,train_feature,train_label\n",
    "                                   ,cv=cv\n",
    "                                   ,scoring='neg_root_mean_squared_error'\n",
    "                                   ,n_jobs=-1\n",
    "                                   ,error_score='raise')).mean()\n",
    "    \n",
    "    return validate_loss\n",
    "\n",
    " ##生成参数范围\n",
    "iterations_range = range(1500,2500,50)\n",
    "depth_range = range(1,10,1)\n",
    "l2_leaf_reg_range = range(2,8,1)\n",
    "\n",
    "param_grid_simple={'iterations':hp.choice('iterations',iterations_range)\n",
    "                   ,'max_depth':hp.choice('max_depth',depth_range)\n",
    "                   ,'l2_leaf_reg':hp.choice('l2_leaf_reg',l2_leaf_reg_range)\n",
    "                   ,'learning_rate':hp.quniform('learning_rate',0.001,0.5,0.001)\n",
    "                  }\n",
    "\n",
    "def param_hyperopt(max_evals=100):\n",
    "    # 记录迭代过程\n",
    "    trials=Trials()\n",
    "    \n",
    "    # 提前停止\n",
    "    early_stop_fn=no_progress_loss(50) \n",
    "\n",
    "    params_best=fmin(hyperopt_objective # 设定目标函数\n",
    "                     ,space=param_grid_simple \n",
    "                     ,algo=tpe.suggest \n",
    "                     ,max_evals=max_evals # 设定迭代次数\n",
    "                     ,trials=trials \n",
    "                     ,early_stop_fn=early_stop_fn # 控制提前停止\n",
    "                    )\n",
    "    \n",
    "    print('best parmas:',params_best)\n",
    "    return params_best,trials\n",
    "print('Stacking贝叶斯优化开始------------')\n",
    "params_best,trials = param_hyperopt(max_evals=50)\n",
    "print('Stacking贝叶斯优化结束------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner = cat.CatBoostRegressor(max_depth = depth_range[params_best['max_depth']],\n",
    "                                      iterations = iterations_range[params_best['iterations']],\n",
    "                                      l2_leaf_reg = l2_leaf_reg_range[params_best['l2_leaf_reg']])\n",
    "meta_learner.fit(train_feature, train_label)\n",
    "\n",
    "\n",
    "\n",
    "##预测\n",
    "pred_param = meta_learner.predict(valid_feature.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_catboost(model):\n",
    "    result=pd.DataFrame(model.get_feature_importance(),index=model.feature_names_,columns=['FeatureImportance'])\n",
    "    return result.sort_values('FeatureImportance',ascending=False)\n",
    "df=feature_importance_catboost(meta_learner)\n",
    "newco=df.drop(df.index[55:]).index\n",
    "df.drop(df.index[55:])\n",
    "#newco=df.drop(df.index[51:]).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##模型调参\n",
    "from hyperopt import hp, tpe, fmin,STATUS_OK, Trials\n",
    "from hyperopt.early_stop import no_progress_loss\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "\n",
    "##定义第二层的要优化的参数函数\n",
    "def hyperopt_objective(params):\n",
    "    model=cat.CatBoostRegressor(iterations=int(params['iterations'])\n",
    "              ,max_depth=int(params['max_depth'])\n",
    "              ,l2_leaf_reg=params['l2_leaf_reg']\n",
    "              ,learning_rate=params['learning_rate']\n",
    "              )\n",
    "    \n",
    "    cv=KFold(n_splits=5,shuffle=True,random_state=7)\n",
    "    validate_loss=abs(cross_val_score(model,trainnewpd,train_label\n",
    "                                   ,cv=cv\n",
    "                                   ,scoring='neg_root_mean_squared_error'\n",
    "                                   ,n_jobs=-1\n",
    "                                   ,error_score='raise')).mean()\n",
    "    \n",
    "    return validate_loss\n",
    "\n",
    " ##生成参数范围\n",
    "iterations_range = range(1500,2500,50)\n",
    "depth_range = range(1,10,1)\n",
    "l2_leaf_reg_range = range(2,8,1)\n",
    "\n",
    "param_grid_simple={'iterations':hp.choice('iterations',iterations_range)\n",
    "                   ,'max_depth':hp.choice('max_depth',depth_range)\n",
    "                   ,'l2_leaf_reg':hp.choice('l2_leaf_reg',l2_leaf_reg_range)\n",
    "                   ,'learning_rate':hp.quniform('learning_rate',0.001,0.5,0.001)\n",
    "                  }\n",
    "\n",
    "def param_hyperopt(max_evals=100):\n",
    "    # 记录迭代过程\n",
    "    trials=Trials()\n",
    "    \n",
    "    # 提前停止\n",
    "    early_stop_fn=no_progress_loss(50) \n",
    "\n",
    "    params_best=fmin(hyperopt_objective\n",
    "                     ,space=param_grid_simple \n",
    "                     ,algo=tpe.suggest \n",
    "                     ,max_evals=max_evals \n",
    "                     ,trials=trials \n",
    "                     ,early_stop_fn=early_stop_fn\n",
    "                    )\n",
    "    \n",
    "    print('best parmas:',params_best)\n",
    "    return params_best,trials\n",
    "print('Stacking贝叶斯优化开始------------')\n",
    "params_best,trials = param_hyperopt(max_evals=50)\n",
    "print('Stacking贝叶斯优化结束------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainnew=[]\n",
    "validnew=[]\n",
    "testnew=[]\n",
    "for i in newco:\n",
    "    trainnew.append(train_feature[i])\n",
    "    validnew.append(valid_feature[i])\n",
    "    testnew.append(test_1[i])\n",
    "trainnewpd=pd.DataFrame(trainnew).T\n",
    "validnewpd=pd.DataFrame(validnew).T\n",
    "testnewpd=pd.DataFrame(testnew).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner.fit(trainnewpd, train_label)\n",
    "\n",
    "pred_param = meta_learner.predict(validnewpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(mean_squared_error(valid_label.tolist(),pred_param)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = meta_learner.predict(test_1)\n",
    "pd.DataFrame(pred).to_csv('night.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "8ba9518ca4d3a1cfdfdedb62c6a9445a18bf006711f276b156ac15948056c126"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
